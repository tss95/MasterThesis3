{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-council",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "import pylab as pl\n",
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"0\" \n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "classes_dir = '/media/tord/T7/Thesis_ssd/MasterThesis3.0'\n",
    "os.chdir(classes_dir)\n",
    "from Classes.DataProcessing.LoadData import LoadData\n",
    "from Classes.DataProcessing.HelperFunctions import HelperFunctions\n",
    "from Classes.DataProcessing.DataHandler import DataHandler\n",
    "from Classes.DataProcessing.TimeAugmentor import TimeAugmentor\n",
    "from Classes.DataProcessing.NoiseAugmentor import NoiseAugmentor\n",
    "from Classes.DataProcessing.RamLoader import RamLoader\n",
    "from Classes.DataProcessing.RamGenerator import RamGenerator\n",
    "from Classes.Modeling.InceptionTimeModel import InceptionTimeModel\n",
    "from Classes.Modeling.CustomCallback import CustomCallback\n",
    "from Classes.Modeling.ResultFitter import ResultFitter\n",
    "from Classes.Scaling.ScalerFitter import ScalerFitter\n",
    "from Classes.Scaling.MinMaxScalerFitter import MinMaxScalerFitter\n",
    "from Classes.Scaling.StandardScalerFitter import StandardScalerFitter\n",
    "import json\n",
    "#from Classes import Tf_shutup\n",
    "#Tf_shutup.Tf_shutup()\n",
    "\n",
    "from livelossplot import PlotLossesKeras\n",
    "\n",
    "\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"]= (15,15)\n",
    "helper = HelperFunctions()\n",
    "\n",
    "import sys\n",
    "ISCOLAB = 'google.colab' in sys.modules\n",
    "\n",
    "import random\n",
    "import pprint\n",
    "\n",
    "base_dir = '/media/tord/T7/Thesis_ssd/MasterThesis3.0/Classes'\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-oakland",
   "metadata": {},
   "source": [
    "## Todo:\n",
    " - Noise augmentation improvement. Needs to augment batch wise, not at the beginning like it currently is doing.\n",
    " - Create Random Grid Search for the Inception Time model\n",
    " - Implement Tensorboard in order to visualize performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-playback",
   "metadata": {},
   "source": [
    "## Fixing Noise Augment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-minute",
   "metadata": {},
   "source": [
    "#### Currently the pipline is this:\n",
    "1. Load data and map redundency\n",
    "2. Initiate Time Augmentor\n",
    "3. Fit time augmentor\n",
    "4. Fit scaler\n",
    "5. Fit noise augmentor\n",
    "6. Load augmented/scaled data into ram.\n",
    "7. Create model\n",
    "8. Fit model using generator batches for the model, using batches from RAM.\n",
    "\n",
    "#### Want the pipeline to be like this:\n",
    "1. Load data\n",
    "2. Initiate Time Augmentor\n",
    "3. Fit time augmentor\n",
    "4. Fit scaler\n",
    "5. Fit noise augmentor\n",
    "6. Load time augmented and scaled data into ram.\n",
    "7. Create model\n",
    "8. Fit model using generator batches for the model, batch wise noise augmenting data from RAM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-burlington",
   "metadata": {},
   "source": [
    "### Status: Fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjacent-discipline",
   "metadata": {},
   "source": [
    "## Creating RGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-lemon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "careful-repair",
   "metadata": {},
   "source": [
    "## Implementing Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-emperor",
   "metadata": {},
   "source": [
    "### Status: Fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-terrace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
