{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dressed-france",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: GeForce RTX 3090, compute capability 8.6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import gc\n",
    "\n",
    "import sklearn as sk\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras.utils import GeneratorEnqueuer\n",
    "\n",
    "import os\n",
    "base_dir = '/media/tord/T7/Thesis_ssd/MasterThesis3'\n",
    "os.chdir(base_dir)\n",
    "\n",
    "from Classes.Modeling.LocalOptimizer import LocalOptimizer\n",
    "from Classes.Modeling.DynamicModels import DynamicModels\n",
    "from Classes.DataProcessing.LoadData import LoadData\n",
    "from Classes.DataProcessing.HelperFunctions import HelperFunctions\n",
    "from Classes.DataProcessing.DataHandler import DataHandler\n",
    "from Classes.DataProcessing.RamLoader import RamLoader\n",
    "from Classes.DataProcessing.ts_RamGenerator import data_generator\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "\n",
    "import random\n",
    "import pprint\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-gibraltar",
   "metadata": {},
   "source": [
    "# Best Noise-not-noise CNN model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "coastal-scale",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3\n",
      "{'noise': 105999, 'earthquake': 105999, 'explosion': 102808}\n",
      "Mapping redundancy: [--------------------------------------->] 100 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "load_args = {\n",
    "    'earth_explo_only' : False,\n",
    "    'noise_earth_only' : False,\n",
    "    'noise_not_noise' : True,\n",
    "    'downsample' : True,\n",
    "    'upsample' : True,\n",
    "    'frac_diff' : 1,\n",
    "    'seed' : 1,\n",
    "    'subsample_size' : 0.25,\n",
    "    'balance_non_train_set' : True,\n",
    "    'use_true_test_set' : False,\n",
    "    'even_balance' : True\n",
    "}\n",
    "loadData = LoadData(**load_args)\n",
    "full_ds, train_ds, val_ds, test_ds = loadData.get_datasets()\n",
    "noise_ds = loadData.noise_ds\n",
    "handler = DataHandler(loadData)\n",
    "helper = HelperFunctions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "concerned-meeting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 6000, 3)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 6000, 74)          11618     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6000, 74)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 6000, 74)          296       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 3000, 74)          0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 3000, 74)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 222000)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 290)               64380290  \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 145)               42195     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 146       \n",
      "=================================================================\n",
      "Total params: 64,434,545\n",
      "Trainable params: 64,434,397\n",
      "Non-trainable params: 148\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_nr_type = \"CNN\"\n",
    "num_classes = len(set(loadData.label_dict.values()))\n",
    "num_channels = 3\n",
    "\n",
    "optimizer = 'sgd'\n",
    "num_layers = 1\n",
    "learning_rate = 0.1\n",
    "epochs = 50\n",
    "batch_size = 64\n",
    "use_layerwise_dropout_batchnorm = True\n",
    "start_neurons = 290\n",
    "padding = 'same'\n",
    "output_layer_activation = 'sigmoid'\n",
    "l2_r = 0.1\n",
    "l1_r = 0.0001\n",
    "kernel_size = 52\n",
    "filters = 74\n",
    "dropout_rate = 0.0001\n",
    "decay_sequence = [1]\n",
    "activation = 'relu'\n",
    "\n",
    "timesteps = 6000\n",
    "\n",
    "optimizer = helper.get_optimizer(optimizer, learning_rate)\n",
    "\n",
    "model_args = helper.generate_build_model_args(model_nr_type, batch_size, dropout_rate, \n",
    "                                                               activation, output_layer_activation,\n",
    "                                                               l2_r, l1_r, start_neurons, filters, kernel_size, \n",
    "                                                               padding, \n",
    "                                                               num_layers = num_layers, \n",
    "                                                               is_lstm = True, \n",
    "                                                               num_classes = num_classes,\n",
    "                                                               decay_sequence = decay_sequence, \n",
    "                                                               channels = num_channels, \n",
    "                                                               timesteps = timesteps,\n",
    "                                                               use_layerwise_dropout_batchnorm = use_layerwise_dropout_batchnorm,\n",
    "                                                               )\n",
    "model = DynamicModels(**model_args).model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "seeing-distance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit process completed after 219.09593892097473 seconds. Total datapoints fitted: 52600.\n",
      "Average time per datapoint: 0.004165322032718151\n",
      "\n",
      "\n",
      "Stage one loading training set, timeAug: [--------------------------------------->] 100 %\n",
      "\n",
      "Stage one loading validation set, timeAug: [--------------------------------------->] 100 %\n",
      "\n",
      "Fitting scaler progress: [------------------->] 100 %\n",
      "\n",
      "Stage two loading training set, labels and standard scaler: [--------------------------------------->] 100 %\n",
      "\n",
      "Stage two loading validation set, labels and standard scaler: [--------------------------------------->] 100 %\n",
      "\n",
      "Completed loading to RAM [--------------------------------------> ] 99 %\n"
     ]
    }
   ],
   "source": [
    "use_time_augmentor = True\n",
    "use_noise_augmentor = True\n",
    "scaler_name = \"standard\"\n",
    "filter_name = None\n",
    "band_min = 2\n",
    "band_max = 4\n",
    "highpass_freq = 5\n",
    "\n",
    "use_tensorboard = True\n",
    "use_liveplots = False\n",
    "use_custom_callback = True\n",
    "use_early_stopping = True\n",
    "start_from_scratch = False\n",
    "use_reduced_lr = True\n",
    "log_data = True\n",
    "\n",
    "\n",
    "ramLoader = RamLoader(loadData, \n",
    "                      handler, \n",
    "                      use_time_augmentor = use_time_augmentor, \n",
    "                      use_noise_augmentor = use_noise_augmentor, \n",
    "                      scaler_name = scaler_name,\n",
    "                      filter_name = filter_name, \n",
    "                      band_min = band_min,\n",
    "                      band_max = band_max,\n",
    "                      highpass_freq = highpass_freq, \n",
    "                      load_test_set = False)\n",
    "x_train, y_train, x_val, y_val, timeAug, scaler, noiseAug = ramLoader.load_to_ram()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "available-phase",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_enq = GeneratorEnqueuer(data_generator(x_train, y_train, batch_size, loadData, handler, noiseAug, num_channels = num_channels, is_lstm  = True), use_multiprocessing = False)\n",
    "val_enq = GeneratorEnqueuer(data_generator(x_val, y_val,batch_size, loadData, handler, noiseAug, num_channels = num_channels, is_lstm  = True), use_multiprocessing = False)\n",
    "train_enq.start(workers = 12, max_queue_size = 15)\n",
    "val_enq.start(workers = 12, max_queue_size = 15)\n",
    "train_gen = train_enq.get()\n",
    "val_gen = train_enq.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "approved-underwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate compiler args using picks\n",
    "model_compile_args = helper.generate_model_compile_args(optimizer, num_classes)\n",
    "# Compile model using generated args\n",
    "model.compile(**model_compile_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "nuclear-fence",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "616/616 [==============================] - 23s 32ms/step - loss: 4.9358 - binary_accuracy: 0.7165 - precision: 0.8274 - recall: 0.5379 - val_loss: 0.5003 - val_binary_accuracy: 0.7881 - val_precision: 0.9862 - val_recall: 0.5825\n",
      "Epoch 2/50\n",
      "616/616 [==============================] - 19s 31ms/step - loss: 0.4314 - binary_accuracy: 0.8609 - precision: 0.9153 - recall: 0.7904 - val_loss: 0.3305 - val_binary_accuracy: 0.8963 - val_precision: 0.9541 - val_recall: 0.8275\n",
      "Epoch 3/50\n",
      "616/616 [==============================] - 20s 32ms/step - loss: 0.3480 - binary_accuracy: 0.8748 - precision: 0.9079 - recall: 0.8317 - val_loss: 0.3424 - val_binary_accuracy: 0.8902 - val_precision: 0.9734 - val_recall: 0.7978\n",
      "Epoch 4/50\n",
      "616/616 [==============================] - 19s 31ms/step - loss: 0.5191 - binary_accuracy: 0.8905 - precision: 0.9162 - recall: 0.8590 - val_loss: 0.2868 - val_binary_accuracy: 0.8980 - val_precision: 0.9666 - val_recall: 0.8244\n",
      "Epoch 5/50\n",
      "616/616 [==============================] - 20s 32ms/step - loss: 0.3456 - binary_accuracy: 0.9013 - precision: 0.9172 - recall: 0.8801 - val_loss: 0.3684 - val_binary_accuracy: 0.8524 - val_precision: 0.9732 - val_recall: 0.7229\n",
      "Epoch 6/50\n",
      "616/616 [==============================] - 19s 31ms/step - loss: 0.2838 - binary_accuracy: 0.9074 - precision: 0.9286 - recall: 0.8812 - val_loss: 0.5042 - val_binary_accuracy: 0.9090 - val_precision: 0.9537 - val_recall: 0.8587\n",
      "Epoch 7/50\n",
      "616/616 [==============================] - 20s 32ms/step - loss: 0.2951 - binary_accuracy: 0.9065 - precision: 0.9246 - recall: 0.8824 - val_loss: 0.3491 - val_binary_accuracy: 0.8854 - val_precision: 0.9755 - val_recall: 0.7858\n",
      "Epoch 8/50\n",
      "616/616 [==============================] - 20s 32ms/step - loss: 0.2591 - binary_accuracy: 0.9092 - precision: 0.9314 - recall: 0.8816 - val_loss: 0.3192 - val_binary_accuracy: 0.8882 - val_precision: 0.9688 - val_recall: 0.7974\n",
      "Epoch 9/50\n",
      "616/616 [==============================] - 19s 31ms/step - loss: 0.2727 - binary_accuracy: 0.9135 - precision: 0.9406 - recall: 0.8816 - val_loss: 0.3335 - val_binary_accuracy: 0.8806 - val_precision: 0.9719 - val_recall: 0.7836\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0500000007451.\n",
      "Epoch 10/50\n",
      "616/616 [==============================] - 20s 32ms/step - loss: 0.2021 - binary_accuracy: 0.9364 - precision: 0.9534 - recall: 0.9165 - val_loss: 0.2211 - val_binary_accuracy: 0.9257 - val_precision: 0.9605 - val_recall: 0.8873\n",
      "Epoch 11/50\n",
      "616/616 [==============================] - 19s 32ms/step - loss: 0.1605 - binary_accuracy: 0.9484 - precision: 0.9609 - recall: 0.9336 - val_loss: 3.8502 - val_binary_accuracy: 0.8450 - val_precision: 0.8605 - val_recall: 0.8204\n",
      "Epoch 12/50\n",
      "616/616 [==============================] - 20s 32ms/step - loss: 1.1064 - binary_accuracy: 0.9066 - precision: 0.9283 - recall: 0.8773 - val_loss: 0.2527 - val_binary_accuracy: 0.9176 - val_precision: 0.9708 - val_recall: 0.8581\n",
      "Epoch 13/50\n",
      "616/616 [==============================] - 19s 31ms/step - loss: 0.1724 - binary_accuracy: 0.9422 - precision: 0.9577 - recall: 0.9234 - val_loss: 0.2195 - val_binary_accuracy: 0.9273 - val_precision: 0.9310 - val_recall: 0.9194\n",
      "Epoch 14/50\n",
      "616/616 [==============================] - 20s 32ms/step - loss: 0.1424 - binary_accuracy: 0.9551 - precision: 0.9653 - recall: 0.9438 - val_loss: 0.2433 - val_binary_accuracy: 0.9270 - val_precision: 0.9527 - val_recall: 0.8982\n",
      "Epoch 15/50\n",
      "616/616 [==============================] - 20s 32ms/step - loss: 0.1262 - binary_accuracy: 0.9616 - precision: 0.9699 - recall: 0.9521 - val_loss: 0.2025 - val_binary_accuracy: 0.9291 - val_precision: 0.9354 - val_recall: 0.9216\n",
      "Epoch 16/50\n",
      "616/616 [==============================] - 20s 32ms/step - loss: 0.1153 - binary_accuracy: 0.9658 - precision: 0.9722 - recall: 0.9579 - val_loss: 0.2475 - val_binary_accuracy: 0.9045 - val_precision: 0.8808 - val_recall: 0.9340\n",
      "Epoch 17/50\n",
      "616/616 [==============================] - 19s 32ms/step - loss: 0.1642 - binary_accuracy: 0.9482 - precision: 0.9653 - recall: 0.9281 - val_loss: 0.1457 - val_binary_accuracy: 0.9513 - val_precision: 0.9600 - val_recall: 0.9398\n",
      "Epoch 18/50\n",
      "616/616 [==============================] - 19s 32ms/step - loss: 0.1694 - binary_accuracy: 0.9526 - precision: 0.9712 - recall: 0.9318 - val_loss: 0.3725 - val_binary_accuracy: 0.8952 - val_precision: 0.9685 - val_recall: 0.8127\n",
      "Epoch 19/50\n",
      "616/616 [==============================] - 19s 31ms/step - loss: 0.1620 - binary_accuracy: 0.9507 - precision: 0.9749 - recall: 0.9238 - val_loss: 0.1997 - val_binary_accuracy: 0.9412 - val_precision: 0.9580 - val_recall: 0.9227\n",
      "Epoch 20/50\n",
      "616/616 [==============================] - 19s 32ms/step - loss: 0.1415 - binary_accuracy: 0.9580 - precision: 0.9723 - recall: 0.9421 - val_loss: 0.1950 - val_binary_accuracy: 0.9311 - val_precision: 0.9453 - val_recall: 0.9150\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0250000003725.\n",
      "Epoch 21/50\n",
      "616/616 [==============================] - 20s 32ms/step - loss: 0.0749 - binary_accuracy: 0.9790 - precision: 0.9857 - recall: 0.9716 - val_loss: 0.1371 - val_binary_accuracy: 0.9541 - val_precision: 0.9548 - val_recall: 0.9526\n",
      "Epoch 22/50\n",
      "616/616 [==============================] - 20s 32ms/step - loss: 0.0804 - binary_accuracy: 0.9781 - precision: 0.9851 - recall: 0.9702 - val_loss: 0.1174 - val_binary_accuracy: 0.9590 - val_precision: 0.9597 - val_recall: 0.9564\n",
      "Epoch 23/50\n",
      "616/616 [==============================] - 20s 33ms/step - loss: 0.0816 - binary_accuracy: 0.9761 - precision: 0.9838 - recall: 0.9675 - val_loss: 0.2004 - val_binary_accuracy: 0.9285 - val_precision: 0.9268 - val_recall: 0.9275\n",
      "Epoch 24/50\n",
      "616/616 [==============================] - 20s 32ms/step - loss: 0.1127 - binary_accuracy: 0.9793 - precision: 0.9862 - recall: 0.9718 - val_loss: 0.2068 - val_binary_accuracy: 0.9428 - val_precision: 0.9527 - val_recall: 0.9318\n",
      "Epoch 25/50\n",
      "616/616 [==============================] - 20s 32ms/step - loss: 0.0860 - binary_accuracy: 0.9795 - precision: 0.9853 - recall: 0.9729 - val_loss: 0.2053 - val_binary_accuracy: 0.9292 - val_precision: 0.9476 - val_recall: 0.9082\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0125000001863.\n",
      "Epoch 26/50\n",
      "616/616 [==============================] - 20s 32ms/step - loss: 0.0612 - binary_accuracy: 0.9848 - precision: 0.9899 - recall: 0.9791 - val_loss: 0.1440 - val_binary_accuracy: 0.9497 - val_precision: 0.9413 - val_recall: 0.9582\n",
      "Epoch 27/50\n",
      "616/616 [==============================] - 20s 32ms/step - loss: 0.0565 - binary_accuracy: 0.9837 - precision: 0.9887 - recall: 0.9781 - val_loss: 0.1006 - val_binary_accuracy: 0.9686 - val_precision: 0.9730 - val_recall: 0.9627\n",
      "Epoch 28/50\n",
      "616/616 [==============================] - 20s 32ms/step - loss: 0.0619 - binary_accuracy: 0.9825 - precision: 0.9891 - recall: 0.9754 - val_loss: 0.1732 - val_binary_accuracy: 0.9422 - val_precision: 0.9283 - val_recall: 0.9563\n",
      "Epoch 29/50\n",
      "616/616 [==============================] - 20s 32ms/step - loss: 0.0568 - binary_accuracy: 0.9860 - precision: 0.9902 - recall: 0.9813 - val_loss: 0.1705 - val_binary_accuracy: 0.9390 - val_precision: 0.9328 - val_recall: 0.9461\n",
      "Epoch 30/50\n",
      "616/616 [==============================] - 20s 32ms/step - loss: 0.0478 - binary_accuracy: 0.9870 - precision: 0.9911 - recall: 0.9825 - val_loss: 0.1552 - val_binary_accuracy: 0.9426 - val_precision: 0.9465 - val_recall: 0.9373\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.00625000009313.\n",
      "Epoch 31/50\n",
      "616/616 [==============================] - 20s 32ms/step - loss: 0.0425 - binary_accuracy: 0.9886 - precision: 0.9917 - recall: 0.9852 - val_loss: 0.1175 - val_binary_accuracy: 0.9581 - val_precision: 0.9503 - val_recall: 0.9659\n",
      "Epoch 32/50\n",
      "616/616 [==============================] - 20s 32ms/step - loss: 0.0410 - binary_accuracy: 0.9883 - precision: 0.9928 - recall: 0.9832 - val_loss: 0.0940 - val_binary_accuracy: 0.9663 - val_precision: 0.9564 - val_recall: 0.9760\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00032: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb0e443d970>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_tensorboard = True\n",
    "use_liveplots = False\n",
    "use_custom_callback = True\n",
    "use_early_stopping = True\n",
    "start_from_scratch = False\n",
    "use_reduced_lr = True\n",
    "log_data = True\n",
    "\n",
    "fit_args = helper.generate_fit_args(train_ds, val_ds, batch_size, \n",
    "                                         epochs, val_gen, use_tensorboard = use_tensorboard, \n",
    "                                         use_liveplots = use_liveplots, \n",
    "                                         use_custom_callback = use_custom_callback,\n",
    "                                         use_early_stopping = use_early_stopping,\n",
    "                                         use_reduced_lr = use_reduced_lr)\n",
    "\n",
    "model.fit(train_gen, **fit_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "digital-colon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /media/tord/T7/Thesis_ssd/MasterThesis3/SavedModels/CNN/best_noise-not-noise-model/assets\n"
     ]
    }
   ],
   "source": [
    "save_dir = '/media/tord/T7/Thesis_ssd/MasterThesis3/SavedModels/CNN'\n",
    "model_name = 'best_noise-not-noise-model'\n",
    "model_path = f'{save_dir}/{model_name}'\n",
    "\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "anticipated-sword",
   "metadata": {},
   "outputs": [],
   "source": [
    "#re_x_val = np.reshape(x_val, (x_val.shape[0], x_val.shape[2], x_val.shape[1]))\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "def predict_model(model, x_test, y_test, class_dict):\n",
    "    num_predictions = len(y_test)\n",
    "    #true_labels_str = np.empty(())\n",
    "    predictions = model.predict(x_test)\n",
    "    predictions = convert_to_class(predictions)\n",
    "    predictions = predictions[:len(x_test)]\n",
    "    return predictions\n",
    "        \n",
    "    \n",
    "def convert_to_class(predictions):\n",
    "    if predictions.shape[1] == 1:\n",
    "        predictions = np.rint(predictions)\n",
    "        return predictions\n",
    "    raise Exception(\"More than two classes has not been implemented\")\n",
    "    \n",
    "\n",
    "def evaluate_model(model, x_test, y_test, label_dict, plot = True, run_evaluate = False):\n",
    "    if evaluate:\n",
    "        loss, accuracy, precision, recall = model.evaluate(x = x_test, y = y_test)\n",
    "    \n",
    "    predictions = predict_model(model, x_test, y_test, label_dict)\n",
    "    predictions = np.reshape(predictions, (predictions.shape[0]))\n",
    "    y_test = np.reshape(y_test, (y_test.shape[0]))\n",
    "    conf = tf.math.confusion_matrix(y_test, predictions, num_classes=2)\n",
    "    class_report = classification_report(y_test, predictions, target_names = handle_non_noise_dict(label_dict))\n",
    "    if plot:\n",
    "        plot_confusion_matrix(conf, label_dict)\n",
    "    print(conf)\n",
    "    print(class_report)\n",
    "    \n",
    "    \n",
    "    return conf, class_report\n",
    "\n",
    "def plot_confusion_matrix(conf, label_dict):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(conf)\n",
    "    labels = list(handle_non_noise_dict(label_dict))\n",
    "    plt.title('Confusion matrix of the classifier')\n",
    "    fig.colorbar(cax)\n",
    "    ax.set_xticklabels([''] + labels)\n",
    "    ax.set_yticklabels([''] + labels)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    print(conf.shape)\n",
    "    for i in range(conf.shape[0]):\n",
    "        for j in range(conf.shape[1]):\n",
    "            text = ax.text(j, i, int(conf[i, j]), ha=\"center\", va=\"center\", color=\"r\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def handle_non_noise_dict(label_dict):\n",
    "    if len(list(set(label_dict.values()))) == 2 and len(list(label_dict.keys())) == 3:\n",
    "        label_dict = {'noise' : 0, 'not_noise' : 1}\n",
    "    return label_dict\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "unlike-advance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247/247 [==============================] - 1s 4ms/step - loss: 0.2890 - binary_accuracy: 0.9389 - precision: 0.9470 - recall: 0.9286\n",
      "(2, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-121-45728f55c9a3>:53: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + labels)\n",
      "<ipython-input-121-45728f55c9a3>:54: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([''] + labels)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[3779  203]\n",
      " [ 279 3629]], shape=(2, 2), dtype=int32)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       noise       0.93      0.95      0.94      3982\n",
      "   not_noise       0.95      0.93      0.94      3908\n",
      "\n",
      "    accuracy                           0.94      7890\n",
      "   macro avg       0.94      0.94      0.94      7890\n",
      "weighted avg       0.94      0.94      0.94      7890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conf, report = evaluate_model(model, re_x_val, y_val, loadData.label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "horizontal-chase",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[3779  203]\n",
      " [ 279 3629]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "mineral-shift",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       noise       0.93      0.95      0.94      3982\n",
      "   not_noise       0.95      0.93      0.94      3908\n",
      "\n",
      "    accuracy                           0.94      7890\n",
      "   macro avg       0.94      0.94      0.94      7890\n",
      "weighted avg       0.94      0.94      0.94      7890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-arabic",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
