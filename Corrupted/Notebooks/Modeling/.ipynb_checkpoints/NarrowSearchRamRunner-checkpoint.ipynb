{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "clean-columbus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "import pylab as pl\n",
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"0\" \n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import re\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "classes_dir = 'D:\\Thesis_ssd\\MasterThesis3.0'\n",
    "os.chdir(classes_dir)\n",
    "from Classes.DataProcessing.LoadData import LoadData\n",
    "from Classes.DataProcessing.HelperFunctions import HelperFunctions\n",
    "from Classes.DataProcessing.DataHandler import DataHandler\n",
    "from Classes.DataProcessing.TimeAugmentor import TimeAugmentor\n",
    "from Classes.Modeling.DynamicModels import DynamicModels\n",
    "from Classes.Modeling.StaticModels import StaticModels\n",
    "from Classes.Modeling.NarrowSearchRam import NarrowSearchRam\n",
    "from Classes.Modeling.CustomCallback import CustomCallback\n",
    "from Classes.Modeling.ResultFitter import ResultFitter\n",
    "from Classes.Scaling.ScalerFitter import ScalerFitter\n",
    "from Classes.Scaling.MinMaxScalerFitter import MinMaxScalerFitter\n",
    "from Classes.Scaling.StandardScalerFitter import StandardScalerFitter\n",
    "import json\n",
    "#from Classes import Tf_shutup\n",
    "#Tf_shutup.Tf_shutup()\n",
    "\n",
    "from livelossplot import PlotLossesKeras\n",
    "\n",
    "\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"]= (15,15)\n",
    "helper = HelperFunctions()\n",
    "\n",
    "import sys\n",
    "ISCOLAB = 'google.colab' in sys.modules\n",
    "\n",
    "import random\n",
    "import pprint\n",
    "\n",
    "base_dir = 'D:\\Thesis_ssd\\MasterThesis3.0'\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "orange-quarterly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping redundancy: [--------------------------------------->] 100 %\r"
     ]
    }
   ],
   "source": [
    "load_args = {\n",
    "    'earth_explo_only' : False,\n",
    "    'noise_earth_only' : False,\n",
    "    'noise_not_noise' : True,\n",
    "    'downsample' : True,\n",
    "    'upsample' : True,\n",
    "    'frac_diff' : 0.3,\n",
    "    'seed' : 1,\n",
    "    'subsample_size' : 0.4,\n",
    "    'balance_non_train_set' : True,\n",
    "    'use_true_test_set' : False\n",
    "}\n",
    "loadData = LoadData(**load_args)\n",
    "full_ds, train_ds, val_ds, test_ds = loadData.get_datasets()\n",
    "noise_ds = loadData.noise_ds\n",
    "handler = DataHandler(loadData)\n",
    "\n",
    "if load_args['earth_explo_only']:\n",
    "    full_and_noise_ds = np.concatenate((full_ds, noise_ds))\n",
    "    timeAug = TimeAugmentor(handler, full_and_noise_ds, seed = load_args['seed'])\n",
    "else:\n",
    "    timeAug = TimeAugmentor(handler, full_ds, seed = load_args['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "about-doctrine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33854 6771 4514\n",
      "All data:\n",
      "Total: 45139, earthquake: 15036, explosion: 14787, noise: 15316\n",
      "Train set:\n",
      "Total: 33854, earthquake: 11291, explosion: 11127, noise: 11436\n",
      "Validation set:\n",
      "Total: 6771, earthquake: 2230, explosion: 2210, noise: 2331\n",
      "Test set:\n",
      "Total: 4514, earthquake: 1515, explosion: 1450, noise: 1549\n",
      "Nr noise samples 11436\n"
     ]
    }
   ],
   "source": [
    "# Printing data stats:\n",
    "print(len(train_ds), len(val_ds), len(test_ds))\n",
    "print(\"All data:\")\n",
    "classes, counts = handler.get_class_distribution_from_ds(full_ds)\n",
    "print(\"Train set:\")\n",
    "classes, counts = handler.get_class_distribution_from_ds(train_ds)\n",
    "print(\"Validation set:\")\n",
    "classes, counts = handler.get_class_distribution_from_ds(val_ds)\n",
    "print(\"Test set:\")\n",
    "classes, counts = handler.get_class_distribution_from_ds(test_ds)\n",
    "print(\"Nr noise samples \" + str(len(loadData.noise_ds)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "advisory-tennis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detrend and highpass filters are not implemented in this class yet.\n"
     ]
    }
   ],
   "source": [
    "main_grid = {\n",
    "            \"num_layers\" : [2],\n",
    "            \"batch_size\" : [256],\n",
    "            \"epochs\" : [40],\n",
    "            \"learning_rate\" : [0.01],\n",
    "            \"optimizer\" : [\"sgd\"],\n",
    "            \"start_neurons\" : [4],\n",
    "            \"decay_sequence\" : [[1,2,4,6,8,10]],\n",
    "            \"dropout_rate\" : [0.3],\n",
    "            \"filters\" : [17],\n",
    "            \"kernel_size\" : [5],\n",
    "            \"padding\" : [\"same\"],\n",
    "            \"use_layerwise_dropout_batchnorm\" : [True],\n",
    "            \"l2_r\" : [0.001],\n",
    "            \"l1_r\" : [0.0001],\n",
    "            \"activation\" : [\"tanh\"],\n",
    "            \"output_layer_activation\" : [\"sigmoid\"]\n",
    "           }\n",
    "\n",
    "hyper_grid = {\n",
    "        \"num_layers\" : [3,4,5,6],\n",
    "        \"batch_size\" : [128, 512, 1028],\n",
    "        \"epochs\" : [40],\n",
    "        \"learning_rate\" : [0.1, 0.05, 0.025, 0.005],\n",
    "        \"optimizer\" : [\"sgd\"]\n",
    "    }\n",
    "model_grid = {\n",
    "    \"start_neurons\" : [2,4,6,7],\n",
    "    \"use_layerwise_dropout_batchnorm\" : [False, True],\n",
    "    \"decay_sequence\" : [[1,2,4,4,2,1], [1,4,8,8,4,1], [1,0.5,0.25,0.25,0.5,1], [1,1,1,1,1,1]],\n",
    "    \"dropout_rate\" : [0.3, 0.25, 0.2, 0.15, 0.1],\n",
    "    \"filters\" : [11],\n",
    "    \"kernel_size\" : [5],\n",
    "    \"padding\" : [\"same\"],\n",
    "    \"l2_r\" : [0.005, 0.001, 0.0005, 0.0001, 0],\n",
    "    \"l1_r\" : [0.0005, 0.0001, 0.00005],\n",
    "    \"activation\" : [\"tanh\"],\n",
    "    \"output_layer_activation\" : [\"sigmoid\"]\n",
    "}\n",
    "\n",
    "\n",
    "model_nr = \"LSTM\"\n",
    "is_lstm = True\n",
    "num_channels = 3\n",
    "\n",
    "use_time_augmentor = True\n",
    "use_scaler = True\n",
    "use_noise_augmentor = True\n",
    "detrend = False\n",
    "use_minmax = False\n",
    "use_highpass = False\n",
    "highpass_freq = 0.1\n",
    "\n",
    "use_tensorboard = False\n",
    "use_liveplots = True\n",
    "use_custom_callback = False\n",
    "use_early_stopping = True\n",
    "start_from_scratch = True\n",
    "\n",
    "narrowSearch = NarrowSearchRam(loadData, train_ds, val_ds, test_ds, model_nr, detrend, use_scaler, use_time_augmentor, \n",
    "                                    use_noise_augmentor, use_minmax, use_highpass, main_grid, hyper_grid, \n",
    "                                    model_grid, use_tensorboard = use_tensorboard,use_liveplots = use_liveplots, \n",
    "                                    use_custom_callback = use_custom_callback, use_early_stopping = use_early_stopping, \n",
    "                                    highpass_freq = highpass_freq, start_from_scratch = start_from_scratch, is_lstm = is_lstm,\n",
    "                                    num_channels = num_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "divine-relative",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_tensorboard_dir():\n",
    "    import os\n",
    "    import shutil\n",
    "    path = f\"{base_dir}/Tensorboard_dir/fit\"\n",
    "    files = os.listdir(path)\n",
    "    print(files)\n",
    "    for f in files:\n",
    "        shutil.rmtree(os.path.join(path,f))\n",
    "if use_tensorboard:\n",
    "    clear_tensorboard_dir()\n",
    "    %tensorboard --logdir tensorboard_dir/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-draft",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %\r",
      "Fitting time augmentor: [>                   ] 0 %"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit process completed after 606.5321826934814 seconds. Total datapoints fitted: 45139.\n",
      "Average time per datapoint: 0.013436987587086145\n",
      "[{'activation': 'tanh', [------------------> ] 99 %%\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 40,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.1,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 40,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.05,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 40,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.025,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 40,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.005,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 40,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0005,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 40,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 40,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 5e-05,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 4, 2, 1],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 40,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 4, 8, 8, 4, 1],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 40,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 0.5, 0.25, 0.25, 0.5, 1],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 40,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 1, 1, 1, 1, 1],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 40,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 128,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 40,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 512,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 40,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 1028,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 40,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 40,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.25,\n",
      "  'epochs': 40,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.2,\n",
      "  'epochs': 40,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.15,\n",
      "  'epochs': 40,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.1,\n",
      "  'epochs': 40,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 40,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.005,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 40,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 40,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.0005,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 40,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.0001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 40,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 40,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 2,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 40,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 40,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 6,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 40,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 7,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 40,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 3,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 40,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 4,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 40,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 5,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 40,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 6,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 40,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': False},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 40,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True}]\n",
      "Starting loading\n",
      "Starting loading\n",
      "Model nr 1 of 34\n",
      "[{'model_nr_type': 'LSTM', 'index': 0}, {'batch_size': 256, 'epochs': 40, 'learning_rate': 0.1, 'num_channels': 3, 'num_layers': 2, 'optimizer': 'sgd'}, {'activation': 'tanh', 'decay_sequence': [1, 2], 'dropout_rate': 0.3, 'filters': 17, 'kernel_size': 5, 'l1_r': 0.0001, 'l2_r': 0.001, 'output_layer_activation': 'sigmoid', 'padding': 'same', 'start_neurons': 4, 'use_layerwise_dropout_batchnorm': True}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Thesis_ssd\\MasterThesis3.0\\Classes\\Modeling\\GridSearchResultProcessor.py:96: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  temp_df = pd.DataFrame(np.array(picks).reshape(1,len(results_df.columns)), columns = results_df.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 6000, 4)           128       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 6000, 4)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 6000, 4)           16        \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 6000, 2)           56        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6000, 2)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 6000, 2)           8         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12000)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 12001     \n",
      "=================================================================\n",
      "Total params: 12,209\n",
      "Trainable params: 12,197\n",
      "Non-trainable params: 12\n",
      "_________________________________________________________________\n",
      "Starting: \n",
      "{   'batch_size': 256,\n",
      "    'epochs': 40,\n",
      "    'learning_rate': 0.1,\n",
      "    'num_channels': 3,\n",
      "    'num_layers': 2,\n",
      "    'optimizer': 'sgd'}\n",
      "---------------------------------------------------------------------------------\n",
      "{   'activation': 'tanh',\n",
      "    'decay_sequence': [1, 2],\n",
      "    'dropout_rate': 0.3,\n",
      "    'filters': 17,\n",
      "    'kernel_size': 5,\n",
      "    'l1_r': 0.0001,\n",
      "    'l2_r': 0.001,\n",
      "    'output_layer_activation': 'sigmoid',\n",
      "    'padding': 'same',\n",
      "    'start_neurons': 4,\n",
      "    'use_layerwise_dropout_batchnorm': True}\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 132 steps, validate for 26 steps\n",
      "Epoch 1/40\n"
     ]
    }
   ],
   "source": [
    "results_df, min_loss, max_accuracy, max_precision, max_recall = narrowSearch.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-provision",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
