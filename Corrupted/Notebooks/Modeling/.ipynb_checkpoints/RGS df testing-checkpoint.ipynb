{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pprint\n",
    "\n",
    "base_dir = 'C:\\Documents\\Thesis_ssd\\MasterThesis'\n",
    "os.chdir(base_dir)\n",
    "\n",
    "from Classes.DataProcessing.LoadData import LoadData\n",
    "from Classes.DataProcessing.BaselineHelperFunctions import BaselineHelperFunctions\n",
    "from Classes.DataProcessing.DataHandler import DataHandler\n",
    "from Classes.DataProcessing.DataGenerator import DataGenerator\n",
    "from Classes.Modeling.Models import Models\n",
    "from Classes.Modeling.RandomGridSearch import RandomGridSearch\n",
    "from Classes.Modeling.CustomCallback import CustomCallback\n",
    "from Classes.Scaling.ScalerFitter import ScalerFitter\n",
    "from Classes.Scaling.MinMaxScalerFitter import MinMaxScalerFitter\n",
    "from Classes.Scaling.StandardScalerFitter import StandardScalerFitter\n",
    "from Classes.Modeling.GridSearchResultProcessor import GridSearchResultProcessor\n",
    "import json\n",
    "\n",
    "helper = BaselineHelperFunctions()\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "loadData = LoadData(num_classes, isBalanced = True)\n",
    "shuffle = False\n",
    "full_ds, train_ds, val_ds, test_ds = loadData.getDatasets(shuffle = shuffle)\n",
    "handler = DataHandler()\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "helper = BaselineHelperFunctions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_grid = {\n",
    "        \"batch_size\" : [8, 16, 32, 64, 128, 256, 512],\n",
    "        \"epochs\" : [1],\n",
    "        \"learning_rate\" : [0.1, 0.01, 0.001, 0.0001, 0.00001],\n",
    "        \"optimizer\" : [\"adam\", \"rmsprop\", \"sgd\"]\n",
    "    }\n",
    "model_grid = {\n",
    "    \"activation\" : [\"relu\", \"sigmoid\", \"softmax\", \"tanh\"],\n",
    "    \"dropout_rate\" : [0.5, 0.4, 0.3, 0.2, 0.1, 0.01, 0],\n",
    "    \"filters\" : [11, 13, 15, 17, 19, 21, 23, 25],\n",
    "    \"kernel_size\" : [3, 5, 7, 9, 11, 13],\n",
    "    \"l1_r\" : [0.3, 0.2, 0.1, 0.01, 0.001, 0.0001],\n",
    "    \"l2_r\" : [0.3, 0.2, 0.1, 0.01, 0.001, 0.0001],\n",
    "    \"output_layer_activation\" : [\"softmax\", \"sigmoid\"],\n",
    "    \"padding\" : [\"same\"],\n",
    "    \"start_neurons\" : [8,16, 32, 64, 128, 256, 512, 1024]\n",
    "}\n",
    "\"\"\"\n",
    "{'activation': 'softmax', \n",
    " 'dropout_rate': 0.1, \n",
    " 'filters': 25, \n",
    " 'kernel_size': 9, \n",
    " 'l1_r': 0.01, \n",
    " 'l2_r': 0.0001, \n",
    " 'output_layer_activation': 'softmax', \n",
    " 'padding': 'same', \n",
    " 'start_neurons': 32}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "model_nr = 8\n",
    "\n",
    "test_mode = True\n",
    "use_scaler = False\n",
    "use_noise_augmentor = False\n",
    "detrend = False\n",
    "use_minmax = False\n",
    "use_highpass = False\n",
    "highpass_freq = 0.1\n",
    "\n",
    "n_picks = 2\n",
    "\n",
    "use_tensorboard = False\n",
    "use_liveplots = False\n",
    "use_custom_callback = False\n",
    "use_early_stopping = True\n",
    "start_from_scratch = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomGridSearch = RandomGridSearch(train_ds, val_ds, test_ds, model_nr, test_mode, detrend,\n",
    "                                    use_scaler, use_noise_augmentor, use_minmax, use_highpass, n_picks, \n",
    "                                    hyper_grid = hyper_grid, model_grid = model_grid, \n",
    "                                    num_classes = num_classes, use_tensorboard = use_tensorboard,\n",
    "                                    use_liveplots = use_liveplots, use_custom_callback = use_custom_callback,\n",
    "                                    use_early_stopping = use_early_stopping, highpass_freq = highpass_freq,\n",
    "                                    start_from_scratch = start_from_scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters stored before fit\n",
      "  batch_size epochs learning_rate optimizer activation dropout_rate filters  \\\n",
      "0         16      1         1e-05   rmsprop       relu          0.5      21   \n",
      "1         64      1           0.1   rmsprop       tanh            0      17   \n",
      "2          8      1         0.001      adam       relu            0      19   \n",
      "3         16      1           0.1   rmsprop       tanh          0.3      17   \n",
      "4        128      1          0.01   rmsprop    sigmoid          0.1      11   \n",
      "\n",
      "  kernel_size   l1_r    l2_r  ... padding start_neurons    train_loss  \\\n",
      "0          11    0.3     0.2  ...    same          1024  6.391216e+06   \n",
      "1           3    0.3  0.0001  ...    same           512  2.968888e+05   \n",
      "2          13  0.001     0.3  ...    same           512  3.610073e+07   \n",
      "3           3    0.1   0.001  ...    same           256  3.232169e+04   \n",
      "4          13    0.1    0.01  ...    same            32           NaN   \n",
      "\n",
      "   train_accuracy  train_precision  train_recall      val_loss  val_accuracy  \\\n",
      "0        0.569853         0.493274      0.101103  2.617363e+07      0.515625   \n",
      "1        0.499081         0.498630      0.501838  2.968889e+05      0.463542   \n",
      "2        0.554745         0.554745      0.554745  3.271793e+07      0.526042   \n",
      "3        0.499081         0.499081      0.499081  3.232224e+04      0.463542   \n",
      "4             NaN              NaN           NaN           NaN           NaN   \n",
      "\n",
      "   val_precision  val_recall  \n",
      "0       0.400000    0.093750  \n",
      "1       0.466321    0.468750  \n",
      "2       0.526042    0.526042  \n",
      "3       0.463542    0.463542  \n",
      "4            NaN         NaN  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (128, 3, 32)              772352    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (128, 3, 32)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (128, 3, 32)              128       \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (128, 3, 16)              3136      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (128, 3, 16)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (128, 3, 16)              64        \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (128, 3, 8)               136       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (128, 3, 8)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (128, 3, 8)               32        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (128, 24)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (128, 2)                  50        \n",
      "=================================================================\n",
      "Total params: 775,898\n",
      "Trainable params: 775,786\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n",
      "Starting: \n",
      "{'batch_size': 128, 'epochs': 1, 'learning_rate': 0.01, 'optimizer': 'rmsprop'}\n",
      "---------------------------------------------------------------------------------\n",
      "{   'activation': 'sigmoid',\n",
      "    'dropout_rate': 0.1,\n",
      "    'filters': 11,\n",
      "    'kernel_size': 13,\n",
      "    'l1_r': 0.1,\n",
      "    'l2_r': 0.01,\n",
      "    'output_layer_activation': 'softmax',\n",
      "    'padding': 'same',\n",
      "    'start_neurons': 32}\n",
      "8/8 [==============================] - 4s 518ms/step - loss: 798.7642 - accuracy: 0.4824 - precision: 0.4824 - recall: 0.4824 - val_loss: 447.4585 - val_accuracy: 0.5547 - val_precision: 0.5547 - val_recall: 0.5547\n",
      "WARNING:tensorflow:From C:\\Documents\\Thesis_ssd\\MasterThesis\\Classes\\Modeling\\RandomGridSearch.py:214: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.evaluate, which supports generators.\n",
      "{'train_loss': 447.5163269042969, 'train_accuracy': 0.5078125, 'train_precision': 0.5078125, 'train_recall': 0.5078125} {'val_loss': 447.4765625, 'val_accuracy': 0.5401041507720947, 'val_precision': 0.5401041507720947, 'val_recall': 0.5401041507720947}\n",
      "Parameters stored before fit\n",
      "  batch_size epochs learning_rate optimizer activation dropout_rate filters  \\\n",
      "0         16      1         1e-05   rmsprop       relu          0.5      21   \n",
      "1         64      1           0.1   rmsprop       tanh            0      17   \n",
      "2          8      1         0.001      adam       relu            0      19   \n",
      "3         16      1           0.1   rmsprop       tanh          0.3      17   \n",
      "4        128      1          0.01   rmsprop    sigmoid          0.1      11   \n",
      "5        256      1         1e-05      adam       tanh          0.4      23   \n",
      "\n",
      "  kernel_size   l1_r    l2_r  ... padding start_neurons    train_loss  \\\n",
      "0          11    0.3     0.2  ...    same          1024  6.391216e+06   \n",
      "1           3    0.3  0.0001  ...    same           512  2.968888e+05   \n",
      "2          13  0.001     0.3  ...    same           512  3.610073e+07   \n",
      "3           3    0.1   0.001  ...    same           256  3.232169e+04   \n",
      "4          13    0.1    0.01  ...    same            32  4.475163e+02   \n",
      "5           7    0.1  0.0001  ...    same            16           NaN   \n",
      "\n",
      "   train_accuracy  train_precision  train_recall      val_loss  val_accuracy  \\\n",
      "0        0.569853         0.493274      0.101103  2.617363e+07      0.515625   \n",
      "1        0.499081         0.498630      0.501838  2.968889e+05      0.463542   \n",
      "2        0.554745         0.554745      0.554745  3.271793e+07      0.526042   \n",
      "3        0.499081         0.499081      0.499081  3.232224e+04      0.463542   \n",
      "4        0.507812         0.507812      0.507812  4.474766e+02      0.540104   \n",
      "5             NaN              NaN           NaN           NaN           NaN   \n",
      "\n",
      "   val_precision  val_recall  \n",
      "0       0.400000    0.093750  \n",
      "1       0.466321    0.468750  \n",
      "2       0.526042    0.526042  \n",
      "3       0.463542    0.463542  \n",
      "4       0.540104    0.540104  \n",
      "5            NaN         NaN  \n",
      "\n",
      "[6 rows x 21 columns]\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (256, 3, 16)              385152    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (256, 3, 16)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (256, 3, 16)              64        \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (256, 3, 8)               800       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (256, 3, 8)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (256, 3, 8)               32        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (256, 3, 4)               36        \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (256, 3, 4)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (256, 3, 4)               16        \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (256, 12)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (256, 2)                  26        \n",
      "=================================================================\n",
      "Total params: 386,126\n",
      "Trainable params: 386,070\n",
      "Non-trainable params: 56\n",
      "_________________________________________________________________\n",
      "Starting: \n",
      "{'batch_size': 256, 'epochs': 1, 'learning_rate': 1e-05, 'optimizer': 'adam'}\n",
      "---------------------------------------------------------------------------------\n",
      "{   'activation': 'tanh',\n",
      "    'dropout_rate': 0.4,\n",
      "    'filters': 23,\n",
      "    'kernel_size': 7,\n",
      "    'l1_r': 0.1,\n",
      "    'l2_r': 0.0001,\n",
      "    'output_layer_activation': 'sigmoid',\n",
      "    'padding': 'same',\n",
      "    'start_neurons': 16}\n",
      "oof\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 825ms/step - loss: 614.4520 - accuracy: 0.5176 - precision_1: 0.5270 - recall_1: 0.5332 - val_loss: 613.3571 - val_accuracy: 0.4805 - val_precision_1: 0.4783 - val_recall_1: 0.4727\n",
      "{'train_loss': 613.35595703125, 'train_accuracy': 0.4912109375, 'train_precision': 0.4819159209728241, 'train_recall': 0.4814453125} {'val_loss': 613.3571166992188, 'val_accuracy': 0.48046875, 'val_precision': 0.47826087474823, 'val_recall': 0.47265625}\n",
      "----------------------------------------------------LOSS----------------------------------------------------------\n",
      "Min val loss: 447.4765625, at index: 4\n",
      "Min training loss: 447.5163269042969, at index: 4\n",
      "----------------------------------------------------ACCURACY------------------------------------------------------\n",
      "Highest val accuracy: 0.5401041507720947, at index: 4\n",
      "Highest training accuracy: 0.569852948189, at index: 0\n",
      "----------------------------------------------------PRECISION-----------------------------------------------------\n",
      "Highest val precision: 0.5401041507720947, at index: 4\n",
      "Highest training precision: 0.554744541645, at index: 2\n",
      "-----------------------------------------------------RECALL-------------------------------------------------------\n",
      "Highest val recall: 0.554744541645, at index: 4\n",
      "Highest training recall: 0.554744541645, at index: 2\n",
      "------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "results, highest_test_accuracy_index, highest_train_accuracy_index, highest_test_precision_index, highest_test_recall_index= randomGridSearch.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = randomGridSearch.results_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>activation</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>filters</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>l1_r</th>\n",
       "      <th>l2_r</th>\n",
       "      <th>output_layer_activation</th>\n",
       "      <th>padding</th>\n",
       "      <th>start_neurons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>same</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>same</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>adam</td>\n",
       "      <td>relu</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>softmax</td>\n",
       "      <td>same</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>softmax</td>\n",
       "      <td>same</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.1</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>softmax</td>\n",
       "      <td>same</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>adam</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.4</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>same</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  batch_size epochs learning_rate optimizer activation dropout_rate filters  \\\n",
       "0         16      1         1e-05   rmsprop       relu          0.5      21   \n",
       "1         64      1           0.1   rmsprop       tanh            0      17   \n",
       "2          8      1         0.001      adam       relu            0      19   \n",
       "3         16      1           0.1   rmsprop       tanh          0.3      17   \n",
       "4        128      1          0.01   rmsprop    sigmoid          0.1      11   \n",
       "5        256      1         1e-05      adam       tanh          0.4      23   \n",
       "\n",
       "  kernel_size   l1_r    l2_r output_layer_activation padding start_neurons  \n",
       "0          11    0.3     0.2                 sigmoid    same          1024  \n",
       "1           3    0.3  0.0001                 sigmoid    same           512  \n",
       "2          13  0.001     0.3                 softmax    same           512  \n",
       "3           3    0.1   0.001                 softmax    same           256  \n",
       "4          13    0.1    0.01                 softmax    same            32  \n",
       "5           7    0.1  0.0001                 sigmoid    same            16  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[results_df.columns[0:13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.391216e+06</td>\n",
       "      <td>0.569853</td>\n",
       "      <td>0.493274</td>\n",
       "      <td>0.101103</td>\n",
       "      <td>2.617363e+07</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.968888e+05</td>\n",
       "      <td>0.499081</td>\n",
       "      <td>0.498630</td>\n",
       "      <td>0.501838</td>\n",
       "      <td>2.968889e+05</td>\n",
       "      <td>0.463542</td>\n",
       "      <td>0.466321</td>\n",
       "      <td>0.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.610073e+07</td>\n",
       "      <td>0.554745</td>\n",
       "      <td>0.554745</td>\n",
       "      <td>0.554745</td>\n",
       "      <td>3.271793e+07</td>\n",
       "      <td>0.526042</td>\n",
       "      <td>0.526042</td>\n",
       "      <td>0.526042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.232169e+04</td>\n",
       "      <td>0.499081</td>\n",
       "      <td>0.499081</td>\n",
       "      <td>0.499081</td>\n",
       "      <td>3.232224e+04</td>\n",
       "      <td>0.463542</td>\n",
       "      <td>0.463542</td>\n",
       "      <td>0.463542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.475163e+02</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>4.474766e+02</td>\n",
       "      <td>0.540104</td>\n",
       "      <td>0.540104</td>\n",
       "      <td>0.540104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.133560e+02</td>\n",
       "      <td>0.491211</td>\n",
       "      <td>0.481916</td>\n",
       "      <td>0.481445</td>\n",
       "      <td>6.133571e+02</td>\n",
       "      <td>0.480469</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.472656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     train_loss  train_accuracy  train_precision  train_recall      val_loss  \\\n",
       "0  6.391216e+06        0.569853         0.493274      0.101103  2.617363e+07   \n",
       "1  2.968888e+05        0.499081         0.498630      0.501838  2.968889e+05   \n",
       "2  3.610073e+07        0.554745         0.554745      0.554745  3.271793e+07   \n",
       "3  3.232169e+04        0.499081         0.499081      0.499081  3.232224e+04   \n",
       "4  4.475163e+02        0.507812         0.507812      0.507812  4.474766e+02   \n",
       "5  6.133560e+02        0.491211         0.481916      0.481445  6.133571e+02   \n",
       "\n",
       "   val_accuracy  val_precision  val_recall  \n",
       "0      0.515625       0.400000    0.093750  \n",
       "1      0.463542       0.466321    0.468750  \n",
       "2      0.526042       0.526042    0.526042  \n",
       "3      0.463542       0.463542    0.463542  \n",
       "4      0.540104       0.540104    0.540104  \n",
       "5      0.480469       0.478261    0.472656  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[results_df.columns[13:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "''# Remove dependence on num_classes and model nr\n",
    "def fit_from_index(self, results_df, index):\n",
    "    values = list(results_df.iloc[index][1:14])\n",
    "    keys = list(results_df.columns[1:14])\n",
    "    params = {keys[i]: values[i] for i in range(len(keys))}\n",
    "    \n",
    "    build_model_args = self.helper.generate_build_model_args(self.model_nr, params['batch_size'], \n",
    "                                                             params['dropout_rate'], params['activation'], \n",
    "                                                             params['output_layer_activation'],params['l2_r'], \n",
    "                                                             params['l1_r'], params['start_neurons'],\n",
    "                                                             params['filters'], params['kernel_size'],\n",
    "                                                             params['padding'], self.num_classes)\n",
    "    # Build model using args generated above\n",
    "    model = Models(**build_model_args).model\n",
    "    \n",
    "    # Generate generator args using picks.\n",
    "    gen_args = self.helper.generate_gen_args(params['batch_size'], self.test, self.detrend, \n",
    "                                             use_scaler = self.use_scaler, scaler = self.scaler, \n",
    "                                             use_noise_augmentor = self.use_noise_augmentor, \n",
    "                                             augmentor = self.augmentor, num_classes = self.num_classes)\n",
    "    \n",
    "    # Initiate generators using the args\n",
    "    train_gen = self.data_gen.data_generator(self.train_ds, **gen_args)\n",
    "    val_gen = self.data_gen.data_generator(self.val_ds, **gen_args)\n",
    "    test_gen = self.data_gen.data_generator(self.test_ds, **gen_args)\n",
    "    \n",
    "    # Generate compiler args using picks\n",
    "    opt = self.getOptimizer(params['optimizer'], params['learning_rate'])\n",
    "    model_compile_args = self.helper.generate_model_compile_args(params['opt'], self.num_classes)\n",
    "    # Compile model using generated args\n",
    "    model.compile(**model_compile_args)\n",
    "    \n",
    "    # Generate fit args using picks.\n",
    "    fit_args = self.helper.generate_fit_args(train_ds, self.val_ds, params['batch_size'], self.test, \n",
    "                                             params['epoch'], test_gen, use_tensorboard = self.use_tensorboard, \n",
    "                                             use_liveplots = self.use_liveplots, \n",
    "                                             use_custom_callback = self.use_custom_callback,\n",
    "                                             use_early_stopping = self.use_early_stopping)\n",
    "    # Fit the model using the generated args\n",
    "    model_fit = model.fit(train_gen, **fit_args)\n",
    "    \n",
    "    helper.plot_confusion_matrix(model_fit, test_gen, self.test_ds, params['batch_size'], self.num_classes)\n",
    "    \n",
    "    # Evaluate the fitted model on the test set\n",
    "    loss, accuracy, precision, recall = model.evaluate_generator(generator=test_gen,\n",
    "                                                               steps=self.helper.get_steps_per_epoch(self.test_ds, \n",
    "                                                                                                     params['batch_size'], \n",
    "                                                                                                     False))\n",
    "    \n",
    "    pp = pprint.PrettyPrinter(indent=4)\n",
    "    print(f'Test loss: {loss}')\n",
    "    print(f'Test accuracy: {accuracy}')\n",
    "    print(f'Test precision: {precision}')\n",
    "    print(f'Test recall: {recall}')\n",
    "    return model_fit\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 1, 'learning_rate': 1e-05, 'optimizer': 'rmsprop', 'activation': 'relu', 'dropout_rate': 0.5, 'filters': 21, 'kernel_size': 11, 'l1_r': 0.3, 'l2_r': 0.2, 'output_layer_activation': 'sigmoid', 'padding': 'same', 'start_neurons': 1024, 'train_loss': 6391216.0}\n"
     ]
    }
   ],
   "source": [
    "fit_from_index(results_df, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_model_args = self.helper.generate_build_model_args(self.model_nr, batch_size, dropout_rate, \n",
    "                                                                     activation, output_layer_activation,\n",
    "                                                                     l2_r, l1_r, start_neurons, filters, kernel_size, \n",
    "                                                                     padding, self.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomGridSearch.find_best_performers(loaded_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_performers(results_df):\n",
    "    train_loss_index = results_df.columns.get_loc('train_loss')\n",
    "    metrics = results_df[results_df.columns[train_loss_index:]]\n",
    "    min_loss = {'train_loss' : min(metrics['train_loss']), 'val_loss' : min(metrics['val_loss']), \n",
    "                'train_index' : metrics_df[metrics_df['train_loss'] == min(metrics_df['train_loss'])].index[0], \n",
    "                'val_index' : metrics_df[metrics_df['val_loss'] == min(metrics_df['val_loss'])].index[0]}\n",
    "    \n",
    "    max_accuracy = {'train_accuracy' : max(metrics['train_accuracy']), 'val_accuracy' : max(metrics['val_accuracy']), \n",
    "                    'train_index' : metrics_df[metrics_df['train_accuracy'] == max(metrics_df['train_accuracy'])].index[0], \n",
    "                    'val_index' : metrics_df[metrics_df['val_accuracy'] == max(metrics_df['val_accuracy'])].index[0]}\n",
    "    \n",
    "    max_precision = {'train_precision' : max(metrics['train_precision']), 'val_precision' : max(metrics['val_precision']), \n",
    "                     'train_index' : metrics_df[metrics_df['train_precision'] == max(metrics_df['train_precision'])].index[0], \n",
    "                     'val_index' : metrics_df[metrics_df['val_precision'] == max(metrics_df['val_precision'])].index[0]}\n",
    "    \n",
    "    max_recall = {'train_recall' : max(metrics['train_recall']), 'val_recall' : max(metrics['train_recall']), \n",
    "                  'train_index' : metrics_df[metrics_df['train_recall'] == max(metrics_df['train_recall'])].index[0], \n",
    "                  'val_index' : metrics_df[metrics_df['val_recall'] == max(metrics_df['val_recall'])].index[0]}\n",
    "    \n",
    "    return min_loss, max_accuracy, max_precision, max_recall\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_performers(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(keys)\n",
    "print(keys2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "hyper_keys = list(hyper_grid.keys())\n",
    "model_keys = list(model_grid.keys())\n",
    "metrics_train_keys = [\"train_loss\", \"train_accuracy\", \"train_presicion\", \"train_recall\"]\n",
    "metrics_val_keys = [\"val_loss\", \"val_accuracy\", \"val_presicion\", \"val_recall\"]\n",
    "header = np.concatenate((hyper_keys, model_keys, metrics_train_keys, metrics_val_keys))\n",
    "info_table = pd.DataFrame(np.array([i for i in range(len(header))]).reshape(1, 21) ,columns = header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = pd.DataFrame([[0, np.nan]], columns = [\"a\", \"b\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_add = pd.DataFrame(np.array([0 ,1]).reshape(1,2), columns = [\"a\", \"b\"])\n",
    "print(to_add)\n",
    "testing = testing.append(to_add)\n",
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_columns = testing.columns[testing.isnull().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_columns = temp_df.columns[temp_df.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_cols = [i for i in temp_df.columns if pd.isnull(temp_df[i].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in temp_df.columns:\n",
    "    print(temp_df[column].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df['val_loss'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
