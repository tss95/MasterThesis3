{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py as h5\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "earthquake_samples = 'earthquake_sample_events.h5'\n",
    "explosion_samples = 'explosion_sample_events.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create mixed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mixed_dataset(earthquake_dataset, explosion_dataset):\n",
    "    with h5py.File(earthquake_dataset, 'r') as fin:\n",
    "        earthquake_info_dataset = fin.get('event_info')\n",
    "        earthquake_trace_dataset = fin.get('traces')\n",
    "        print(type(earthquake_info_dataset))\n",
    "        print(type(earthquake_trace_dataset))\n",
    "\n",
    "        # Convert to numpy arrays\n",
    "        earthquake_info = np.array(earthquake_info_dataset)\n",
    "        earthquake_trace = np.array(earthquake_trace_dataset)\n",
    "    event_type = (earthquake_dataset.split('_'))[0]\n",
    "    print(f'Loaded {earthquake_info.shape[0]} {event_type}s')\n",
    "    \n",
    "    with h5py.File(explosion_dataset, 'r') as fin:\n",
    "        explosion_info_dataset = fin.get('event_info')\n",
    "        explosion_trace_dataset = fin.get('traces')\n",
    "\n",
    "        # Convert to numpy arrays\n",
    "        explosion_info = np.array(explosion_info_dataset)\n",
    "        explosion_trace = np.array(explosion_trace_dataset)\n",
    "    event_type = (explosion_dataset.split('_'))[0]\n",
    "    print(f'Loaded {explosion_info.shape[0]} {event_type}s')\n",
    "    \n",
    "    # Mixing:\n",
    "    n = explosion_info.shape[0] + earthquake_info.shape[0]\n",
    "    mixed_info = np.empty((n,), dtype = type(earthquake_info))\n",
    "    k,d = earthquake_trace.shape[1:3]\n",
    "    mixed_trace = np.empty((n,k,d), dtype = type(earthquake_trace))\n",
    "    \n",
    "    i = 0\n",
    "    for j in range(len(explosion_info)):\n",
    "        mixed_info[i] = explosion_info[j]\n",
    "        mixed_trace[i] = explosion_trace[j]\n",
    "        i += 1\n",
    "    for k in range(len(earthquake_info)):\n",
    "        mixed_info[i] = earthquake_info[k]\n",
    "        mixed_trace[i] = earthquake_trace[k]\n",
    "        i += 1\n",
    "        \n",
    "    randomize = np.arange(len(mixed_info))\n",
    "    np.random.shuffle(randomize)\n",
    "    mixed_info = mixed_info[randomize]\n",
    "    mixed_trace = mixed_trace[randomize]\n",
    "    return explosion_info, earthquake_info, explosion_trace, earthquake_trace, mixed_info, mixed_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'h5py._hl.dataset.Dataset'>\n",
      "<class 'h5py._hl.dataset.Dataset'>\n",
      "Loaded 152 earthquakes\n",
      "Loaded 198 explosions\n"
     ]
    }
   ],
   "source": [
    " explosion_info, earthquake_info, explosion_trace, earthquake_trace, mixed_info, mixed_trace = create_mixed_dataset(earthquake_samples, explosion_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_test_ratio = 0.8\n",
    "seed = 69420\n",
    "\n",
    "train_trace, test_trace, train_info, test_info = train_test_split(mixed_trace, mixed_info, train_size = 0.8, random_state= seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(dataset, file_name, save_path):\n",
    "    np.save(save_path + '/' + file_name + '.npy', dataset)\n",
    "    print(f\"Saved to: {save_path}/{file_name}.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'train_test_mixed'\n",
    "train_folder = f'{root}/train'\n",
    "test_folder = f'{root}/test'\n",
    "mixed_folder = f'{root}/mixed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: train_test_mixed/train/train_info.npy\n",
      "Saved to: train_test_mixed/train/train_trace.npy\n"
     ]
    }
   ],
   "source": [
    "train_info_name = 'train_info'\n",
    "train_trace_name = 'train_trace'\n",
    "save_data(train_info, train_info_name, train_folder)\n",
    "save_data(train_trace, train_trace_name, train_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: train_test_mixed/test/test_info.npy\n",
      "Saved to: train_test_mixed/test/test_trace.npy\n"
     ]
    }
   ],
   "source": [
    "test_info_name = 'test_info'\n",
    "test_trace_name = 'test_trace'\n",
    "save_data(test_info, test_info_name, test_folder)\n",
    "save_data(test_trace, test_trace_name, test_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: train_test_mixed/mixed/mixed_info.npy\n",
      "Saved to: train_test_mixed/mixed/mixed_trace.npy\n"
     ]
    }
   ],
   "source": [
    "mixed_info_name = 'mixed_info'\n",
    "mixed_trace_name = 'mixed_trace'\n",
    "save_data(mixed_info, mixed_info_name, mixed_folder)\n",
    "save_data(mixed_trace, mixed_trace_name, mixed_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folders:\n",
    "root = 'train_test_mixed'\n",
    "train_folder = f'{root}/train/'\n",
    "test_folder = f'{root}/test/'\n",
    "mixed_folder = f'{root}/mixed/'\n",
    "\n",
    "earthquake_samples = 'earthquake_sample_events.h5'\n",
    "explosion_samples = 'explosion_sample_events.h5'\n",
    "\n",
    "# Mixed, train, test sets:\n",
    "mixed_info = np.load(mixed_folder + 'mixed_info.npy', allow_pickle=True)\n",
    "mixed_trace = np.load(mixed_folder + 'mixed_trace.npy', allow_pickle=True)\n",
    "\n",
    "train_info = np.load(train_folder + 'train_info.npy', allow_pickle=True)\n",
    "train_trace = np.load(train_folder + 'train_trace.npy', allow_pickle=True)\n",
    "\n",
    "test_info = np.load(test_folder + 'test_info.npy', allow_pickle=True)\n",
    "test_trace = np.load(test_folder + 'test_trace.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding filters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_tracer(stream):\n",
    "    # Remove 'trend', e.g. remove linear offset from 0:\n",
    "    stream.detrend('demean')\n",
    "\n",
    "    # Taper the traces, meaning the ends will go gradually to 0 -- this is required before filtering\n",
    "    stream.taper(max_percentage=0.05, type='cosine')\n",
    "\n",
    "    # Apply a bandpass filter, selecting frequencies from 3 to 5 Hz\n",
    "    stream.filter('bandpass', freqmin=3.0, freqmax=5.0)\n",
    "    return stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stream(tracer, info):\n",
    "    info = json_loads(info)\n",
    "    station = info['trace_stats']['station']\n",
    "    channels = info['trace_stats']['channels']\n",
    "    sampl_rate = info['trace_stats']['sampling_rate']\n",
    "\n",
    "    trace_BHE = Trace(\n",
    "        data=tracer[0],\n",
    "        header={\n",
    "            'station': station,\n",
    "            'channel': channels[0],\n",
    "            'sampling_rate': sampl_rate,\n",
    "            'starttime': start_time\n",
    "        }\n",
    "    )\n",
    "    trace_BHN = Trace(\n",
    "        data=tracer[0],\n",
    "        header={\n",
    "            'station': station,\n",
    "            'channel': channels[1],\n",
    "            'sampling_rate': sampl_rate, \n",
    "            'starttime': start_time\n",
    "        }\n",
    "    )\n",
    "    trace_BHZ = Trace(\n",
    "        data=tracer[0],\n",
    "        header={\n",
    "            'station': station,\n",
    "            'channel': channels[2],\n",
    "            'sampling_rate': sampl_rate,\n",
    "            'starttime': start_time\n",
    "        }\n",
    "    )\n",
    "    # Assemple into a Stream\n",
    "    stream = Stream([trace_BHE, trace_BHN, trace_BHZ])\n",
    "    return stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_every_tracer(tracer_set, info_set):\n",
    "    streams = np.empty((tracer_set.shape), dtype=type(tracer_set))\n",
    "    for idx, tracer in enumerate(tracer_set):\n",
    "        streams[idx] = filter_tracer(create_stream(tracer, info_set[idx]))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FastAI 2",
   "language": "python",
   "name": "fastai2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
