{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from dateutil import parser\n",
    "\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "from obspy import Stream, Trace, UTCDateTime\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "import pylab as pl\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import datetime\n",
    "import keras\n",
    "\n",
    "from keras.layers import Activation, Conv1D, Dense, Dropout, Flatten, MaxPooling3D, BatchNormalization, InputLayer, LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.models import Sequential\n",
    "from keras.utils import Sequence\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import re\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import os\n",
    "import sys\n",
    "classes_dir = 'F:\\Thesis_ssd\\MasterThesis3.0'\n",
    "os.chdir(classes_dir)\n",
    "from Classes.DataProcessing.LoadData import LoadData\n",
    "from Classes.DataProcessing.HelperFunctions import HelperFunctions\n",
    "from Classes.DataProcessing.DataHandler import DataHandler\n",
    "from Classes.DataProcessing.DataGenerator import DataGenerator\n",
    "from Classes.DataProcessing.NoiseAugmentor import NoiseAugmentor\n",
    "from Classes.Modeling.Models import Models\n",
    "from Classes.Modeling.CustomCallback import CustomCallback\n",
    "from Classes.Scaling.ScalerFitter import ScalerFitter\n",
    "from Classes.Scaling.MinMaxScalerFitter import MinMaxScalerFitter\n",
    "from Classes.Scaling.StandardScalerFitter import StandardScalerFitter\n",
    "from Classes import Tf_shutup\n",
    "Tf_shutup.Tf_shutup()\n",
    "\n",
    "from livelossplot import PlotLossesKeras\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"]= (15,15)\n",
    "helper = HelperFunctions()\n",
    "\n",
    "import sys\n",
    "ISCOLAB = 'google.colab' in sys.modules\n",
    "\n",
    "import random\n",
    "import pprint\n",
    "\n",
    "base_dir = 'F:\\Thesis_ssd\\MasterThesis3.0'\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data conditions: ###\n",
    "load_args = {\n",
    "    'earth_explo_only' : True,\n",
    "    'noise_earth_only' : False,\n",
    "    'downsample' : True,\n",
    "    'upsample' : True,\n",
    "    'frac_diff' : 0.5,\n",
    "    'seed' : 1,\n",
    "    'subsample_size' : 0.05\n",
    "}\n",
    "\n",
    "loadData = LoadData(**load_args)\n",
    "\n",
    "full_ds, train_ds, val_ds, test_ds = loadData.get_datasets()\n",
    "noise_ds = loadData.noise_ds\n",
    "handler = DataHandler(loadData)\n",
    "data_gen = DataGenerator(loadData)\n",
    "full_and_noise_ds = np.concatenate((full_ds, noise_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5198 459 459\n",
      "Total: 5198, earthquake: 2620, explosion: 2578\n",
      "Nr noise samples 2635\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ds), len(val_ds), len(test_ds))\n",
    "classes, counts = handler.get_class_distribution_from_ds(train_ds)\n",
    "print(\"Nr noise samples \" + str(len(loadData.noise_ds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace, info = handler.path_to_trace(train_ds[train_ds[:,1] == \"earthquake\"][0][0])\n",
    "some_eq = train_ds[train_ds[:,1] == \"earthquake\"][4][0]\n",
    "some_ex = train_ds[train_ds[:,1] == \"explosion\"][2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-04-12 11:11:00.317330\n",
      "2015-04-12 11:12:31.441000\n",
      "3644.9468\n"
     ]
    }
   ],
   "source": [
    "start_time = parser.isoparse(info['origins'][0]['time']).replace(tzinfo=None)\n",
    "print(start_time)\n",
    "event_time = parser.isoparse(info['est_arrivaltime_arces'])\n",
    "print(event_time)\n",
    "sampling_rate = info['trace_stats']['sampling_rate']\n",
    "\n",
    "relative_event_time = event_time - start_time\n",
    "relative_seconds = relative_event_time.total_seconds()\n",
    "initial_index = relative_seconds*sampling_rate\n",
    "print(initial_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_initial_event_index(path):\n",
    "    trace, info = handler.path_to_trace(path)\n",
    "    start_time = parser.isoparse(info['trace_stats']['starttime']).replace(tzinfo=None)\n",
    "    if info['analyst_pick_time'] != None:\n",
    "        event_time = parser.isoparse(info['analyst_pick_time']).replace(tzinfo=None)\n",
    "    else:\n",
    "        event_time = parser.isoparse(info['est_arrivaltime_arces']).replace(tzinfo=None)\n",
    "    sampling_rate = info['trace_stats']['sampling_rate']\n",
    "    relative_seconds = (event_time - start_time).total_seconds()\n",
    "    # Problem with uncertainty: Some events have very large uncertainty.\n",
    "    # This can be so high that the interesting event could have potentially occured prior to the recording.\n",
    "    if 'time_errors' in info['origins'][0]:\n",
    "        uncertainty = float(info['origins'][0]['time_errors']['uncertainty'])\n",
    "    else:\n",
    "        uncertainty = 0\n",
    "    initial_index = max(math.floor((relative_seconds-uncertainty)*sampling_rate),0)\n",
    "\n",
    "    return initial_index, trace, info\n",
    "\n",
    "def shift_event(path):\n",
    "    initial_index, trace, info = find_initial_event_index(path)\n",
    "    pre_length = trace.shape[1]\n",
    "    random_start_index = np.random.randint(0, 5000)\n",
    "    augmented_trace = np.empty((3, 6000))\n",
    "    interesting_part_length = pre_length - initial_index\n",
    "    # Handling what happens when the duration of the interesting event is shorter than what is needed to fill the array:\n",
    "    ideal_length = augmented_trace.shape[1] - random_start_index\n",
    "    missing_length = ideal_length - interesting_part_length\n",
    "    if missing_length > 0:\n",
    "        filler_index_start = np.random.randint(0, (initial_index - missing_length))\n",
    "        filler_index_end = filler_index_start + missing_length\n",
    "        # First index of what requires more filling\n",
    "        required_fill_index_start = augmented_trace.shape[1] - missing_length\n",
    "    \n",
    "    for i in range(augmented_trace.shape[0]):\n",
    "        augmented_trace[i][0:random_start_index] = trace[i][0:random_start_index]\n",
    "        augmented_trace[i][random_start_index:random_start_index + interesting_part_length] = trace[i][initial_index: initial_index + (augmented_trace.shape[1] - random_start_index)]\n",
    "        if missing_length > 0:\n",
    "            augmented_trace[i][required_fill_index_start:augmented_trace.shape[1]] = trace[i][filler_index_start:filler_index_end]\n",
    "\n",
    "    return augmented_trace, info\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeAugmentor():\n",
    "    \n",
    "    def __init__(self, DataHandler, ds, seed = None):\n",
    "        self.handler = DataHandler\n",
    "        self.ds = ds\n",
    "        self.fitted_dict = {}\n",
    "        self.seed = seed\n",
    "             \n",
    "    def fit(self):\n",
    "        path_ds = self.ds[:,0]\n",
    "        len_ds = len(path_ds)\n",
    "        _,_,pre_length = self.handler.get_trace_shape_no_cast(self.ds, True)\n",
    "        post_length = 6000\n",
    "        if self.seed != None:\n",
    "            np.random.seed(self.seed)\n",
    "        for idx, path in enumerate(path_ds):\n",
    "            self.progress_bar(idx + 1, len_ds)\n",
    "            initial_index, info = self.find_initial_event_index(path)\n",
    "            random_start_index = np.random.randint(0, 5000)\n",
    "            interesting_part_length = pre_length - initial_index\n",
    "            # Handling what happens when the duration of the interesting event is shorter than what is needed to fill the array:\n",
    "            ideal_length = post_length - random_start_index\n",
    "            missing_length = ideal_length - interesting_part_length\n",
    "            # Only interesting for events where we need to fill in at the end:\n",
    "            # Problem occurs if initial_index - missing_length  < 0.\n",
    "            if initial_index - missing_length <= 0:\n",
    "                filler_index = 0\n",
    "            else: \n",
    "                filler_index_start = np.random.randint(0, (initial_index - missing_length))\n",
    "            filler_index_end = filler_index_start + missing_length\n",
    "            # First index of what requires more filling\n",
    "            required_fill_index_start = post_length - missing_length\n",
    "            self.fitted_dict[path] = { 'initial_index' : initial_index,\n",
    "                                       'random_start_index' : random_start_index,\n",
    "                                       'interesting_part_length' : interesting_part_length,\n",
    "                                       'missing_length' : missing_length,\n",
    "                                       'filler_index_start' : filler_index_start,\n",
    "                                       'filler_index_end' : filler_index_end,\n",
    "                                       'required_fill_index_start' : required_fill_index_start}\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    def augment_event(self, path):\n",
    "        trace, info = self.handler.path_to_trace(path)\n",
    "        fit = self.fitted_dict[path]\n",
    "        augmented_trace = np.empty((3, 6000))\n",
    "        for i in range(augmented_trace.shape[0]):\n",
    "            augmented_trace[i] = self.fill_start(trace, augmented_trace, fit['random_start_index'], fit['initial_index'], i)\n",
    "            augmented_trace[i] = self.fill_interesting_part(trace, augmented_trace, fit['random_start_index'], fit['interesting_part_length'], fit['initial_index'], i)\n",
    "            if fitted_args['missing_length'] > 0:\n",
    "                augmented_trace[i] = fill_lacking_ends(trace, augmented_trace, fit['random_start_index'], fit['interesting_part_length'], i)\n",
    "        return augmented_trace\n",
    "    \n",
    "    def fill_start(self, trace, augmented_trace, random_start_index, initial_index, i_channel):\n",
    "        if random_start_index < initial_index:\n",
    "            augmented_trace[i_channel][0:random_start_index] = trace[i_channel][0:random_start_index]\n",
    "            return augmented_trace[i_channel]\n",
    "        else:\n",
    "            augmented_trace[i_channel][0:initial_index] = trace[i_channel][0:initial_index]\n",
    "            trace_interval_start = trace.shape[1] - random_start_index\n",
    "            trace_interval_end = trace.shape[1]\n",
    "            augmented_trace[i_channel][initial_index:random_start_index] = trace[i_channel][trace_interval_start:trace_interval_end]\n",
    "            return augmented_trace[i_channel]\n",
    "\n",
    "    def fill_interesting_part(self, trace, augmented_trace, random_start_index, interesting_length, initial_index, i_channel):\n",
    "        aug_interval_end = min(random_start_index + interesting_length, augmented_trace.shape[1])\n",
    "        trace_interval_end = min(initial_index + interesting_length, trace.shape[1])\n",
    "        augmented_trace[i_channel][random_start_index:aug_interval_end] = trace[i_channel][initial_index:trace_interval_end]\n",
    "        return augmented_trace[i_channel]\n",
    "        \n",
    "    def fill_lacking_ends(self, trace, augmented_trace, random_start_index, missing_length, i_channel)\n",
    "        fill_interval_start = random_start_index\n",
    "        fill_interval_end = random_start_index + missing_length\n",
    "        augmented_trace[i_channel][augmented_trace.shape[1] - missing_length:augmented_trace.shape[1]] = trace[i_channel][fill_interval_start:fill_interval_end]\n",
    "        return augmented_trace[i_channel]\n",
    "    \n",
    "\n",
    "    def find_initial_event_index(self, path):\n",
    "        _, info = self.handler.path_to_trace(path)\n",
    "        start_time = parser.isoparse(info['trace_stats']['starttime']).replace(tzinfo=None)\n",
    "        if info['analyst_pick_time'] != None:\n",
    "            event_time = parser.isoparse(info['analyst_pick_time']).replace(tzinfo=None)\n",
    "        else:\n",
    "            event_time = parser.isoparse(info['est_arrivaltime_arces']).replace(tzinfo=None)\n",
    "        sampling_rate = info['trace_stats']['sampling_rate']\n",
    "        relative_seconds = (event_time - start_time).total_seconds()\n",
    "        # Problem with uncertainty: Some events have very large uncertainty.\n",
    "        # This can be so high that the interesting event could have potentially occured prior to the recording.\n",
    "        uncertainty = 0\n",
    "        if 'origins' in info:\n",
    "            if 'time_errors' in info['origins'][0]:\n",
    "                uncertainty = float(info['origins'][0]['time_errors']['uncertainty'])\n",
    "            \n",
    "        initial_index = max(math.floor((relative_seconds-uncertainty)*sampling_rate),0)\n",
    "\n",
    "        return initial_index, info\n",
    "    \n",
    "    def progress_bar(self, current, total, barLength = 20):\n",
    "        percent = float(current) * 100 / total\n",
    "        arrow   = '-' * int(percent/100 * barLength - 1) + '>'\n",
    "        spaces  = ' ' * (barLength - len(arrow))\n",
    "        print('Fitting time augmentor: [%s%s] %d %%' % (arrow, spaces, percent), end='\\r')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeAug = TimeAugmentor(handler, full_and_noise_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting time augmentor: [------------------->] 100 %\r"
     ]
    }
   ],
   "source": [
    "timeAug.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'initial_index': 2396, 'random_start_index': 3086, 'interesting_part_length': 3604, 'missing_length': -690, 'filler_index_start': 1791, 'filler_index_end': 1101, 'required_fill_index_start': 6690}\n"
     ]
    }
   ],
   "source": [
    "print(timeAug.fitted_dict[full_and_noise_ds[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:/Thesis_ssd\\norsar_data_nov\\explosions\\2017-03-20T17.33.25.059000Z.h5\n",
      "F:/Thesis_ssd\\norsar_data_nov\\explosions\\2016-11-12T12.36.11.162000Z.h5\n",
      "F:/Thesis_ssd\\norsar_data_nov\\earthquakes\\2011-05-25T16.56.34.766000Z.h5\n",
      "F:/Thesis_ssd\\norsar_data_nov\\explosions\\2009-10-31T23.07.12.884000Z.h5\n",
      "F:/Thesis_ssd\\norsar_data_nov\\earthquakes\\2015-12-12T00.39.30.177000Z.h5\n",
      "F:/Thesis_ssd\\norsar_data_nov\\explosions\\2012-06-21T23.28.46.719000Z.h5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (4408) into shape (3617)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-0230ada93339>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfull_and_noise_ds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimeAug\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maugment_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-0a6c33ee3728>\u001b[0m in \u001b[0;36maugment_event\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0maugmented_trace\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mfitted_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'random_start_index'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mfitted_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'random_start_index'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;31m# augmented_trace[random:så_langt_som_mulig] = original[interesting_index:fra interesting_index til så langt som mulig]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[0maugmented_trace\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfitted_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'random_start_index'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfitted_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'random_start_index'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfitted_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'interesting_part_length'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maugmented_trace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfitted_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'initial_index'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfitted_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'initial_index'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maugmented_trace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfitted_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'random_start_index'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfitted_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'initial_index'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfitted_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'missing_length'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m                 \u001b[0maugmented_trace\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfitted_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'required_fill_index_start'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0maugmented_trace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfitted_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'filler_index_start'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mfitted_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'filler_index_end'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (4408) into shape (3617)"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "i = 0\n",
    "for path, label in full_and_noise_ds:\n",
    "    print(path)\n",
    "    _ = timeAug.augment_event(path)\n",
    "    i += 1\n",
    "    \n",
    "end = time.time()\n",
    "print(end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "for i in range(1000):\n",
    "    train_aug.augment_event(train_aug.ds[i][0])\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_trace, no_info = handler.path_to_trace(noise_ds[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(no_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_trace, shift_info = shift_event(broken_eq)\n",
    "print(shift_trace.shape)\n",
    "plot_event(shift_trace, shift_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_index, trace, info = find_initial_event_index(broken_eq)\n",
    "print(initial_index)\n",
    "pprint.pprint(info)\n",
    "start_time = parser.isoparse(info['trace_stats']['starttime']).replace(tzinfo=None)\n",
    "event_time = parser.isoparse(info['est_arrivaltime_arces']).replace(tzinfo=None)\n",
    "\n",
    "relative_event_time = event_time - start_time\n",
    "relative_seconds = relative_event_time.total_seconds()\n",
    "initial_index = math.floor(relative_seconds*sampling_rate)\n",
    "print(initial_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace, info = handler.path_to_trace(some_eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_event(trace, info):\n",
    "    start_time = info['origins'][0]['time']\n",
    "    channels = info['trace_stats']['channels']\n",
    "    sampl_rate = info['trace_stats']['sampling_rate']\n",
    "    station = info['trace_stats']['station']\n",
    "    \n",
    "    trace_BHE = Trace(\n",
    "    data=trace[0],\n",
    "    header={\n",
    "        'station': station,\n",
    "        'channel': channels[0],\n",
    "        'sampling_rate': sampl_rate,\n",
    "        'starttime': start_time})\n",
    "    trace_BHN = Trace(\n",
    "        data=trace[1],\n",
    "        header={\n",
    "            'station': station,\n",
    "            'channel': channels[1],\n",
    "            'sampling_rate': sampl_rate, \n",
    "            'starttime': start_time})\n",
    "    trace_BHZ = Trace(\n",
    "        data=trace[2],\n",
    "        header={\n",
    "            'station': station,\n",
    "            'channel': channels[2],\n",
    "            'sampling_rate': sampl_rate,\n",
    "            'starttime': start_time})\n",
    "    stream = Stream([trace_BHE, trace_BHN, trace_BHZ])\n",
    "    stream.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_trace, eq_info = handler.path_to_trace(broken_eq)\n",
    "plot_event(eq_trace, eq_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "#pprint.pprint(eq_info)\n",
    "\n",
    "start_time = parser.isoparse(eq_info['origins'][0]['time']).replace(tzinfo=None)\n",
    "print(start_time)\n",
    "event_time = parser.isoparse(eq_info['est_arrivaltime_arces'])\n",
    "print(event_time)\n",
    "sampling_rate = eq_info['trace_stats']['sampling_rate']\n",
    "\n",
    "relative_event_time = event_time - start_time\n",
    "relative_seconds = relative_event_time.total_seconds()\n",
    "initial_index = relative_seconds*sampling_rate\n",
    "print(initial_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'analyst_pick_time': None,\n",
    " 'az_to_arces': 41.29157761552466,\n",
    " 'baz_to_arces': 242.79234883014138,\n",
    " 'dist_to_arces': 1361.1977383995043,\n",
    " 'est_arrivaltime_arces': '2015-07-11 01:41:33.470000',\n",
    " 'event_type': 'earthquake',\n",
    " 'event_type_certainty': 'known',\n",
    " 'magnitude_dist_ratio': 0.0016536906699879804,\n",
    " 'magnitude_sqrtdist_ratio': 0.06101194717547493,\n",
    " 'magnitudes': [{'mag': 2.251,\n",
    "                 'magnitude_type': 'Mb',\n",
    "                 'origin_id': 'smi:local/b6237688-ee4d-44b5-8391-aab180d33332',\n",
    "                 'resource_id': 'smi:local/f08083f1-46d9-46a6-b8b3-35887f2ec6c8'},\n",
    "                {'mag': 1.5,\n",
    "                 'magnitude_type': 'Ml',\n",
    "                 'origin_id': 'smi:local/b6237688-ee4d-44b5-8391-aab180d33332',\n",
    "                 'resource_id': 'smi:local/1508237c-eaaf-4960-a436-983d144f2d9f'}],\n",
    " 'origins': [{'arrivals': [{'azimuth': 264.66301,\n",
    "                            'backazimuth_residual': -999.0,\n",
    "                            'comments': [{'resource_id': 'smi:local/7ac38599-9ba0-4e0c-aea4-2290b48d30cb',\n",
    "                                          'text': 'ARID=51420'}],\n",
    "                            'horizontal_slowness_residual': -999.0,\n",
    "                            'phase': 'Sn',\n",
    "                            'pick_id': 'smi:local/d94f53b6-fd78-4cb1-b667-ccfb9707a7f5',\n",
    "                            'resource_id': 'smi:local/c6c341ab-4e1d-4a9d-9c96-984b42494173',\n",
    "                            'time_residual': -1.8494183},\n",
    "                           {'azimuth': 282.0618,\n",
    "                            'backazimuth_residual': -999.0,\n",
    "                            'comments': [{'resource_id': 'smi:local/ff495e37-8457-465f-ad71-fe3e77104707',\n",
    "                                          'text': 'ARID=51421'}],\n",
    "                            'horizontal_slowness_residual': -999.0,\n",
    "                            'phase': 'Lg',\n",
    "                            'pick_id': 'smi:local/82afdaf6-d6bc-4714-a4ff-354414093e48',\n",
    "                            'resource_id': 'smi:local/bb7a84e7-0564-4b21-8478-16c4832466a9',\n",
    "                            'time_residual': 1.1276108},\n",
    "                           {'azimuth': 282.0618,\n",
    "                            'backazimuth_residual': -999.0,\n",
    "                            'comments': [{'resource_id': 'smi:local/a302aaf7-9011-476d-a23c-edbb4e8a5b5c',\n",
    "                                          'text': 'ARID=51422'}],\n",
    "                            'horizontal_slowness_residual': -999.0,\n",
    "                            'phase': 'Pn',\n",
    "                            'pick_id': 'smi:local/07debc07-cd08-4b21-b13a-16dcfd1da725',\n",
    "                            'resource_id': 'smi:local/62eb3b10-9c50-4dfe-b02a-8f2ff0363214',\n",
    "                            'time_residual': 0.25156139},\n",
    "                           {'azimuth': 284.69384,\n",
    "                            'backazimuth_residual': -999.0,\n",
    "                            'comments': [{'resource_id': 'smi:local/66f2c26b-6702-4017-a5f8-ceb39a04614e',\n",
    "                                          'text': 'ARID=51423'}],\n",
    "                            'horizontal_slowness_residual': -999.0,\n",
    "                            'phase': 'Lg',\n",
    "                            'pick_id': 'smi:local/ecbb394d-9bda-4e33-b376-5bf8f34c832c',\n",
    "                            'resource_id': 'smi:local/15cf1963-8d4e-4c38-b10c-2c0a7ece25c4',\n",
    "                            'time_residual': -5.8988919},\n",
    "                           {'azimuth': 292.078,\n",
    "                            'backazimuth_residual': -7.9011668,\n",
    "                            'comments': [{'resource_id': 'smi:local/4df857e9-6dbe-4a3e-a83a-5670f0cb5996',\n",
    "                                          'text': 'ARID=51424'}],\n",
    "                            'horizontal_slowness_residual': -2.9234867,\n",
    "                            'phase': 'Pn',\n",
    "                            'pick_id': 'smi:local/6cfd16e9-84df-4550-8c73-f32ae3491857',\n",
    "                            'resource_id': 'smi:local/f8265085-af25-4a1e-9fbb-71fabf376b5f',\n",
    "                            'time_residual': 1.6930018},\n",
    "                           {'azimuth': 288.05724,\n",
    "                            'backazimuth_residual': 6.9927645,\n",
    "                            'comments': [{'resource_id': 'smi:local/7fc66aa8-846d-4762-bbcb-f375e85a80ff',\n",
    "                                          'text': 'ARID=5058921'}],\n",
    "                            'horizontal_slowness_residual': -2.034051,\n",
    "                            'phase': 'Pn',\n",
    "                            'pick_id': 'smi:local/cff348ea-3317-4d75-a250-0e8b1849ce64',\n",
    "                            'resource_id': 'smi:local/0f937e25-7e3d-4875-8614-6fd9b695e353',\n",
    "                            'time_residual': -1.915003},\n",
    "                           {'azimuth': 288.05724,\n",
    "                            'backazimuth_residual': 6.7627645,\n",
    "                            'comments': [{'resource_id': 'smi:local/834fd3c3-b535-4ead-a9d9-142df3281a34',\n",
    "                                          'text': 'ARID=5058927'}],\n",
    "                            'horizontal_slowness_residual': -4.6857037,\n",
    "                            'phase': 'Sn',\n",
    "                            'pick_id': 'smi:local/dad73d32-4ede-41c7-ab7f-d2e3ab2fe7f3',\n",
    "                            'resource_id': 'smi:local/3fc34832-7f0d-43de-b4ea-7e56e79c15ae',\n",
    "                            'time_residual': -2.5075625},\n",
    "                           {'azimuth': 292.078,\n",
    "                            'backazimuth_residual': 4.4870482,\n",
    "                            'comments': [{'resource_id': 'smi:local/691a9f56-f432-44aa-890c-a8655d5aa1c2',\n",
    "                                          'text': 'ARID=5058929'}],\n",
    "                            'horizontal_slowness_residual': -2.9264298,\n",
    "                            'phase': 'Sn',\n",
    "                            'pick_id': 'smi:local/d56bdfa0-6279-47b8-a3cb-7dc87dcc6c0c',\n",
    "                            'resource_id': 'smi:local/b1d9dbaa-022b-4e71-b19e-dfa7c06709a3',\n",
    "                            'time_residual': 1.001216},\n",
    "                           {'azimuth': 284.69384,\n",
    "                            'backazimuth_residual': 1.2061596,\n",
    "                            'comments': [{'resource_id': 'smi:local/73ada222-ba66-48ba-a785-8a6583de6099',\n",
    "                                          'text': 'ARID=10127282'}],\n",
    "                            'horizontal_slowness_residual': -0.81531174,\n",
    "                            'phase': 'Pn',\n",
    "                            'pick_id': 'smi:local/eaf9d35d-8ba4-40fd-8705-1f6b63437fdf',\n",
    "                            'resource_id': 'smi:local/373414b5-6913-4289-8ea8-467e5ab77843',\n",
    "                            'time_residual': -0.21510253},\n",
    "                           {'azimuth': 284.69384,\n",
    "                            'backazimuth_residual': 1.0061596,\n",
    "                            'comments': [{'resource_id': 'smi:local/9b1335dc-8aec-486b-9465-43c842f4de66',\n",
    "                                          'text': 'ARID=10127283'}],\n",
    "                            'horizontal_slowness_residual': 0.56019928,\n",
    "                            'phase': 'Sn',\n",
    "                            'pick_id': 'smi:local/eff7d55f-b22c-45e7-92d0-01c28a0f7057',\n",
    "                            'resource_id': 'smi:local/615bbab1-0b7b-4f11-a647-7674f7979815',\n",
    "                            'time_residual': -1.3685685},\n",
    "                           {'azimuth': 40.515957,\n",
    "                            'backazimuth_residual': -999.0,\n",
    "                            'comments': [{'resource_id': 'smi:local/40f0d608-238a-4e8a-9fe2-732ffe51fb84',\n",
    "                                          'text': 'ARID=51416'}],\n",
    "                            'horizontal_slowness_residual': -999.0,\n",
    "                            'phase': 'Sn',\n",
    "                            'pick_id': 'smi:local/6c08b2e3-cd1f-400b-8095-3e0aa4175dea',\n",
    "                            'resource_id': 'smi:local/95f8c1f5-385d-478a-bcf8-095486341c8d',\n",
    "                            'time_residual': -2.1312188},\n",
    "                           {'azimuth': 40.515957,\n",
    "                            'backazimuth_residual': -999.0,\n",
    "                            'comments': [{'resource_id': 'smi:local/806ef43b-c39d-4aa7-b9de-8b6cbe98c3e7',\n",
    "                                          'text': 'ARID=51417'}],\n",
    "                            'horizontal_slowness_residual': -999.0,\n",
    "                            'phase': 'Pn',\n",
    "                            'pick_id': 'smi:local/8ff5e958-ea0f-4faa-b7a4-c2cbadf082be',\n",
    "                            'resource_id': 'smi:local/bd705fc0-e532-42bd-8679-7028c10823ca',\n",
    "                            'time_residual': -0.37866468},\n",
    "                           {'azimuth': 291.30956,\n",
    "                            'backazimuth_residual': -999.0,\n",
    "                            'comments': [{'resource_id': 'smi:local/ca39da24-9dfe-40d1-82ac-ac5bfa0e6204',\n",
    "                                          'text': 'ARID=51418'}],\n",
    "                            'horizontal_slowness_residual': -999.0,\n",
    "                            'phase': 'Sn',\n",
    "                            'pick_id': 'smi:local/5824c4b2-8301-49b3-bd1a-1ce4c5b2ac68',\n",
    "                            'resource_id': 'smi:local/c4b47394-8454-4d4a-982d-3ba35befe6b3',\n",
    "                            'time_residual': 1.046918},\n",
    "                           {'azimuth': 291.30956,\n",
    "                            'backazimuth_residual': -999.0,\n",
    "                            'comments': [{'resource_id': 'smi:local/17a767f9-9038-47f8-a1a0-5a89be4d0cfd',\n",
    "                                          'text': 'ARID=51419'}],\n",
    "                            'horizontal_slowness_residual': -999.0,\n",
    "                            'phase': 'Pn',\n",
    "                            'pick_id': 'smi:local/8039d945-a7d6-46a1-9fda-a38979441c28',\n",
    "                            'resource_id': 'smi:local/6513e828-e166-426f-945e-3d90822ef121',\n",
    "                            'time_residual': 1.2761877}],\n",
    "              'comments': [{'resource_id': 'smi:local/32ee4897-2203-4182-b36f-dd11d8cfd4e9',\n",
    "                            'text': 'orid: 18827'}],\n",
    "              'creation_info': {'agency_id': 'NORSAR',\n",
    "                                'author': 'ARS:berit',\n",
    "                                'creation_time': '2015-08-10T12:23:51.000000Z'},\n",
    "              'depth': 6.8413744,\n",
    "              'depth_errors': {'uncertainty': 22.255111},\n",
    "              'latitude': 61.869417,\n",
    "              'longitude': 2.026115,\n",
    "              'quality': {'associated_phase_count': 14, 'used_phase_count': 14},\n",
    "              'resource_id': 'smi:local/b6237688-ee4d-44b5-8391-aab180d33332',\n",
    "              'time': '2015-07-11T01:38:04.055310Z',\n",
    "              'time_errors': {'uncertainty': 5.1670545}}],\n",
    " 'resource_id': 'smi:local/a73ab6ac-291e-4a98-91a6-e39e9309673e',\n",
    " 'trace_stats': {'channels': ['P-beam, vertical',\n",
    "                              'S-beam, transverse',\n",
    "                              'S-beam, radial'],\n",
    "                 'sampling_rate': 40.0,\n",
    "                 'starttime': '2015-07-11T01:40:33.475000Z',\n",
    "                 'station': 'ARCES beam'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Which time should i look at?\n",
    " - The time uncertainty is in seconds, right?\n",
    " - How long does earthquakes recorded by ARCES normally last?\n",
    " - Some uncertainties are so high that the event could have occured prior to recording. For events such as this I assume that the event starts at index = 0.\n",
    " - Some events lack uncertainty measure.\n",
    " - What does est_arrivaltime_arces actually mean? Assumed it meant event_start_time but then I saw noise has the same statistic.\n",
    " - Can I use noise augmentation when training a model which does not classify noise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "     Likely depreciated due to new fitting method.\n",
    "         \n",
    "    def find_initial_event_index(self, path):\n",
    "        trace, info = self.handler.path_to_trace(path)\n",
    "        start_time = parser.isoparse(info['trace_stats']['starttime']).replace(tzinfo=None)\n",
    "        if info['analyst_pick_time'] != None:\n",
    "            event_time = parser.isoparse(info['analyst_pick_time']).replace(tzinfo=None)\n",
    "        else:\n",
    "            event_time = parser.isoparse(info['est_arrivaltime_arces']).replace(tzinfo=None)\n",
    "        sampling_rate = info['trace_stats']['sampling_rate']\n",
    "        relative_seconds = (event_time - start_time).total_seconds()\n",
    "        # Problem with uncertainty: Some events have very large uncertainty.\n",
    "        # This can be so high that the interesting event could have potentially occured prior to the recording.\n",
    "        if 'time_errors' in info['origins'][0]:\n",
    "            uncertainty = float(info['origins'][0]['time_errors']['uncertainty'])\n",
    "        else:\n",
    "            uncertainty = 0\n",
    "        initial_index = max(math.floor((relative_seconds-uncertainty)*sampling_rate),0)\n",
    "\n",
    "        return initial_index, trace, info\n",
    "\n",
    "    def shift_event(self, path):\n",
    "        initial_index, trace, info = self.find_initial_event_index(path)\n",
    "        pre_length = trace.shape[1]\n",
    "        random_start_index = np.random.randint(0, 5000)\n",
    "        augmented_trace = np.empty((3, 6000))\n",
    "        interesting_part_length = pre_length - initial_index\n",
    "        # Handling what happens when the duration of the interesting event is shorter than what is needed to fill the array:\n",
    "        ideal_length = augmented_trace.shape[1] - random_start_index\n",
    "        missing_length = ideal_length - interesting_part_length\n",
    "        if missing_length > 0:\n",
    "            filler_index_start = np.random.randint(0, (initial_index - missing_length))\n",
    "            filler_index_end = filler_index_start + missing_length\n",
    "            # First index of what requires more filling\n",
    "            required_fill_index_start = augmented_trace.shape[1] - missing_length\n",
    "\n",
    "        for i in range(augmented_trace.shape[0]):\n",
    "            augmented_trace[i][0:random_start_index] = trace[i][0:random_start_index]\n",
    "            augmented_trace[i][random_start_index:random_start_index + interesting_part_length] = trace[i][initial_index: initial_index + (augmented_trace.shape[1] - random_start_index)]\n",
    "            if missing_length > 0:\n",
    "                augmented_trace[i][required_fill_index_start:augmented_trace.shape[1]] = trace[i][filler_index_start:filler_index_end]\n",
    "\n",
    "        return augmented_trace\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
