{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py as h5\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "import random\n",
    "import pprint\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'C:\\Documents\\Thesis_ssd\\data_tord_may2020'\n",
    "csv_folder = 'C:\\Documents\\Thesis_ssd\\MasterThesis-2.0\\csv_folder'\n",
    "explo_path = f'{root}/explosions/'\n",
    "earth_path = f'{root}/earthquakes/'\n",
    "noise_path = f'{root}/noise/'\n",
    "induced_path = f'{root}/induced/'\n",
    "data_csv = 'event_paths_no_nan_no_induced_no_explosions.csv'\n",
    "balanced_csv = 'balanced_csv_2_class.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_event_csv(root, csv_name, output_folder = csv_folder):\n",
    "    with open(output_folder + '/' + csv_name, 'w+', newline='') as file:\n",
    "        writer = csv.writer(file, delimiter = ' ', quotechar = '|', quoting = csv.QUOTE_MINIMAL)\n",
    "        \n",
    "        for event_type in os.listdir(root):\n",
    "            if event_type == 'induced' or event_type == 'explosions':\n",
    "                continue\n",
    "            event_list = os.listdir(root+'/'+event_type)\n",
    "            for event in event_list:\n",
    "                path = f'{root}/{event_type}/{event}'\n",
    "                trace_array, label, info = path_to_trace(path)\n",
    "                if np.any(pd.isnull(trace_array)):\n",
    "                    continue\n",
    "                if label == \"induced or triggered event\" or label == \"explosion\":\n",
    "                    continue\n",
    "                else:\n",
    "                    writer.writerow([f'{root}/{event_type}/{event},{label}'])\n",
    "            print(f'Completed {event_type}')\n",
    "    print(\"Completed \" + csv_name)\n",
    "    \n",
    "def csv_to_numpy(data_csv, csv_folder = csv_folder):\n",
    "    nr_rows = 0\n",
    "    with open(csv_folder + '/' + data_csv, 'r') as file:\n",
    "        csv_reader = csv.reader(file, delimiter = ',')\n",
    "        nr_rows = len(list(csv_reader))\n",
    "    dataset = np.empty((nr_rows, 2), dtype=object)\n",
    "    with open(csv_folder + '/' + data_csv, 'r') as file:\n",
    "        csv_reader = csv.reader(file, delimiter = ',')\n",
    "        idx = 0\n",
    "        for row in csv_reader:\n",
    "            dataset[idx][0] = row[0]\n",
    "            dataset[idx][1] = row[1]\n",
    "            idx += 1\n",
    "        np.random.shuffle(dataset)\n",
    "        return dataset\n",
    "    \n",
    "def path_to_trace(path):\n",
    "    trace_array = np.empty((3,6001))\n",
    "    with h5py.File(path, 'r') as dp:\n",
    "        trace_array[:3] = dp.get('traces')\n",
    "        info = np.array(dp.get('event_info'))\n",
    "        info = json.loads(str(info))\n",
    "    # No event type for noise, so handling that below\n",
    "    if path.split('/')[1] == 'noise':\n",
    "        label = 'noise'\n",
    "    else:\n",
    "        label = info['event_type']\n",
    "    # Since we consider induced earthquakes as earthquakes we need to handle that as well:\n",
    "    if label == \"induced or triggered event\":\n",
    "        label = \"earthquake\"\n",
    "    return trace_array, label, info\n",
    "\n",
    "def assert_true_labels(ds):\n",
    "    for path, label in ds:\n",
    "        _, label_from_trace, _ = path_to_trace(path)\n",
    "        if label_from_trace != 'noise':\n",
    "            label_from_trace = label_from_trace + 's'\n",
    "            label = label + 's'\n",
    "        assert path.split('/')[1] == label == label_from_trace, f'Mismatch between {path.split(\"/\")[1]} and {label} and {label_from_trace}, at path: {path}'\n",
    "\n",
    "\n",
    "def get_class_distribution_from_csv(data_csv, csv_folder = csv_folder):\n",
    "    with open(csv_folder + '/' + data_csv) as file:\n",
    "        nr_earthquakes = 0\n",
    "        nr_explosions = 0\n",
    "        nr_noise = 0\n",
    "        nr_total = 0\n",
    "        for row in file:\n",
    "            event_type = row.split(',')[1].rstrip()\n",
    "            if event_type == \"earthquake\":\n",
    "                nr_earthquakes += 1\n",
    "            elif event_type == \"explosion\":\n",
    "                nr_explosions += 1\n",
    "            elif event_type == \"noise\":            \n",
    "                nr_noise += 1\n",
    "            nr_total += 1\n",
    "        \n",
    "        return nr_earthquakes, nr_explosions, nr_noise, nr_total\n",
    "    \n",
    "\n",
    "def even_classes_csv(data_csv, balanced_csv_name, output_folder = csv_folder):\n",
    "    nr_earthquakes, nr_explosions, nr_noise, nr_total = get_class_distribution_from_csv(data_csv)\n",
    "    min_class_nr = min([nr_earthquakes, nr_noise])\n",
    "    print(min_class_nr)\n",
    "    csv_numpy = csv_to_numpy(data_csv)\n",
    "    class_count = [0,0,0]\n",
    "    earthquake_list = []\n",
    "    noise_list = []\n",
    "    final_class_count = []\n",
    "    for path, label in csv_numpy:\n",
    "        if label == \"earthquake\":\n",
    "            earthquake_list.append([path,label])\n",
    "            class_count[0] += 1\n",
    "            class_count[2] += 1\n",
    "        if label == \"noise\":\n",
    "            noise_list.append([path,label])\n",
    "            class_count[1] += 1\n",
    "            class_count[2] += 1\n",
    "    pure_classes = [earthquake_list, noise_list]\n",
    "    print(len(pure_classes[0]))\n",
    "    with open(output_folder + '/' + balanced_csv_name, 'w+', newline='') as file:\n",
    "        writer = csv.writer(file, delimiter = ' ', quotechar = '|', quoting = csv.QUOTE_MINIMAL)\n",
    "        for single_class in pure_classes:\n",
    "            print(f'Sample_size = {min_class_nr} single_class length: {len(single_class)}' )\n",
    "            random_samples = random.sample(single_class, min_class_nr)\n",
    "            final_class_count.append(len(random_samples))\n",
    "            for path, label in random_samples:\n",
    "                writer.writerow([f'{path},{label}'])\n",
    "        print(final_class_count)\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "def generate_subset_csv(input_ds, output_csv_name, output_folder):\n",
    "    nr_rows = len(input_ds)\n",
    "    with open(output_folder + '/' + output_csv_name, 'w+', newline='') as file:\n",
    "        writer = csv.writer(file, delimiter = ',', quotechar = ' ', quoting = csv.QUOTE_MINIMAL)\n",
    "        for row in input_ds:\n",
    "            writer.writerow(row)\n",
    "    print(f'Completed writing {nr_rows} rows to {output_folder}/{output_csv_name}.')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed earthquakes\n",
      "Completed noise\n",
      "Completed event_paths_no_nan_no_induced_no_explosions.csv\n"
     ]
    }
   ],
   "source": [
    "generate_event_csv(root, data_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earthquakes: 6852, Explosions: 0, Noise: 91612, Total: 98464\n"
     ]
    }
   ],
   "source": [
    "nr_eq, nr_ex, nr_noise, nr_total = get_class_distribution_from_csv(data_csv)\n",
    "print(f'Earthquakes: {nr_eq}, Explosions: {nr_ex}, Noise: {nr_noise}, Total: {nr_total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6852\n",
      "6852\n",
      "Sample_size = 6852 single_class length: 6852\n",
      "Sample_size = 6852 single_class length: 91612\n",
      "[6852, 6852]\n"
     ]
    }
   ],
   "source": [
    "# Generate balanced data csv using data_csv:\n",
    "even_classes_csv(data_csv, balanced_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = csv_to_numpy(balanced_csv)\n",
    "\n",
    "train_ds, test_val_ds = train_test_split(ds, test_size = 0.2)\n",
    "val_ds, test_ds = train_test_split(test_val_ds, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10963 1918 823\n",
      "13704\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ds), len(val_ds), len(test_ds))\n",
    "print(len(train_ds) + len(val_ds) + len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_true_labels(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed writing 823 rows to C:\\Documents\\Thesis_ssd\\MasterThesis-2.0\\csv_folder/2_class/balanced/test_set.csv.\n",
      "Completed writing 1918 rows to C:\\Documents\\Thesis_ssd\\MasterThesis-2.0\\csv_folder/2_class/balanced/validation_set.csv.\n",
      "Completed writing 10963 rows to C:\\Documents\\Thesis_ssd\\MasterThesis-2.0\\csv_folder/2_class/balanced/train_set.csv.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "root_sub = 'balanced'\n",
    "output_folder = f\"{csv_folder}/2_class/{root_sub}\"\n",
    "\n",
    "# Test set:\n",
    "output_csv_name = \"test_set.csv\"\n",
    "generate_subset_csv(test_ds, output_csv_name, output_folder)\n",
    "\n",
    "# Validation set:\n",
    "output_csv_name = \"validation_set.csv\"\n",
    "generate_subset_csv(val_ds, output_csv_name, output_folder)\n",
    "\n",
    "# Train set:\n",
    "output_csv_name = \"train_set.csv\"\n",
    "generate_subset_csv(train_ds, output_csv_name, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
