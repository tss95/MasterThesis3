{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "from obspy import Stream, Trace, UTCDateTime\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "import pylab as pl\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.layers import Activation, Conv1D, Dense, Dropout, Flatten, MaxPooling3D, BatchNormalization, InputLayer, LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.models import Sequential\n",
    "from keras.utils import Sequence\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import re\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import os\n",
    "import sys\n",
    "classes_dir = 'C:\\Documents\\Thesis_ssd\\MasterThesis'\n",
    "os.chdir(classes_dir)\n",
    "from Classes.DataProcessing.LoadData import LoadData\n",
    "from Classes.DataProcessing.BaselineHelperFunctions import BaselineHelperFunctions\n",
    "from Classes.DataProcessing.DataHandler import DataHandler\n",
    "from Classes.DataProcessing.DataGenerator import DataGenerator\n",
    "from Classes.DataProcessing.NoiseAugmentor import NoiseAugmentor\n",
    "from Classes.Modeling.Models import Models\n",
    "from Classes.Modeling.RandomGridSearch import RandomGridSearch\n",
    "from Classes.Modeling.CustomCallback import CustomCallback\n",
    "from Classes.Scaling.ScalerFitter import ScalerFitter\n",
    "from Classes.Scaling.MinMaxScalerFitter import MinMaxScalerFitter\n",
    "from Classes.Scaling.StandardScalerFitter import StandardScalerFitter\n",
    "from Classes import Tf_shutup\n",
    "Tf_shutup.Tf_shutup()\n",
    "\n",
    "from livelossplot import PlotLossesKeras\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"]= (15,15)\n",
    "helper = BaselineHelperFunctions()\n",
    "\n",
    "import sys\n",
    "ISCOLAB = 'google.colab' in sys.modules\n",
    "\n",
    "import random\n",
    "import pprint\n",
    "\n",
    "base_dir = 'C:\\Documents\\Thesis_ssd\\MasterThesis'\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "loadData = LoadData(num_classes = num_classes, isBalanced = True)\n",
    "shuffle = True\n",
    "full_ds, train_ds, val_ds, test_ds = loadData.getDatasets(shuffle = shuffle)\n",
    "data_gen = DataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "{'model_nr': 5, 'index': 10}\n",
    "{'batch_size': 32, 'epochs': 35, 'learning_rate': 1e-05, 'optimizer': 'rmsprop'}\n",
    "{'activation': 'relu', 'dropout_rate': 0.4, 'filters': 21, 'kernel_size': 7, 'l1_r': 0.001, 'l2_r': 0.2, \n",
    "'output_layer_activation': 'sigmoid', 'padding': 'same', 'start_neurons': 16}\n",
    "\n",
    "{'model_nr': 4, 'index': 10}\n",
    "{'batch_size': 8, 'epochs': 30, 'learning_rate': 0.0001, 'optimizer': 'adam'}\n",
    "{'activation': 'relu', 'dropout_rate': 0.3, 'filters': 17, 'kernel_size': 3, 'l1_r': 0.01, 'l2_r': 0.1, \n",
    "'output_layer_activation': 'softmax', 'padding': 'same', 'start_neurons': 128}\n",
    "\n",
    "Crashing model:\n",
    "Test_mode: False, use_scaler: True, use_minmax: False, use_noise_augmentor: True, detrend: False\n",
    "{'model_nr': 4, 'index': 21}\n",
    "{'batch_size': 16, 'epochs': 35, 'learning_rate': 0.001, 'optimizer': 'sgd'}\n",
    "{'activation': 'relu', 'dropout_rate': 0.01, 'filters': 15, 'kernel_size': 13, 'l1_r': 0.0001, \n",
    "'l2_r': 0.2, 'output_layer_activation': 'sigmoid', 'padding': 'same', 'start_neurons': 64}\n",
    "\n",
    "\n",
    "2 classes:\n",
    "{'model_nr': 7, 'index': 38}\n",
    "Test_mode: False, use_scaler: True, use_minmax: False, use_noise_augmentor: True detrend: False. \n",
    "{'batch_size': 64, 'epochs': 40, 'learning_rate': 0.001, 'optimizer': 'rmsprop'}\n",
    "{'activation': 'tanh', 'dropout_rate': 0, 'filters': 13, 'kernel_size': 5, 'l1_r': 0.0001,\n",
    "'l2_r': 0.01, 'output_layer_activation': 'softmax', 'padding': 'same', 'start_neurons': 32}\n",
    "{'test_loss': 1.4299607276916504, 'test_accuracy': 0.7728365659713745, \n",
    "'test_precision': 0.7728365659713745, 'test_recall': 0.7728365659713745}\n",
    "{'train_loss': 0.9629267454147339, 'train_accuracy': 0.8897058963775635, \n",
    "'train_precision': 0.8897058963775635, 'train_recall': 0.8897058963775635}\n",
    "\n",
    "\n",
    "2 classes:\n",
    "{'model_nr': 7, 'index': 31}\n",
    "{'batch_size': 128, 'epochs': 40, 'learning_rate': 0.1, 'optimizer': 'sgd'}\n",
    "{'activation': 'tanh', 'dropout_rate': 0.1, 'filters': 17, 'kernel_size': 7, \n",
    "'l1_r': 0.001, 'l2_r': 0.0001, 'output_layer_activation': 'sigmoid', 'padding': 'same', 'start_neurons': 8}\n",
    "{'test_loss': 1.1340930461883545, 'test_accuracy': 0.7511160969734192, \n",
    "'test_precision': 0.7511160969734192, 'test_recall': 0.7511160969734192}\n",
    "{'train_loss': 1.0580902099609375, 'train_accuracy': 0.7890625, \n",
    "'train_precision': 0.7890625, 'train_recall': 0.7890625}\n",
    "\n",
    "\"\"\"\n",
    "############ Model picker #############\n",
    "model_nr = 7\n",
    "\n",
    "########### Hyperparameters ###########\n",
    "batch_size = 64\n",
    "epochs = 80\n",
    "learning_rate = 0.001\n",
    "#opt = tf.keras.optimizers.SGD(learning_rate=learning_rate, clipnorm=1.0, clipvalue=0.5)\n",
    "opt = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "activation = 'tanh'\n",
    "output_layer_activation = 'softmax'\n",
    "dropout_rate = 0\n",
    "filters = 13\n",
    "kernel_size = 5\n",
    "l1_r = 0.0001\n",
    "l2_r = 0.01\n",
    "padding = 'same'\n",
    "start_neurons = 32\n",
    "\n",
    "########### Preprocessing ###########\n",
    "test = False\n",
    "use_noise_augmentor = True\n",
    "detrend = False\n",
    "use_scaler = True\n",
    "use_highpass = False\n",
    "highpass_freq = 0.2\n",
    "\n",
    "use_tensorboard = True\n",
    "use_livelossplot = False\n",
    "use_custom = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20201019-171450']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 10988."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def clear_tensorboard_dir():\n",
    "    import os\n",
    "    import shutil\n",
    "    path = f\"{base_dir}/Tensorboard_dir/fit\"\n",
    "    files = os.listdir(path)\n",
    "    print(files)\n",
    "    for f in files:\n",
    "        shutil.rmtree(os.path.join(path,f))\n",
    "        \n",
    "if use_tensorboard:\n",
    "    import datetime\n",
    "    clear_tensorboard_dir()\n",
    "    %load_ext tensorboard\n",
    "    %tensorboard --logdir tensorboard_dir/fit\n",
    "    log_dir = f\"{base_dir}/tensorboard_dir/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    callbacks = [tensorboard_callback]\n",
    "\n",
    "if use_custom:\n",
    "    custom_callback = CustomCallback(data_gen)\n",
    "    callbacks = custom_callback\n",
    "elif use_livelossplot:\n",
    "    callbacks = PlotLossesKeras()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (64, 3, 32)               772352    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (64, 3, 32)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (64, 3, 32)               128       \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (64, 16)                  3136      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (64, 16)                  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (64, 16)                  64        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (64, 16)                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, 3)                   51        \n",
      "=================================================================\n",
      "Total params: 775,731\n",
      "Trainable params: 775,635\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_ds, channels, timesteps = data_gen.get_trace_shape_no_cast(train_ds)\n",
    "input_shape = (batch_size, channels, timesteps)\n",
    "\n",
    "build_model_args = {'model_nr' : model_nr,\n",
    "                    'input_shape' : input_shape,\n",
    "                    'num_classes' : num_classes,\n",
    "                    'dropout_rate' : dropout_rate,\n",
    "                    'activation' : activation,\n",
    "                    'output_layer_activation' : output_layer_activation,\n",
    "                    'l2_r' : l2_r,\n",
    "                    'l1_r' : l1_r,\n",
    "                    'full_regularizer' : True,\n",
    "                    'start_neurons' : start_neurons,\n",
    "                    'filters' : filters,\n",
    "                    'kernel_size' : kernel_size,\n",
    "                    'padding' : 'same'}\n",
    "model = Models(**build_model_args).model\n",
    "\n",
    "model_args = {'loss' : \"binary_crossentropy\",\n",
    "              'optimizer' : opt,\n",
    "              'metrics' : [\"accuracy\",\"MSE\",\n",
    "                           tf.keras.metrics.Precision(thresholds=None, top_k=None, class_id=None, name=None, dtype=None),\n",
    "                           tf.keras.metrics.Recall(thresholds=None, top_k=None, class_id=None, name=None, dtype=None)]}\n",
    "model.compile(**model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "  1/256 [..............................] - ETA: 0s - loss: 5.4604 - accuracy: 0.3438 - MSE: 0.2734 - precision: 0.3409 - recall: 0.2344WARNING:tensorflow:From C:\\Users\\tss_9\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "  2/256 [..............................] - ETA: 25s - loss: 5.3612 - accuracy: 0.3359 - MSE: 0.2742 - precision: 0.3617 - recall: 0.2656WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0320s vs `on_train_batch_end` time: 0.1759s). Check your callbacks.\n",
      "257/256 [==============================] - 54s 208ms/step - loss: 2.2963 - accuracy: 0.4748 - MSE: 0.2117 - precision: 0.5559 - recall: 0.2450 - val_loss: 1.5663 - val_accuracy: 0.3972 - val_MSE: 0.2178 - val_precision: 0.6364 - val_recall: 0.0049\n",
      "Epoch 2/80\n",
      "257/256 [==============================] - 48s 185ms/step - loss: 1.2767 - accuracy: 0.5597 - MSE: 0.1836 - precision: 0.6993 - recall: 0.3183 - val_loss: 1.2205 - val_accuracy: 0.4861 - val_MSE: 0.2005 - val_precision: 0.6479 - val_recall: 0.2000\n",
      "Epoch 3/80\n",
      "257/256 [==============================] - 47s 185ms/step - loss: 1.0711 - accuracy: 0.5734 - MSE: 0.1792 - precision: 0.6935 - recall: 0.3566 - val_loss: 1.0750 - val_accuracy: 0.5382 - val_MSE: 0.1898 - val_precision: 0.6669 - val_recall: 0.2802\n",
      "Epoch 4/80\n",
      "257/256 [==============================] - 48s 185ms/step - loss: 0.9872 - accuracy: 0.5889 - MSE: 0.1741 - precision: 0.7005 - recall: 0.4024 - val_loss: 1.0538 - val_accuracy: 0.5455 - val_MSE: 0.1858 - val_precision: 0.6581 - val_recall: 0.3448\n",
      "Epoch 5/80\n",
      "257/256 [==============================] - 48s 186ms/step - loss: 0.9652 - accuracy: 0.6069 - MSE: 0.1681 - precision: 0.7059 - recall: 0.4402 - val_loss: 1.0499 - val_accuracy: 0.5573 - val_MSE: 0.1831 - val_precision: 0.6562 - val_recall: 0.3691\n",
      "Epoch 6/80\n",
      "257/256 [==============================] - 47s 184ms/step - loss: 0.9527 - accuracy: 0.6161 - MSE: 0.1635 - precision: 0.7129 - recall: 0.4683 - val_loss: 1.0453 - val_accuracy: 0.5521 - val_MSE: 0.1833 - val_precision: 0.6499 - val_recall: 0.3913\n",
      "Epoch 7/80\n",
      "257/256 [==============================] - 47s 184ms/step - loss: 0.9514 - accuracy: 0.6250 - MSE: 0.1601 - precision: 0.7139 - recall: 0.4845 - val_loss: 1.0231 - val_accuracy: 0.5576 - val_MSE: 0.1819 - val_precision: 0.6467 - val_recall: 0.4118\n",
      "Epoch 8/80\n",
      "257/256 [==============================] - 48s 186ms/step - loss: 0.9276 - accuracy: 0.6413 - MSE: 0.1546 - precision: 0.7242 - recall: 0.5103 - val_loss: 1.0386 - val_accuracy: 0.5719 - val_MSE: 0.1806 - val_precision: 0.6356 - val_recall: 0.4469\n",
      "Epoch 9/80\n",
      "257/256 [==============================] - 48s 185ms/step - loss: 0.9271 - accuracy: 0.6537 - MSE: 0.1502 - precision: 0.7310 - recall: 0.5371 - val_loss: 1.0487 - val_accuracy: 0.5743 - val_MSE: 0.1811 - val_precision: 0.6477 - val_recall: 0.4347\n",
      "Epoch 10/80\n",
      "257/256 [==============================] - 48s 188ms/step - loss: 0.9128 - accuracy: 0.6603 - MSE: 0.1475 - precision: 0.7370 - recall: 0.5497 - val_loss: 1.0282 - val_accuracy: 0.5691 - val_MSE: 0.1793 - val_precision: 0.6442 - val_recall: 0.4483\n",
      "Epoch 11/80\n",
      "257/256 [==============================] - 49s 192ms/step - loss: 0.9031 - accuracy: 0.6733 - MSE: 0.1437 - precision: 0.7432 - recall: 0.5702 - val_loss: 1.0145 - val_accuracy: 0.5903 - val_MSE: 0.1748 - val_precision: 0.6584 - val_recall: 0.4517\n",
      "Epoch 12/80\n",
      "257/256 [==============================] - 49s 190ms/step - loss: 0.8956 - accuracy: 0.6824 - MSE: 0.1398 - precision: 0.7504 - recall: 0.5834 - val_loss: 1.0204 - val_accuracy: 0.5958 - val_MSE: 0.1722 - val_precision: 0.6633 - val_recall: 0.4851\n",
      "Epoch 13/80\n",
      "257/256 [==============================] - 50s 193ms/step - loss: 0.8838 - accuracy: 0.6891 - MSE: 0.1361 - precision: 0.7550 - recall: 0.6010 - val_loss: 1.0212 - val_accuracy: 0.5944 - val_MSE: 0.1750 - val_precision: 0.6399 - val_recall: 0.5042ision: 0.7543 - recall: 0. - ETA: 6s - loss: 0.8873 - accuracy: 0.6891 - MSE: 0.1\n",
      "Epoch 14/80\n",
      "257/256 [==============================] - 49s 189ms/step - loss: 0.8721 - accuracy: 0.7011 - MSE: 0.1322 - precision: 0.7635 - recall: 0.6176 - val_loss: 1.0176 - val_accuracy: 0.5767 - val_MSE: 0.1777 - val_precision: 0.6397 - val_recall: 0.4882\n",
      "Epoch 15/80\n",
      "257/256 [==============================] - 49s 190ms/step - loss: 0.8598 - accuracy: 0.7115 - MSE: 0.1293 - precision: 0.7691 - recall: 0.6297 - val_loss: 1.0304 - val_accuracy: 0.5913 - val_MSE: 0.1750 - val_precision: 0.6514 - val_recall: 0.4997\n",
      "Epoch 16/80\n",
      "257/256 [==============================] - 49s 190ms/step - loss: 0.8572 - accuracy: 0.7177 - MSE: 0.1267 - precision: 0.7727 - recall: 0.6442 - val_loss: 1.0278 - val_accuracy: 0.5837 - val_MSE: 0.1776 - val_precision: 0.6394 - val_recall: 0.5201\n",
      "Epoch 17/80\n",
      "257/256 [==============================] - 49s 192ms/step - loss: 0.8421 - accuracy: 0.7248 - MSE: 0.1241 - precision: 0.7765 - recall: 0.6525 - val_loss: 1.0310 - val_accuracy: 0.5851 - val_MSE: 0.1790 - val_precision: 0.6278 - val_recall: 0.5101\n",
      "Epoch 18/80\n",
      "257/256 [==============================] - 51s 197ms/step - loss: 0.8376 - accuracy: 0.7294 - MSE: 0.1221 - precision: 0.7795 - recall: 0.6606 - val_loss: 1.0127 - val_accuracy: 0.5955 - val_MSE: 0.1766 - val_precision: 0.6391 - val_recall: 0.5097\n",
      "Epoch 19/80\n",
      "257/256 [==============================] - 49s 192ms/step - loss: 0.8225 - accuracy: 0.7383 - MSE: 0.1181 - precision: 0.7903 - recall: 0.6745 - val_loss: 1.0316 - val_accuracy: 0.5892 - val_MSE: 0.1785 - val_precision: 0.6300 - val_recall: 0.5243\n",
      "Epoch 20/80\n",
      "257/256 [==============================] - 49s 191ms/step - loss: 0.8311 - accuracy: 0.7415 - MSE: 0.1172 - precision: 0.7877 - recall: 0.6793 - val_loss: 1.0619 - val_accuracy: 0.6080 - val_MSE: 0.1744 - val_precision: 0.6450 - val_recall: 0.5306\n",
      "Epoch 21/80\n",
      "257/256 [==============================] - 49s 190ms/step - loss: 0.8226 - accuracy: 0.7452 - MSE: 0.1155 - precision: 0.7901 - recall: 0.6878 - val_loss: 1.0132 - val_accuracy: 0.6066 - val_MSE: 0.1748 - val_precision: 0.6496 - val_recall: 0.5111\n",
      "Epoch 22/80\n",
      "257/256 [==============================] - 49s 191ms/step - loss: 0.8215 - accuracy: 0.7488 - MSE: 0.1148 - precision: 0.7943 - recall: 0.6888 - val_loss: 1.0562 - val_accuracy: 0.5993 - val_MSE: 0.1750 - val_precision: 0.6398 - val_recall: 0.5285\n",
      "Epoch 23/80\n",
      "257/256 [==============================] - 49s 190ms/step - loss: 0.8156 - accuracy: 0.7524 - MSE: 0.1125 - precision: 0.7973 - recall: 0.6964 - val_loss: 1.0358 - val_accuracy: 0.5955 - val_MSE: 0.1741 - val_precision: 0.6354 - val_recall: 0.5344\n",
      "Epoch 24/80\n",
      "257/256 [==============================] - 55s 214ms/step - loss: 0.8073 - accuracy: 0.7581 - MSE: 0.1110 - precision: 0.8002 - recall: 0.7034 - val_loss: 1.0101 - val_accuracy: 0.5976 - val_MSE: 0.1759 - val_precision: 0.6335 - val_recall: 0.5240 0.7595 - MSE: 0.1107 - pr - ETA: 3s - loss: 0.8086 - accuracy: 0.7580 - MSE: 0.1113 - precision: 0.8\n",
      "Epoch 25/80\n",
      "257/256 [==============================] - 47s 183ms/step - loss: 0.8064 - accuracy: 0.7559 - MSE: 0.1105 - precision: 0.7977 - recall: 0.7016 - val_loss: 1.0229 - val_accuracy: 0.6125 - val_MSE: 0.1709 - val_precision: 0.6504 - val_recall: 0.5382\n",
      "Epoch 26/80\n",
      "257/256 [==============================] - 42s 164ms/step - loss: 0.8067 - accuracy: 0.7611 - MSE: 0.1098 - precision: 0.8029 - recall: 0.7088 - val_loss: 1.0232 - val_accuracy: 0.6160 - val_MSE: 0.1740 - val_precision: 0.6429 - val_recall: 0.5521\n",
      "Epoch 27/80\n",
      "257/256 [==============================] - 42s 163ms/step - loss: 0.8012 - accuracy: 0.7666 - MSE: 0.1081 - precision: 0.8055 - recall: 0.7154 - val_loss: 1.0488 - val_accuracy: 0.5906 - val_MSE: 0.1798 - val_precision: 0.6186 - val_recall: 0.5306\n",
      "Epoch 28/80\n",
      "257/256 [==============================] - 42s 164ms/step - loss: 0.8008 - accuracy: 0.7647 - MSE: 0.1079 - precision: 0.8041 - recall: 0.7175 - val_loss: 1.0442 - val_accuracy: 0.6069 - val_MSE: 0.1782 - val_precision: 0.6290 - val_recall: 0.5580\n",
      "Epoch 29/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/256 [==============================] - 44s 173ms/step - loss: 0.7949 - accuracy: 0.7698 - MSE: 0.1067 - precision: 0.8043 - recall: 0.7180 - val_loss: 1.0486 - val_accuracy: 0.5997 - val_MSE: 0.1784 - val_precision: 0.6327 - val_recall: 0.5257curacy: 0.7695 - MSE: 0.1066 - precision: 0.\n",
      "Epoch 30/80\n",
      "257/256 [==============================] - 44s 172ms/step - loss: 0.7887 - accuracy: 0.7695 - MSE: 0.1060 - precision: 0.8083 - recall: 0.7234 - val_loss: 1.0160 - val_accuracy: 0.6045 - val_MSE: 0.1784 - val_precision: 0.6335 - val_recall: 0.5431\n",
      "Epoch 31/80\n",
      "257/256 [==============================] - 45s 176ms/step - loss: 0.7881 - accuracy: 0.7739 - MSE: 0.1050 - precision: 0.8110 - recall: 0.7259 - val_loss: 1.0307 - val_accuracy: 0.6174 - val_MSE: 0.1731 - val_precision: 0.6506 - val_recall: 0.5611\n",
      "Epoch 32/80\n",
      "257/256 [==============================] - 45s 173ms/step - loss: 0.7863 - accuracy: 0.7757 - MSE: 0.1043 - precision: 0.8109 - recall: 0.7285 - val_loss: 1.0391 - val_accuracy: 0.6045 - val_MSE: 0.1778 - val_precision: 0.6319 - val_recall: 0.5372\n",
      "Epoch 33/80\n",
      "257/256 [==============================] - 44s 170ms/step - loss: 0.7798 - accuracy: 0.7772 - MSE: 0.1027 - precision: 0.8121 - recall: 0.7327 - val_loss: 1.0651 - val_accuracy: 0.6094 - val_MSE: 0.1755 - val_precision: 0.6460 - val_recall: 0.5493\n",
      "Epoch 34/80\n",
      "257/256 [==============================] - 44s 171ms/step - loss: 0.7860 - accuracy: 0.7755 - MSE: 0.1029 - precision: 0.8101 - recall: 0.7338 - val_loss: 1.0572 - val_accuracy: 0.5965 - val_MSE: 0.1810 - val_precision: 0.6184 - val_recall: 0.5448\n",
      "Epoch 35/80\n",
      "257/256 [==============================] - 44s 169ms/step - loss: 0.7796 - accuracy: 0.7794 - MSE: 0.1020 - precision: 0.8139 - recall: 0.7366 - val_loss: 1.0456 - val_accuracy: 0.5958 - val_MSE: 0.1800 - val_precision: 0.6320 - val_recall: 0.5437\n",
      "Epoch 36/80\n",
      "257/256 [==============================] - 44s 171ms/step - loss: 0.7842 - accuracy: 0.7761 - MSE: 0.1029 - precision: 0.8108 - recall: 0.7341 - val_loss: 1.0257 - val_accuracy: 0.6222 - val_MSE: 0.1759 - val_precision: 0.6394 - val_recall: 0.5885\n",
      "Epoch 37/80\n",
      "257/256 [==============================] - 44s 170ms/step - loss: 0.7795 - accuracy: 0.7770 - MSE: 0.1020 - precision: 0.8115 - recall: 0.7372 - val_loss: 1.0006 - val_accuracy: 0.6198 - val_MSE: 0.1739 - val_precision: 0.6450 - val_recall: 0.5684\n",
      "Epoch 38/80\n",
      "257/256 [==============================] - 44s 170ms/step - loss: 0.7788 - accuracy: 0.7782 - MSE: 0.1019 - precision: 0.8139 - recall: 0.7377 - val_loss: 1.0614 - val_accuracy: 0.6229 - val_MSE: 0.1755 - val_precision: 0.6514 - val_recall: 0.5795\n",
      "Epoch 39/80\n",
      "257/256 [==============================] - 44s 171ms/step - loss: 0.7654 - accuracy: 0.7859 - MSE: 0.1002 - precision: 0.8183 - recall: 0.7446 - val_loss: 1.0279 - val_accuracy: 0.6201 - val_MSE: 0.1750 - val_precision: 0.6455 - val_recall: 0.5677\n",
      "Epoch 40/80\n",
      "257/256 [==============================] - 44s 170ms/step - loss: 0.7676 - accuracy: 0.7846 - MSE: 0.1001 - precision: 0.8163 - recall: 0.7458 - val_loss: 1.0120 - val_accuracy: 0.6118 - val_MSE: 0.1753 - val_precision: 0.6426 - val_recall: 0.5556\n",
      "Epoch 41/80\n",
      "257/256 [==============================] - 43s 169ms/step - loss: 0.7736 - accuracy: 0.7821 - MSE: 0.1013 - precision: 0.8132 - recall: 0.7417 - val_loss: 1.0220 - val_accuracy: 0.6028 - val_MSE: 0.1783 - val_precision: 0.6406 - val_recall: 0.5434\n",
      "Epoch 42/80\n",
      "257/256 [==============================] - 43s 169ms/step - loss: 0.7609 - accuracy: 0.7860 - MSE: 0.0991 - precision: 0.8167 - recall: 0.7479 - val_loss: 1.0416 - val_accuracy: 0.6146 - val_MSE: 0.1770 - val_precision: 0.6358 - val_recall: 0.5753\n",
      "Epoch 43/80\n",
      "257/256 [==============================] - 44s 170ms/step - loss: 0.7623 - accuracy: 0.7842 - MSE: 0.0992 - precision: 0.8164 - recall: 0.7473 - val_loss: 1.0189 - val_accuracy: 0.6163 - val_MSE: 0.1751 - val_precision: 0.6419 - val_recall: 0.5733\n",
      "Epoch 44/80\n",
      "257/256 [==============================] - 44s 171ms/step - loss: 0.7560 - accuracy: 0.7912 - MSE: 0.0966 - precision: 0.8218 - recall: 0.7529 - val_loss: 1.0203 - val_accuracy: 0.6007 - val_MSE: 0.1793 - val_precision: 0.6245 - val_recall: 0.5514\n",
      "Epoch 45/80\n",
      "257/256 [==============================] - 44s 172ms/step - loss: 0.7603 - accuracy: 0.7902 - MSE: 0.0976 - precision: 0.8200 - recall: 0.7519 - val_loss: 1.0466 - val_accuracy: 0.5944 - val_MSE: 0.1814 - val_precision: 0.6166 - val_recall: 0.5646\n",
      "Epoch 46/80\n",
      "257/256 [==============================] - 44s 171ms/step - loss: 0.7602 - accuracy: 0.7886 - MSE: 0.0980 - precision: 0.8192 - recall: 0.7536 - val_loss: 1.0199 - val_accuracy: 0.5965 - val_MSE: 0.1814 - val_precision: 0.6320 - val_recall: 0.5451\n",
      "Epoch 47/80\n",
      "257/256 [==============================] - 44s 171ms/step - loss: 0.7617 - accuracy: 0.7974 - MSE: 0.0961 - precision: 0.8258 - recall: 0.7591 - val_loss: 1.0527 - val_accuracy: 0.6010 - val_MSE: 0.1791 - val_precision: 0.6267 - val_recall: 0.5531acy: 0.7980 - MSE: 0.0960 - precision:\n",
      "Epoch 48/80\n",
      "257/256 [==============================] - 42s 165ms/step - loss: 0.7638 - accuracy: 0.7942 - MSE: 0.0968 - precision: 0.8241 - recall: 0.7581 - val_loss: 1.0565 - val_accuracy: 0.6076 - val_MSE: 0.1794 - val_precision: 0.6298 - val_recall: 0.5642\n",
      "Epoch 49/80\n",
      "257/256 [==============================] - 47s 182ms/step - loss: 0.7589 - accuracy: 0.7901 - MSE: 0.0973 - precision: 0.8209 - recall: 0.7550 - val_loss: 1.0313 - val_accuracy: 0.6167 - val_MSE: 0.1767 - val_precision: 0.6425 - val_recall: 0.5785\n",
      "Epoch 50/80\n",
      "257/256 [==============================] - 43s 167ms/step - loss: 0.7570 - accuracy: 0.7919 - MSE: 0.0960 - precision: 0.8226 - recall: 0.7561 - val_loss: 1.0647 - val_accuracy: 0.6090 - val_MSE: 0.1791 - val_precision: 0.6359 - val_recall: 0.5670\n",
      "Epoch 51/80\n",
      "257/256 [==============================] - 43s 166ms/step - loss: 0.7591 - accuracy: 0.7927 - MSE: 0.0958 - precision: 0.8227 - recall: 0.7585 - val_loss: 1.0494 - val_accuracy: 0.6069 - val_MSE: 0.1825 - val_precision: 0.6256 - val_recall: 0.5750\n",
      "Epoch 52/80\n",
      "257/256 [==============================] - 43s 167ms/step - loss: 0.7512 - accuracy: 0.7930 - MSE: 0.0960 - precision: 0.8234 - recall: 0.7586 - val_loss: 1.0181 - val_accuracy: 0.6247 - val_MSE: 0.1736 - val_precision: 0.6477 - val_recall: 0.5847\n",
      "Epoch 53/80\n",
      "257/256 [==============================] - 43s 167ms/step - loss: 0.7558 - accuracy: 0.7961 - MSE: 0.0957 - precision: 0.8245 - recall: 0.7619 - val_loss: 1.0780 - val_accuracy: 0.6198 - val_MSE: 0.1764 - val_precision: 0.6414 - val_recall: 0.5875\n",
      "Epoch 54/80\n",
      "257/256 [==============================] - 43s 168ms/step - loss: 0.7540 - accuracy: 0.7891 - MSE: 0.0969 - precision: 0.8193 - recall: 0.7560 - val_loss: 1.0531 - val_accuracy: 0.6153 - val_MSE: 0.1768 - val_precision: 0.6306 - val_recall: 0.5875\n",
      "Epoch 55/80\n",
      "257/256 [==============================] - 43s 166ms/step - loss: 0.7552 - accuracy: 0.7954 - MSE: 0.0949 - precision: 0.8238 - recall: 0.7613 - val_loss: 1.0553 - val_accuracy: 0.6184 - val_MSE: 0.1782 - val_precision: 0.6337 - val_recall: 0.5924\n",
      "Epoch 56/80\n",
      "257/256 [==============================] - 43s 166ms/step - loss: 0.7496 - accuracy: 0.7966 - MSE: 0.0949 - precision: 0.8228 - recall: 0.7631 - val_loss: 1.0208 - val_accuracy: 0.6330 - val_MSE: 0.1731 - val_precision: 0.6477 - val_recall: 0.6031\n",
      "Epoch 57/80\n",
      "257/256 [==============================] - 43s 166ms/step - loss: 0.7438 - accuracy: 0.7980 - MSE: 0.0939 - precision: 0.8287 - recall: 0.7636 - val_loss: 1.0427 - val_accuracy: 0.6115 - val_MSE: 0.1775 - val_precision: 0.6323 - val_recall: 0.5816\n",
      "Epoch 58/80\n",
      "257/256 [==============================] - 43s 166ms/step - loss: 0.7515 - accuracy: 0.7973 - MSE: 0.0935 - precision: 0.8253 - recall: 0.7632 - val_loss: 1.0028 - val_accuracy: 0.6316 - val_MSE: 0.1720 - val_precision: 0.6543 - val_recall: 0.6007\n",
      "Epoch 59/80\n",
      "257/256 [==============================] - 43s 166ms/step - loss: 0.7526 - accuracy: 0.7988 - MSE: 0.0942 - precision: 0.8274 - recall: 0.7643 - val_loss: 1.0336 - val_accuracy: 0.6319 - val_MSE: 0.1742 - val_precision: 0.6452 - val_recall: 0.5979\n",
      "Epoch 60/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/256 [==============================] - 42s 165ms/step - loss: 0.7433 - accuracy: 0.8033 - MSE: 0.0921 - precision: 0.8304 - recall: 0.7670 - val_loss: 1.0261 - val_accuracy: 0.6097 - val_MSE: 0.1807 - val_precision: 0.6251 - val_recall: 0.5813\n",
      "Epoch 61/80\n",
      "257/256 [==============================] - 43s 166ms/step - loss: 0.7479 - accuracy: 0.8020 - MSE: 0.0939 - precision: 0.8272 - recall: 0.7682 - val_loss: 1.0494 - val_accuracy: 0.6257 - val_MSE: 0.1761 - val_precision: 0.6436 - val_recall: 0.5983\n",
      "Epoch 62/80\n",
      "257/256 [==============================] - 42s 165ms/step - loss: 0.7508 - accuracy: 0.8022 - MSE: 0.0926 - precision: 0.8289 - recall: 0.7698 - val_loss: 1.0589 - val_accuracy: 0.6156 - val_MSE: 0.1766 - val_precision: 0.6367 - val_recall: 0.5976\n",
      "Epoch 63/80\n",
      "257/256 [==============================] - 42s 165ms/step - loss: 0.7518 - accuracy: 0.8050 - MSE: 0.0914 - precision: 0.8334 - recall: 0.7738 - val_loss: 1.0295 - val_accuracy: 0.6198 - val_MSE: 0.1755 - val_precision: 0.6442 - val_recall: 0.5809\n",
      "Epoch 64/80\n",
      "257/256 [==============================] - 43s 166ms/step - loss: 0.7532 - accuracy: 0.8059 - MSE: 0.0918 - precision: 0.8332 - recall: 0.7726 - val_loss: 1.0362 - val_accuracy: 0.6326 - val_MSE: 0.1709 - val_precision: 0.6577 - val_recall: 0.5972\n",
      "Epoch 65/80\n",
      "257/256 [==============================] - 42s 164ms/step - loss: 0.7446 - accuracy: 0.8082 - MSE: 0.0914 - precision: 0.8342 - recall: 0.7766 - val_loss: 1.0470 - val_accuracy: 0.6219 - val_MSE: 0.1758 - val_precision: 0.6374 - val_recall: 0.5896\n",
      "Epoch 66/80\n",
      "257/256 [==============================] - 43s 165ms/step - loss: 0.7485 - accuracy: 0.8081 - MSE: 0.0907 - precision: 0.8344 - recall: 0.7791 - val_loss: 1.0570 - val_accuracy: 0.6278 - val_MSE: 0.1765 - val_precision: 0.6459 - val_recall: 0.5927\n",
      "Epoch 67/80\n",
      "257/256 [==============================] - 42s 165ms/step - loss: 0.7607 - accuracy: 0.8024 - MSE: 0.0928 - precision: 0.8278 - recall: 0.7702 - val_loss: 1.0507 - val_accuracy: 0.6146 - val_MSE: 0.1765 - val_precision: 0.6294 - val_recall: 0.5837\n",
      "Epoch 68/80\n",
      "257/256 [==============================] - 43s 166ms/step - loss: 0.7420 - accuracy: 0.8042 - MSE: 0.0912 - precision: 0.8294 - recall: 0.7742 - val_loss: 1.0305 - val_accuracy: 0.6191 - val_MSE: 0.1770 - val_precision: 0.6377 - val_recall: 0.5885\n",
      "Epoch 69/80\n",
      "257/256 [==============================] - 42s 164ms/step - loss: 0.7474 - accuracy: 0.8076 - MSE: 0.0905 - precision: 0.8345 - recall: 0.7770 - val_loss: 1.0545 - val_accuracy: 0.6208 - val_MSE: 0.1754 - val_precision: 0.6415 - val_recall: 0.5872\n",
      "Epoch 70/80\n",
      "257/256 [==============================] - 42s 165ms/step - loss: 0.7412 - accuracy: 0.8067 - MSE: 0.0901 - precision: 0.8333 - recall: 0.7783 - val_loss: 1.0327 - val_accuracy: 0.6375 - val_MSE: 0.1713 - val_precision: 0.6578 - val_recall: 0.6042\n",
      "Epoch 71/80\n",
      "257/256 [==============================] - 42s 164ms/step - loss: 0.7523 - accuracy: 0.8057 - MSE: 0.0914 - precision: 0.8312 - recall: 0.7747 - val_loss: 1.0085 - val_accuracy: 0.6299 - val_MSE: 0.1736 - val_precision: 0.6510 - val_recall: 0.5868\n",
      "Epoch 72/80\n",
      "257/256 [==============================] - 42s 164ms/step - loss: 0.7537 - accuracy: 0.8061 - MSE: 0.0909 - precision: 0.8310 - recall: 0.7769 - val_loss: 1.0555 - val_accuracy: 0.6198 - val_MSE: 0.1745 - val_precision: 0.6387 - val_recall: 0.5892\n",
      "Epoch 73/80\n",
      "257/256 [==============================] - 42s 164ms/step - loss: 0.7424 - accuracy: 0.8054 - MSE: 0.0912 - precision: 0.8308 - recall: 0.7744 - val_loss: 1.0437 - val_accuracy: 0.6344 - val_MSE: 0.1726 - val_precision: 0.6559 - val_recall: 0.5938\n",
      "Epoch 74/80\n",
      "257/256 [==============================] - 42s 165ms/step - loss: 0.7440 - accuracy: 0.8066 - MSE: 0.0901 - precision: 0.8323 - recall: 0.7769 - val_loss: 1.0300 - val_accuracy: 0.6340 - val_MSE: 0.1712 - val_precision: 0.6567 - val_recall: 0.6031\n",
      "Epoch 75/80\n",
      "257/256 [==============================] - 43s 166ms/step - loss: 0.7382 - accuracy: 0.8138 - MSE: 0.0877 - precision: 0.8394 - recall: 0.7834 - val_loss: 1.0612 - val_accuracy: 0.6524 - val_MSE: 0.1708 - val_precision: 0.6685 - val_recall: 0.6267\n",
      "Epoch 76/80\n",
      "257/256 [==============================] - 42s 164ms/step - loss: 0.7453 - accuracy: 0.8096 - MSE: 0.0893 - precision: 0.8347 - recall: 0.7806 - val_loss: 1.0293 - val_accuracy: 0.6403 - val_MSE: 0.1714 - val_precision: 0.6598 - val_recall: 0.6115\n",
      "Epoch 77/80\n",
      "257/256 [==============================] - 42s 165ms/step - loss: 0.7441 - accuracy: 0.8106 - MSE: 0.0886 - precision: 0.8361 - recall: 0.7825 - val_loss: 1.0659 - val_accuracy: 0.6340 - val_MSE: 0.1738 - val_precision: 0.6496 - val_recall: 0.6097\n",
      "Epoch 78/80\n",
      "257/256 [==============================] - 42s 165ms/step - loss: 0.7390 - accuracy: 0.8115 - MSE: 0.0884 - precision: 0.8363 - recall: 0.7837 - val_loss: 1.0512 - val_accuracy: 0.6448 - val_MSE: 0.1721 - val_precision: 0.6614 - val_recall: 0.6219\n",
      "Epoch 79/80\n",
      "257/256 [==============================] - 42s 164ms/step - loss: 0.7520 - accuracy: 0.8101 - MSE: 0.0893 - precision: 0.8334 - recall: 0.7827 - val_loss: 1.0944 - val_accuracy: 0.6271 - val_MSE: 0.1758 - val_precision: 0.6448 - val_recall: 0.6038\n",
      "Epoch 80/80\n",
      "257/256 [==============================] - 43s 166ms/step - loss: 0.7484 - accuracy: 0.8096 - MSE: 0.0885 - precision: 0.8349 - recall: 0.7806 - val_loss: 1.0686 - val_accuracy: 0.6385 - val_MSE: 0.1712 - val_precision: 0.6594 - val_recall: 0.6090\n"
     ]
    }
   ],
   "source": [
    "scaler = None\n",
    "if use_scaler:\n",
    "    scaler = StandardScalerFitter(train_ds).fit_scaler(test = test, detrend = detrend)\n",
    "aug = None\n",
    "if use_noise_augmentor:\n",
    "    aug = NoiseAugmentor(train_ds, use_scaler, scaler)\n",
    "    \n",
    "    \n",
    "\n",
    "gen_args = {\n",
    "    'batch_size' : batch_size,\n",
    "    'test' : test,\n",
    "    'detrend' : detrend,\n",
    "    'use_scaler' : use_scaler,\n",
    "    'scaler' : scaler,\n",
    "    'use_noise_augmentor' : use_noise_augmentor,\n",
    "    'augmentor' : aug,\n",
    "    'num_classes' : num_classes,\n",
    "    'use_highpass' : use_highpass,\n",
    "    'highpass_freq' : highpass_freq\n",
    "}\n",
    "\n",
    "\n",
    "train_gen = data_gen.data_generator(train_ds, **gen_args)\n",
    "val_gen = data_gen.data_generator(val_ds, **gen_args)\n",
    "test_gen = data_gen.data_generator(test_ds, **gen_args)\n",
    "\n",
    "\n",
    "\n",
    "args = {'steps_per_epoch' : helper.get_steps_per_epoch(train_ds, batch_size, test),\n",
    "        'epochs' : epochs,\n",
    "        'validation_data' : val_gen,\n",
    "        'validation_steps' : helper.get_steps_per_epoch(val_ds, batch_size, test),\n",
    "        'verbose' : 1,\n",
    "        'use_multiprocessing' : False, \n",
    "        'workers' : 1,\n",
    "        'callbacks' : [callbacks]\n",
    "}\n",
    "\n",
    "model_fit = model.fit(train_gen, **args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'custom_callback' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-caff4dd8bda0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfull_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcustom_callback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_training_logs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'custom_callback' is not defined"
     ]
    }
   ],
   "source": [
    "full_logs = custom_callback.full_training_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.get_n_points_with_highest_training_loss(train_ds, 100, full_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_points_with_highest_training_loss(full_logs, train_ds, n):\n",
    "    train_ds_dict = {}\n",
    "    for path, label in train_ds:\n",
    "        train_ds_dict[path] = {'label' : label,\n",
    "                               'loss': 0,\n",
    "                               'average_loss' : 0,\n",
    "                               'occurances' : 0}\n",
    "    counter = 0\n",
    "    for batch in full_logs:\n",
    "        loss = batch['loss']\n",
    "        for path_class in batch['batch_samples']:\n",
    "            train_ds_dict[path_class[0]]['loss'] += loss\n",
    "            train_ds_dict[path_class[0]]['occurances'] += 1\n",
    "    \n",
    "    train_ds_list = []\n",
    "    for sample in np.array(train_ds[:,0]):\n",
    "        if train_ds_dict[sample]['occurances'] == 0:\n",
    "            continue\n",
    "        train_ds_dict[sample]['average_loss'] = train_ds_dict[sample]['loss'] / train_ds_dict[sample]['occurances']\n",
    "        train_ds_list.append((sample, train_ds_dict[sample]['label'],train_ds_dict[sample]['average_loss']))\n",
    "    \n",
    "    sorted_train_ds_list = sorted(train_ds_list, key=lambda x: x[2], reverse = True)\n",
    "        \n",
    "    \n",
    "    return sorted_train_ds_list[0:n]\n",
    "        \n",
    "#get_n_points_with_highest_loss(full_logs, train_ds, 100)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate_generator(generator=test_gen, steps=helper.get_steps_per_epoch(test_ds, batch_size, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_true_categorical.argmax(axis=1), predictions[0:1234].argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Documents\\Thesis_ssd\\MasterThesis\\Classes\\DataProcessing\\BaselineHelperFunctions.py:47: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "[[215  84  91]\n",
      " [ 97 316  16]\n",
      " [112  37 266]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "helper.plot_confusion_matrix(model, test_gen, test_ds, batch_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_generator(val_gen, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.plot_confusion_matrix(test_ds, batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
