{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataGenerator import DataGenerator\n",
    "from Models import Models\n",
    "from LoadData import LoadData\n",
    "from BaselineHelperFunctions import BaselineHelperFunctions\n",
    "from RandomGridSearch import RandomGridSearch\n",
    "import json\n",
    "\n",
    "helper = BaselineHelperFunctions()\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earthquakes: 6852, Explosions: 6852, Noise: 6852, Total: 20556\n",
      "Train_ds: 16444, Val_ds: 2878, Test_ds: 1234\n"
     ]
    }
   ],
   "source": [
    "csv_root = 'csv_folder_3_class'\n",
    "full_data_csv, train_csv, val_csv, test_csv = LoadData(csv_root, isBalanced = True).getData()\n",
    "data_gen = DataGenerator(csv_root, train_csv, val_csv, test_csv)\n",
    "full_ds = data_gen.load_dataset(full_data_csv)\n",
    "train_ds = data_gen.load_dataset(train_csv)\n",
    "val_ds = data_gen.load_dataset(val_csv)\n",
    "test_ds = data_gen.load_dataset(test_csv)\n",
    "nr_earthquakes, nr_explosions, nr_noise, nr_total = helper.get_class_distribution_from_csv(full_data_csv)\n",
    "\n",
    "print(f\"Earthquakes: {nr_earthquakes}, Explosions: {nr_explosions}, Noise: {nr_noise}, Total: {nr_total}\")\n",
    "print(f'Train_ds: {len(train_ds)}, Val_ds: {len(val_ds)}, Test_ds: {len(test_ds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_grid = {\n",
    "        \"batch_size\" : [8, 16, 32, 64, 128, 256],\n",
    "        \"epochs\" : [50, 65, 70, 75, 80],\n",
    "        \"learning_rate\" : [0.1, 0.01, 0.001, 0.0001, 0.00001],\n",
    "        \"optimizer\" : [\"adam\", \"rmsprop\", \"sgd\"]\n",
    "    }\n",
    "model_grid = {\n",
    "    \"start_neurons\" : [2,4,8,16, 32, 64, 128, 256, 512],\n",
    "    \"dropout_rate\" : [0.5, 0.4, 0.3, 0.2, 0.1, 0.01, 0],\n",
    "    \"filters\" : [3, 9, 15, 17],\n",
    "    \"kernel_size\" : [3],\n",
    "    \"padding\" : [\"same\", \"valid\"],\n",
    "    \"l2_r\" : [0.3, 0.2, 0.1, 0.01, 0.001, 0.0001],\n",
    "    \"l1_r\" : [0.3, 0.2, 0.1, 0.01, 0.001, 0.0001],\n",
    "    \"activation\" : [\"relu\", \"sigmoid\", \"softmax\", \"tanh\"],\n",
    "    \"output_layer_activation\" : [\"softmax\"]\n",
    "}\n",
    "\n",
    "\n",
    "model_nr = 5\n",
    "test_mode = True\n",
    "detrend = False\n",
    "n_picks = 40\n",
    "use_tensorboard = False\n",
    "\n",
    "randomGridSearch = RandomGridSearch(train_ds, val_ds, test_ds, model_nr, True,False, n_picks, hyper_grid = hyper_grid, model_grid = model_grid, use_tensorboard = use_tensorboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20200924-193135', '20200924-193335', '20200924-193544', '20200924-193743', '20200924-193936', '20200924-194143', '20200924-194356', '20200924-194624', '20200924-194748', '20200924-195026', '20200924-195245', '20200924-195524', '20200924-195717', '20200924-195926', '20200924-200113', '20200924-200332', '20200924-200551', '20200924-200738']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 11100), started 1:54:31 ago. (Use '!kill 11100' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4fcfcce4fe37c763\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4fcfcce4fe37c763\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def clear_tensorboard_dir():\n",
    "    import os\n",
    "    import shutil\n",
    "    path = \"tensorboard_dir/fit\"\n",
    "    files = os.listdir(path)\n",
    "    print(files)\n",
    "    for f in files:\n",
    "        shutil.rmtree(os.path.join(path,f))\n",
    "clear_tensorboard_dir()\n",
    "%tensorboard --logdir tensorboard_dir/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (32, 16)                  385152    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (32, 16)                  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (32, 16)                  64        \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (32, 3)                   51        \n",
      "=================================================================\n",
      "Total params: 385,267\n",
      "Trainable params: 385,235\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n",
      "Starting: \n",
      "{   'batch_size': 32,\n",
      "    'epochs': 80,\n",
      "    'learning_rate': 0.0001,\n",
      "    'optimizer': 'rmsprop'}\n",
      "---------------------------------------------------------------------------------\n",
      "{   'activation': 'softmax',\n",
      "    'dropout_rate': 0.1,\n",
      "    'filters': 17,\n",
      "    'kernel_size': 3,\n",
      "    'l1_r': 0.3,\n",
      "    'l2_r': 0.0001,\n",
      "    'output_layer_activation': 'softmax',\n",
      "    'padding': 'valid',\n",
      "    'start_neurons': 16}\n",
      "Epoch 1/80\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 1811.7478 - accuracy: 0.1875 - MSE: 0.3338 - precision: 0.1923 - recall: 0.1562WARNING:tensorflow:From C:\\Users\\tss_9\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      " 2/25 [=>............................] - ETA: 2s - loss: 1793.7913 - accuracy: 0.2344 - MSE: 0.3148 - precision: 0.2449 - recall: 0.1875WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0460s vs `on_train_batch_end` time: 0.1479s). Check your callbacks.\n",
      "25/25 [==============================] - 3s 118ms/step - loss: 1607.0593 - accuracy: 0.3125 - MSE: 0.2815 - precision: 0.3242 - recall: 0.2362 - val_loss: 1451.4215 - val_accuracy: 0.2969 - val_MSE: 0.2226 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/80\n",
      "25/25 [==============================] - 2s 70ms/step - loss: 1333.4843 - accuracy: 0.3475 - MSE: 0.2776 - precision: 0.3450 - recall: 0.2587 - val_loss: 1210.4032 - val_accuracy: 0.2969 - val_MSE: 0.2226 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/80\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1105.7577 - accuracy: 0.3475 - MSE: 0.2733 - precision: 0.3599 - recall: 0.2600 - val_loss: 995.3505 - val_accuracy: 0.2891 - val_MSE: 0.2236 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/80\n",
      "25/25 [==============================] - 2s 70ms/step - loss: 900.7231 - accuracy: 0.3475 - MSE: 0.2647 - precision: 0.3522 - recall: 0.2488 - val_loss: 801.3593 - val_accuracy: 0.2734 - val_MSE: 0.2239 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/80\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 717.0943 - accuracy: 0.3475 - MSE: 0.2696 - precision: 0.3419 - recall: 0.2500 - val_loss: 629.7089 - val_accuracy: 0.2969 - val_MSE: 0.2232 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/80\n",
      "25/25 [==============================] - 2s 66ms/step - loss: 556.6866 - accuracy: 0.3762 - MSE: 0.2588 - precision: 0.3770 - recall: 0.2700 - val_loss: 480.7004 - val_accuracy: 0.3281 - val_MSE: 0.2235 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 417.7501 - accuracy: 0.3850 - MSE: 0.2543 - precision: 0.3887 - recall: 0.2663 - val_loss: 352.9410 - val_accuracy: 0.3281 - val_MSE: 0.2239 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/80\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 300.0753 - accuracy: 0.4075 - MSE: 0.2472 - precision: 0.4171 - recall: 0.2925 - val_loss: 246.1590 - val_accuracy: 0.3359 - val_MSE: 0.2238 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 203.6718 - accuracy: 0.3850 - MSE: 0.2434 - precision: 0.4181 - recall: 0.2937 - val_loss: 161.3215 - val_accuracy: 0.3516 - val_MSE: 0.2229 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/80\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 129.2704 - accuracy: 0.4162 - MSE: 0.2336 - precision: 0.4524 - recall: 0.3150 - val_loss: 98.4728 - val_accuracy: 0.3594 - val_MSE: 0.2216 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/80\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 75.0984 - accuracy: 0.4563 - MSE: 0.2154 - precision: 0.4900 - recall: 0.3363 - val_loss: 53.7092 - val_accuracy: 0.3828 - val_MSE: 0.2219 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/80\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 39.7578 - accuracy: 0.4775 - MSE: 0.2084 - precision: 0.5227 - recall: 0.3600 - val_loss: 28.0065 - val_accuracy: 0.3359 - val_MSE: 0.2232 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/80\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 22.2742 - accuracy: 0.5025 - MSE: 0.1985 - precision: 0.5564 - recall: 0.3762 - val_loss: 17.6347 - val_accuracy: 0.3828 - val_MSE: 0.2215 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 14/80\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 15.8504 - accuracy: 0.5213 - MSE: 0.2008 - precision: 0.5605 - recall: 0.3938 - val_loss: 14.2941 - val_accuracy: 0.3750 - val_MSE: 0.2229 - val_precision: 1.0000 - val_recall: 0.0078\n",
      "Epoch 15/80\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 13.4945 - accuracy: 0.5075 - MSE: 0.2046 - precision: 0.5581 - recall: 0.3900 - val_loss: 13.8625 - val_accuracy: 0.3203 - val_MSE: 0.2249 - val_precision: 0.6250 - val_recall: 0.0391\n",
      "Epoch 16/80\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 12.3567 - accuracy: 0.5050 - MSE: 0.2096 - precision: 0.5479 - recall: 0.4150 - val_loss: 12.8557 - val_accuracy: 0.3516 - val_MSE: 0.2241 - val_precision: 0.2727 - val_recall: 0.0234\n",
      "Epoch 17/80\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 11.3829 - accuracy: 0.4850 - MSE: 0.2106 - precision: 0.5440 - recall: 0.3862 - val_loss: 10.7353 - val_accuracy: 0.4062 - val_MSE: 0.2301 - val_precision: 0.3548 - val_recall: 0.0859\n",
      "Epoch 18/80\n",
      "25/25 [==============================] - 2s 66ms/step - loss: 11.0692 - accuracy: 0.4675 - MSE: 0.2251 - precision: 0.4967 - recall: 0.3738 - val_loss: 10.1887 - val_accuracy: 0.4062 - val_MSE: 0.2268 - val_precision: 0.3929 - val_recall: 0.0859\n",
      "Epoch 19/80\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 10.7464 - accuracy: 0.4500 - MSE: 0.2320 - precision: 0.4668 - recall: 0.3600 - val_loss: 10.9429 - val_accuracy: 0.3984 - val_MSE: 0.2280 - val_precision: 0.3714 - val_recall: 0.1016\n",
      "Epoch 20/80\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 10.8685 - accuracy: 0.4462 - MSE: 0.2305 - precision: 0.4614 - recall: 0.3663 - val_loss: 9.5860 - val_accuracy: 0.3828 - val_MSE: 0.2229 - val_precision: 0.4600 - val_recall: 0.1797\n",
      "Epoch 21/80\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 10.0473 - accuracy: 0.4638 - MSE: 0.2298 - precision: 0.4878 - recall: 0.3750 - val_loss: 10.2212 - val_accuracy: 0.3672 - val_MSE: 0.2279 - val_precision: 0.4182 - val_recall: 0.1797\n",
      "Epoch 22/80\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 10.4680 - accuracy: 0.4712 - MSE: 0.2286 - precision: 0.4887 - recall: 0.3800 - val_loss: 9.7024 - val_accuracy: 0.3828 - val_MSE: 0.2295 - val_precision: 0.4918 - val_recall: 0.2344\n",
      "Epoch 23/80\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 10.4650 - accuracy: 0.4675 - MSE: 0.2269 - precision: 0.4917 - recall: 0.3725 - val_loss: 10.2459 - val_accuracy: 0.4297 - val_MSE: 0.2249 - val_precision: 0.4444 - val_recall: 0.2500\n",
      "Epoch 24/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 2s 63ms/step - loss: 10.2418 - accuracy: 0.4787 - MSE: 0.2252 - precision: 0.5025 - recall: 0.3787 - val_loss: 9.8375 - val_accuracy: 0.3828 - val_MSE: 0.2300 - val_precision: 0.4237 - val_recall: 0.1953\n",
      "Epoch 25/80\n",
      "25/25 [==============================] - 2s 65ms/step - loss: 10.5916 - accuracy: 0.4563 - MSE: 0.2301 - precision: 0.4805 - recall: 0.3700 - val_loss: 10.6092 - val_accuracy: 0.3516 - val_MSE: 0.2439 - val_precision: 0.3636 - val_recall: 0.1875\n",
      "Epoch 26/80\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 10.4859 - accuracy: 0.4387 - MSE: 0.2292 - precision: 0.4671 - recall: 0.3550 - val_loss: 10.5532 - val_accuracy: 0.3438 - val_MSE: 0.2511 - val_precision: 0.3472 - val_recall: 0.1953\n",
      "Epoch 27/80\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 9.9713 - accuracy: 0.4863 - MSE: 0.2174 - precision: 0.5125 - recall: 0.3850 - val_loss: 10.2582 - val_accuracy: 0.3672 - val_MSE: 0.2515 - val_precision: 0.3690 - val_recall: 0.2422\n",
      "Epoch 28/80\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 10.2581 - accuracy: 0.4650 - MSE: 0.2296 - precision: 0.4786 - recall: 0.3638 - val_loss: 11.2767 - val_accuracy: 0.3906 - val_MSE: 0.2497 - val_precision: 0.4156 - val_recall: 0.2500\n",
      "Epoch 29/80\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 10.1183 - accuracy: 0.4638 - MSE: 0.2251 - precision: 0.4941 - recall: 0.3650 - val_loss: 10.5632 - val_accuracy: 0.3906 - val_MSE: 0.2512 - val_precision: 0.3902 - val_recall: 0.2500\n",
      "Epoch 30/80\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 10.3477 - accuracy: 0.4638 - MSE: 0.2277 - precision: 0.4831 - recall: 0.3762 - val_loss: 11.1627 - val_accuracy: 0.4141 - val_MSE: 0.2366 - val_precision: 0.4568 - val_recall: 0.2891\n",
      "Epoch 31/80\n",
      "25/25 [==============================] - 2s 62ms/step - loss: 10.0844 - accuracy: 0.4837 - MSE: 0.2195 - precision: 0.5049 - recall: 0.3862 - val_loss: 10.1940 - val_accuracy: 0.3438 - val_MSE: 0.2639 - val_precision: 0.3846 - val_recall: 0.2734\n",
      "Epoch 32/80\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 9.9745 - accuracy: 0.4750 - MSE: 0.2176 - precision: 0.4992 - recall: 0.3738 - val_loss: 10.3534 - val_accuracy: 0.3906 - val_MSE: 0.2542 - val_precision: 0.4457 - val_recall: 0.3203\n",
      "Epoch 33/80\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 10.3361 - accuracy: 0.4750 - MSE: 0.2247 - precision: 0.4975 - recall: 0.3713 - val_loss: 9.4463 - val_accuracy: 0.3125 - val_MSE: 0.2801 - val_precision: 0.3367 - val_recall: 0.2578\n",
      "Epoch 34/80\n",
      "25/25 [==============================] - 2s 62ms/step - loss: 10.0500 - accuracy: 0.4313 - MSE: 0.2341 - precision: 0.4624 - recall: 0.3462 - val_loss: 9.8055 - val_accuracy: 0.3984 - val_MSE: 0.2495 - val_precision: 0.4086 - val_recall: 0.2969\n",
      "Epoch 35/80\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 10.3684 - accuracy: 0.4913 - MSE: 0.2163 - precision: 0.5174 - recall: 0.3913 - val_loss: 10.6610 - val_accuracy: 0.4062 - val_MSE: 0.2581 - val_precision: 0.4022 - val_recall: 0.2891\n",
      "Epoch 36/80\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 10.1485 - accuracy: 0.4638 - MSE: 0.2278 - precision: 0.4909 - recall: 0.3713 - val_loss: 10.7610 - val_accuracy: 0.4141 - val_MSE: 0.2451 - val_precision: 0.4250 - val_recall: 0.2656\n",
      "Epoch 37/80\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 10.3901 - accuracy: 0.4538 - MSE: 0.2281 - precision: 0.4681 - recall: 0.3575 - val_loss: 10.1804 - val_accuracy: 0.3906 - val_MSE: 0.2623 - val_precision: 0.4021 - val_recall: 0.3047\n",
      "Epoch 38/80\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 9.8199 - accuracy: 0.5000 - MSE: 0.2177 - precision: 0.5195 - recall: 0.3837 - val_loss: 9.9818 - val_accuracy: 0.4453 - val_MSE: 0.2391 - val_precision: 0.4176 - val_recall: 0.2969\n",
      "Epoch 39/80\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 10.3155 - accuracy: 0.4975 - MSE: 0.2179 - precision: 0.5206 - recall: 0.3950 - val_loss: 11.0532 - val_accuracy: 0.5000 - val_MSE: 0.2397 - val_precision: 0.4945 - val_recall: 0.3516\n",
      "Epoch 40/80\n",
      "25/25 [==============================] - 2s 65ms/step - loss: 10.2398 - accuracy: 0.4675 - MSE: 0.2220 - precision: 0.4959 - recall: 0.3750 - val_loss: 10.6722 - val_accuracy: 0.3906 - val_MSE: 0.2481 - val_precision: 0.4516 - val_recall: 0.3281\n",
      "Epoch 41/80\n",
      "25/25 [==============================] - 2s 65ms/step - loss: 10.4759 - accuracy: 0.4900 - MSE: 0.2140 - precision: 0.5026 - recall: 0.3613 - val_loss: 10.9519 - val_accuracy: 0.3750 - val_MSE: 0.2531 - val_precision: 0.3837 - val_recall: 0.2578\n",
      "Epoch 42/80\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 9.5763 - accuracy: 0.4950 - MSE: 0.2121 - precision: 0.5280 - recall: 0.3775 - val_loss: 10.9255 - val_accuracy: 0.3125 - val_MSE: 0.2681 - val_precision: 0.3158 - val_recall: 0.2344\n",
      "Epoch 43/80\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 9.7954 - accuracy: 0.4613 - MSE: 0.2158 - precision: 0.5113 - recall: 0.3663 - val_loss: 10.1465 - val_accuracy: 0.3203 - val_MSE: 0.2733 - val_precision: 0.3261 - val_recall: 0.2344\n",
      "Epoch 44/80\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 9.7920 - accuracy: 0.4812 - MSE: 0.2188 - precision: 0.5068 - recall: 0.3700 - val_loss: 10.2026 - val_accuracy: 0.3516 - val_MSE: 0.2684 - val_precision: 0.3441 - val_recall: 0.2500\n",
      "Epoch 45/80\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 10.0590 - accuracy: 0.4663 - MSE: 0.2212 - precision: 0.4950 - recall: 0.3688 - val_loss: 9.9280 - val_accuracy: 0.3750 - val_MSE: 0.2533 - val_precision: 0.4149 - val_recall: 0.3047\n",
      "Epoch 46/80\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 9.8635 - accuracy: 0.4725 - MSE: 0.2193 - precision: 0.4974 - recall: 0.3550 - val_loss: 9.6831 - val_accuracy: 0.3750 - val_MSE: 0.2498 - val_precision: 0.3956 - val_recall: 0.2812\n",
      "Epoch 47/80\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 9.7585 - accuracy: 0.4900 - MSE: 0.2127 - precision: 0.5296 - recall: 0.3800 - val_loss: 10.1525 - val_accuracy: 0.4062 - val_MSE: 0.2444 - val_precision: 0.4043 - val_recall: 0.2969\n",
      "Epoch 48/80\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 9.8170 - accuracy: 0.4725 - MSE: 0.2188 - precision: 0.5150 - recall: 0.3638 - val_loss: 8.8103 - val_accuracy: 0.4297 - val_MSE: 0.2378 - val_precision: 0.4578 - val_recall: 0.2969\n",
      "Epoch 49/80\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 9.8063 - accuracy: 0.4700 - MSE: 0.2200 - precision: 0.4939 - recall: 0.3537 - val_loss: 9.2517 - val_accuracy: 0.3906 - val_MSE: 0.2382 - val_precision: 0.4535 - val_recall: 0.3047\n",
      "Epoch 50/80\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 9.6380 - accuracy: 0.4600 - MSE: 0.2215 - precision: 0.4940 - recall: 0.3600 - val_loss: 10.0701 - val_accuracy: 0.3438 - val_MSE: 0.2459 - val_precision: 0.4130 - val_recall: 0.2969\n",
      "Epoch 51/80\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 9.7693 - accuracy: 0.4850 - MSE: 0.2134 - precision: 0.5037 - recall: 0.3425 - val_loss: 9.3048 - val_accuracy: 0.3359 - val_MSE: 0.2540 - val_precision: 0.3494 - val_recall: 0.2266\n",
      "Epoch 52/80\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 9.8659 - accuracy: 0.4938 - MSE: 0.2077 - precision: 0.5385 - recall: 0.3675 - val_loss: 10.0323 - val_accuracy: 0.3125 - val_MSE: 0.2752 - val_precision: 0.3218 - val_recall: 0.2188\n",
      "Epoch 53/80\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 9.7861 - accuracy: 0.4825 - MSE: 0.2122 - precision: 0.5189 - recall: 0.3425 - val_loss: 10.5389 - val_accuracy: 0.3281 - val_MSE: 0.2629 - val_precision: 0.3737 - val_recall: 0.2891\n",
      "Epoch 54/80\n",
      "25/25 [==============================] - 2s 65ms/step - loss: 9.6335 - accuracy: 0.4875 - MSE: 0.2146 - precision: 0.5161 - recall: 0.3613 - val_loss: 10.3623 - val_accuracy: 0.3984 - val_MSE: 0.2455 - val_precision: 0.4105 - val_recall: 0.3047\n",
      "Epoch 55/80\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 9.6187 - accuracy: 0.4375 - MSE: 0.2268 - precision: 0.4582 - recall: 0.3150 - val_loss: 10.9512 - val_accuracy: 0.3516 - val_MSE: 0.2686 - val_precision: 0.3737 - val_recall: 0.2891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/80\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 9.5871 - accuracy: 0.4762 - MSE: 0.2153 - precision: 0.5166 - recall: 0.3700 - val_loss: 9.3852 - val_accuracy: 0.4297 - val_MSE: 0.2395 - val_precision: 0.4353 - val_recall: 0.2891\n",
      "Epoch 57/80\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 9.0286 - accuracy: 0.4837 - MSE: 0.2094 - precision: 0.5343 - recall: 0.3600 - val_loss: 10.7813 - val_accuracy: 0.3594 - val_MSE: 0.2592 - val_precision: 0.4186 - val_recall: 0.2812\n",
      "Epoch 58/80\n",
      "25/25 [==============================] - 2s 65ms/step - loss: 9.5970 - accuracy: 0.4462 - MSE: 0.2191 - precision: 0.4833 - recall: 0.3250 - val_loss: 9.2138 - val_accuracy: 0.3594 - val_MSE: 0.2619 - val_precision: 0.4217 - val_recall: 0.2734\n",
      "Epoch 59/80\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 9.9278 - accuracy: 0.4750 - MSE: 0.2139 - precision: 0.5157 - recall: 0.3487 - val_loss: 8.9801 - val_accuracy: 0.3516 - val_MSE: 0.2600 - val_precision: 0.3750 - val_recall: 0.2578\n",
      "Epoch 60/80\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 10.0090 - accuracy: 0.4800 - MSE: 0.2188 - precision: 0.5122 - recall: 0.3688 - val_loss: 9.8429 - val_accuracy: 0.3828 - val_MSE: 0.2503 - val_precision: 0.4091 - val_recall: 0.2812\n",
      "Epoch 61/80\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 10.5253 - accuracy: 0.4825 - MSE: 0.2096 - precision: 0.5098 - recall: 0.3237 - val_loss: 10.4383 - val_accuracy: 0.3594 - val_MSE: 0.2488 - val_precision: 0.4337 - val_recall: 0.2812\n",
      "Epoch 62/80\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 9.9732 - accuracy: 0.4988 - MSE: 0.2075 - precision: 0.5414 - recall: 0.3675 - val_loss: 9.8835 - val_accuracy: 0.3828 - val_MSE: 0.2464 - val_precision: 0.4023 - val_recall: 0.2734\n",
      "Epoch 63/80\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 9.5723 - accuracy: 0.4762 - MSE: 0.2175 - precision: 0.4855 - recall: 0.3350 - val_loss: 9.2413 - val_accuracy: 0.3594 - val_MSE: 0.2591 - val_precision: 0.3723 - val_recall: 0.2734\n",
      "Epoch 64/80\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 9.7836 - accuracy: 0.4825 - MSE: 0.2092 - precision: 0.5358 - recall: 0.3462 - val_loss: 10.0835 - val_accuracy: 0.3516 - val_MSE: 0.2551 - val_precision: 0.3580 - val_recall: 0.2266\n",
      "Epoch 65/80\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 9.9409 - accuracy: 0.5088 - MSE: 0.2013 - precision: 0.5714 - recall: 0.3700 - val_loss: 11.9044 - val_accuracy: 0.3984 - val_MSE: 0.2540 - val_precision: 0.4000 - val_recall: 0.2656\n",
      "Epoch 66/80\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 9.5977 - accuracy: 0.5113 - MSE: 0.2040 - precision: 0.5543 - recall: 0.3700 - val_loss: 8.8766 - val_accuracy: 0.3594 - val_MSE: 0.2491 - val_precision: 0.4167 - val_recall: 0.2344\n",
      "Epoch 67/80\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 9.0892 - accuracy: 0.4775 - MSE: 0.2138 - precision: 0.5143 - recall: 0.3363 - val_loss: 10.5151 - val_accuracy: 0.3281 - val_MSE: 0.2457 - val_precision: 0.3953 - val_recall: 0.2656\n",
      "Epoch 68/80\n",
      "25/25 [==============================] - 2s 65ms/step - loss: 9.3738 - accuracy: 0.4775 - MSE: 0.2135 - precision: 0.5037 - recall: 0.3438 - val_loss: 9.4223 - val_accuracy: 0.3828 - val_MSE: 0.2467 - val_precision: 0.3699 - val_recall: 0.2109\n",
      "Epoch 69/80\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 9.7107 - accuracy: 0.4550 - MSE: 0.2141 - precision: 0.5107 - recall: 0.3288 - val_loss: 9.6598 - val_accuracy: 0.3438 - val_MSE: 0.2550 - val_precision: 0.4118 - val_recall: 0.2734\n",
      "Epoch 70/80\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 9.4843 - accuracy: 0.4888 - MSE: 0.2091 - precision: 0.5300 - recall: 0.3537 - val_loss: 9.7914 - val_accuracy: 0.2969 - val_MSE: 0.2584 - val_precision: 0.3375 - val_recall: 0.2109\n",
      "Epoch 71/80\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 9.2646 - accuracy: 0.4913 - MSE: 0.2075 - precision: 0.5417 - recall: 0.3575 - val_loss: 9.6361 - val_accuracy: 0.3359 - val_MSE: 0.2490 - val_precision: 0.4024 - val_recall: 0.2578\n",
      "Epoch 72/80\n",
      "25/25 [==============================] - 2s 62ms/step - loss: 9.7775 - accuracy: 0.4737 - MSE: 0.2130 - precision: 0.5075 - recall: 0.3363 - val_loss: 9.1167 - val_accuracy: 0.2891 - val_MSE: 0.2603 - val_precision: 0.3171 - val_recall: 0.2031\n",
      "Epoch 73/80\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 9.2637 - accuracy: 0.4688 - MSE: 0.2135 - precision: 0.5088 - recall: 0.3237 - val_loss: 8.9090 - val_accuracy: 0.3516 - val_MSE: 0.2341 - val_precision: 0.4507 - val_recall: 0.2500\n",
      "Epoch 74/80\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 9.0347 - accuracy: 0.4762 - MSE: 0.2103 - precision: 0.5162 - recall: 0.3388 - val_loss: 9.7985 - val_accuracy: 0.4531 - val_MSE: 0.2365 - val_precision: 0.4359 - val_recall: 0.2656\n",
      "Epoch 75/80\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 9.2867 - accuracy: 0.4725 - MSE: 0.2161 - precision: 0.4981 - recall: 0.3200 - val_loss: 9.9258 - val_accuracy: 0.3203 - val_MSE: 0.2481 - val_precision: 0.3804 - val_recall: 0.2734\n",
      "Epoch 76/80\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 9.9724 - accuracy: 0.4500 - MSE: 0.2203 - precision: 0.4761 - recall: 0.2988 - val_loss: 9.3356 - val_accuracy: 0.3438 - val_MSE: 0.2462 - val_precision: 0.3690 - val_recall: 0.2422\n",
      "Epoch 77/80\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 9.2027 - accuracy: 0.4737 - MSE: 0.2126 - precision: 0.5047 - recall: 0.3338 - val_loss: 9.6104 - val_accuracy: 0.3203 - val_MSE: 0.2506 - val_precision: 0.3425 - val_recall: 0.1953\n",
      "Epoch 78/80\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 9.5226 - accuracy: 0.4487 - MSE: 0.2143 - precision: 0.4980 - recall: 0.3162 - val_loss: 10.0305 - val_accuracy: 0.3438 - val_MSE: 0.2519 - val_precision: 0.3766 - val_recall: 0.2266\n",
      "Epoch 79/80\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 9.1754 - accuracy: 0.4825 - MSE: 0.2080 - precision: 0.5437 - recall: 0.3425 - val_loss: 9.8139 - val_accuracy: 0.3516 - val_MSE: 0.2576 - val_precision: 0.3418 - val_recall: 0.2109\n",
      "Epoch 80/80\n",
      "25/25 [==============================] - 2s 62ms/step - loss: 9.5526 - accuracy: 0.4625 - MSE: 0.2158 - precision: 0.4800 - recall: 0.3000 - val_loss: 11.1539 - val_accuracy: 0.4141 - val_MSE: 0.2367 - val_precision: 0.4458 - val_recall: 0.2891\n",
      "WARNING:tensorflow:From C:\\Documents\\Thesis_ssd\\Master Thesis\\Thesis\\RandomGridSearch.py:165: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.evaluate, which supports generators.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (8, 2)                    48032     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (8, 2)                    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (8, 2)                    8         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (8, 3)                    9         \n",
      "=================================================================\n",
      "Total params: 48,049\n",
      "Trainable params: 48,045\n",
      "Non-trainable params: 4\n",
      "_________________________________________________________________\n",
      "Starting: \n",
      "{'batch_size': 8, 'epochs': 50, 'learning_rate': 0.001, 'optimizer': 'adam'}\n",
      "---------------------------------------------------------------------------------\n",
      "{   'activation': 'tanh',\n",
      "    'dropout_rate': 0.01,\n",
      "    'filters': 17,\n",
      "    'kernel_size': 3,\n",
      "    'l1_r': 0.3,\n",
      "    'l2_r': 0.01,\n",
      "    'output_layer_activation': 'softmax',\n",
      "    'padding': 'same',\n",
      "    'start_neurons': 2}\n",
      "Epoch 1/50\n",
      "  2/102 [..............................] - ETA: 1:29 - loss: 223.9734 - accuracy: 0.3750 - MSE: 0.2971 - precision_1: 0.3333 - recall_1: 0.2500WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0030s vs `on_train_batch_end` time: 1.7766s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 5s 44ms/step - loss: 60.8709 - accuracy: 0.3186 - MSE: 0.2834 - precision_1: 0.3081 - recall_1: 0.2047 - val_loss: 26.2956 - val_accuracy: 0.4559 - val_MSE: 0.2196 - val_precision_1: 0.4677 - val_recall_1: 0.2132\n",
      "Epoch 2/50\n",
      "102/102 [==============================] - 2s 17ms/step - loss: 34.9977 - accuracy: 0.3615 - MSE: 0.2599 - precision_1: 0.3720 - recall_1: 0.2120 - val_loss: 39.4814 - val_accuracy: 0.3162 - val_MSE: 0.2425 - val_precision_1: 0.3273 - val_recall_1: 0.1324\n",
      "Epoch 3/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 35.8774 - accuracy: 0.3640 - MSE: 0.2538 - precision_1: 0.3464 - recall_1: 0.1838 - val_loss: 26.4231 - val_accuracy: 0.3529 - val_MSE: 0.2352 - val_precision_1: 0.3390 - val_recall_1: 0.1471\n",
      "Epoch 4/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 21.4237 - accuracy: 0.3382 - MSE: 0.2455 - precision_1: 0.3607 - recall_1: 0.1777 - val_loss: 22.6460 - val_accuracy: 0.3015 - val_MSE: 0.2663 - val_precision_1: 0.2394 - val_recall_1: 0.1250\n",
      "Epoch 5/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 14.9386 - accuracy: 0.3309 - MSE: 0.2460 - precision_1: 0.3272 - recall_1: 0.1311 - val_loss: 12.7237 - val_accuracy: 0.4412 - val_MSE: 0.2267 - val_precision_1: 0.4444 - val_recall_1: 0.1765\n",
      "Epoch 6/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 16.5303 - accuracy: 0.3468 - MSE: 0.2373 - precision_1: 0.3299 - recall_1: 0.1164 - val_loss: 16.1757 - val_accuracy: 0.3529 - val_MSE: 0.2449 - val_precision_1: 0.1915 - val_recall_1: 0.0662\n",
      "Epoch 7/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 14.9609 - accuracy: 0.3346 - MSE: 0.2332 - precision_1: 0.3333 - recall_1: 0.0993 - val_loss: 16.1873 - val_accuracy: 0.4044 - val_MSE: 0.2268 - val_precision_1: 0.3846 - val_recall_1: 0.1471\n",
      "Epoch 8/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 15.4244 - accuracy: 0.3566 - MSE: 0.2285 - precision_1: 0.4029 - recall_1: 0.1017 - val_loss: 16.5905 - val_accuracy: 0.4265 - val_MSE: 0.2289 - val_precision_1: 0.3415 - val_recall_1: 0.1029\n",
      "Epoch 9/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 13.3587 - accuracy: 0.3627 - MSE: 0.2260 - precision_1: 0.4138 - recall_1: 0.0735 - val_loss: 14.8833 - val_accuracy: 0.3897 - val_MSE: 0.2279 - val_precision_1: 0.3902 - val_recall_1: 0.1176\n",
      "Epoch 10/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 18.2694 - accuracy: 0.3480 - MSE: 0.2280 - precision_1: 0.4050 - recall_1: 0.0600 - val_loss: 23.7775 - val_accuracy: 0.3309 - val_MSE: 0.2301 - val_precision_1: 0.4483 - val_recall_1: 0.0956\n",
      "Epoch 11/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 16.7703 - accuracy: 0.3627 - MSE: 0.2268 - precision_1: 0.3953 - recall_1: 0.0417 - val_loss: 15.5502 - val_accuracy: 0.3603 - val_MSE: 0.2248 - val_precision_1: 0.4706 - val_recall_1: 0.0588\n",
      "Epoch 12/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 14.0222 - accuracy: 0.3260 - MSE: 0.2276 - precision_1: 0.3585 - recall_1: 0.0233 - val_loss: 8.7789 - val_accuracy: 0.3603 - val_MSE: 0.2242 - val_precision_1: 0.6000 - val_recall_1: 0.0221\n",
      "Epoch 13/50\n",
      "102/102 [==============================] - 2s 17ms/step - loss: 9.9803 - accuracy: 0.3542 - MSE: 0.2253 - precision_1: 0.2632 - recall_1: 0.0123 - val_loss: 9.5544 - val_accuracy: 0.2941 - val_MSE: 0.2281 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 14/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 9.1974 - accuracy: 0.3321 - MSE: 0.2259 - precision_1: 0.3333 - recall_1: 0.0074 - val_loss: 7.7311 - val_accuracy: 0.3603 - val_MSE: 0.2211 - val_precision_1: 0.3333 - val_recall_1: 0.0074\n",
      "Epoch 15/50\n",
      "102/102 [==============================] - 2s 17ms/step - loss: 10.6692 - accuracy: 0.3407 - MSE: 0.2229 - precision_1: 0.3750 - recall_1: 0.0037 - val_loss: 9.6232 - val_accuracy: 0.3750 - val_MSE: 0.2234 - val_precision_1: 0.6000 - val_recall_1: 0.0221\n",
      "Epoch 16/50\n",
      "102/102 [==============================] - 2s 17ms/step - loss: 8.7168 - accuracy: 0.3321 - MSE: 0.2234 - precision_1: 0.6000 - recall_1: 0.0037 - val_loss: 9.4600 - val_accuracy: 0.3603 - val_MSE: 0.2229 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 17/50\n",
      "102/102 [==============================] - 2s 18ms/step - loss: 8.1942 - accuracy: 0.3493 - MSE: 0.2233 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 9.7602 - val_accuracy: 0.3456 - val_MSE: 0.2216 - val_precision_1: 0.5000 - val_recall_1: 0.0074\n",
      "Epoch 18/50\n",
      "102/102 [==============================] - 2s 17ms/step - loss: 9.2782 - accuracy: 0.3627 - MSE: 0.2224 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 8.6779 - val_accuracy: 0.3750 - val_MSE: 0.2230 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 19/50\n",
      "102/102 [==============================] - 2s 17ms/step - loss: 7.3425 - accuracy: 0.3603 - MSE: 0.2231 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 7.7271 - val_accuracy: 0.3824 - val_MSE: 0.2228 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 20/50\n",
      "102/102 [==============================] - 2s 18ms/step - loss: 6.7227 - accuracy: 0.3346 - MSE: 0.2238 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 6.3878 - val_accuracy: 0.3088 - val_MSE: 0.2250 - val_precision_1: 0.5000 - val_recall_1: 0.0074\n",
      "Epoch 21/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 7.2439 - accuracy: 0.3333 - MSE: 0.2234 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 7.7118 - val_accuracy: 0.3235 - val_MSE: 0.2249 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 22/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 7.4970 - accuracy: 0.3505 - MSE: 0.2216 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 8.4536 - val_accuracy: 0.3603 - val_MSE: 0.2229 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 23/50\n",
      "102/102 [==============================] - 2s 17ms/step - loss: 7.6041 - accuracy: 0.3456 - MSE: 0.2230 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 8.8166 - val_accuracy: 0.3603 - val_MSE: 0.2205 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 24/50\n",
      "102/102 [==============================] - 2s 17ms/step - loss: 6.6020 - accuracy: 0.3456 - MSE: 0.2224 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 8.3457 - val_accuracy: 0.3676 - val_MSE: 0.2223 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 25/50\n",
      "102/102 [==============================] - 2s 17ms/step - loss: 7.3967 - accuracy: 0.3456 - MSE: 0.2229 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 5.9922 - val_accuracy: 0.3750 - val_MSE: 0.2202 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 26/50\n",
      "102/102 [==============================] - 2s 17ms/step - loss: 6.1591 - accuracy: 0.3272 - MSE: 0.2234 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 7.3377 - val_accuracy: 0.3456 - val_MSE: 0.2236 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 27/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 5.9955 - accuracy: 0.3603 - MSE: 0.2218 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 6.5595 - val_accuracy: 0.3309 - val_MSE: 0.2234 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 28/50\n",
      "102/102 [==============================] - 2s 17ms/step - loss: 5.5845 - accuracy: 0.3493 - MSE: 0.2221 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 5.3209 - val_accuracy: 0.3603 - val_MSE: 0.2221 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 29/50\n",
      "102/102 [==============================] - 2s 18ms/step - loss: 7.8407 - accuracy: 0.3566 - MSE: 0.2222 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 5.2260 - val_accuracy: 0.3015 - val_MSE: 0.2230 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 30/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 12.0434 - accuracy: 0.3529 - MSE: 0.2223 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 7.4246 - val_accuracy: 0.3162 - val_MSE: 0.2225 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 5.0464 - accuracy: 0.3615 - MSE: 0.2226 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 4.2119 - val_accuracy: 0.3162 - val_MSE: 0.2222 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 32/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 4.8105 - accuracy: 0.3958 - MSE: 0.2211 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 4.5584 - val_accuracy: 0.3971 - val_MSE: 0.2209 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 33/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 6.5356 - accuracy: 0.3468 - MSE: 0.2227 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 4.1890 - val_accuracy: 0.3235 - val_MSE: 0.2205 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 34/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 6.4008 - accuracy: 0.3578 - MSE: 0.2227 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 4.2092 - val_accuracy: 0.3971 - val_MSE: 0.2208 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 35/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 4.6507 - accuracy: 0.3444 - MSE: 0.2224 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 4.3447 - val_accuracy: 0.3824 - val_MSE: 0.2201 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 36/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 9.0515 - accuracy: 0.3615 - MSE: 0.2221 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 9.2827 - val_accuracy: 0.3750 - val_MSE: 0.2214 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 37/50\n",
      "102/102 [==============================] - 2s 18ms/step - loss: 7.0579 - accuracy: 0.3419 - MSE: 0.2222 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 4.7779 - val_accuracy: 0.4044 - val_MSE: 0.2203 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 38/50\n",
      "102/102 [==============================] - 2s 17ms/step - loss: 4.7585 - accuracy: 0.3456 - MSE: 0.2220 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 4.6592 - val_accuracy: 0.3603 - val_MSE: 0.2206 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 39/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 9.3098 - accuracy: 0.3713 - MSE: 0.2215 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 9.7173 - val_accuracy: 0.3824 - val_MSE: 0.2203 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 40/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 7.5045 - accuracy: 0.3664 - MSE: 0.2220 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 6.6998 - val_accuracy: 0.3824 - val_MSE: 0.2203 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 41/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 5.4189 - accuracy: 0.3493 - MSE: 0.2220 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 6.6901 - val_accuracy: 0.3162 - val_MSE: 0.2232 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 42/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 10.6253 - accuracy: 0.3603 - MSE: 0.2220 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 13.8356 - val_accuracy: 0.3529 - val_MSE: 0.2236 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 43/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 8.5211 - accuracy: 0.3591 - MSE: 0.2218 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 6.8549 - val_accuracy: 0.3529 - val_MSE: 0.2224 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 44/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 6.0340 - accuracy: 0.3419 - MSE: 0.2218 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 4.7798 - val_accuracy: 0.3676 - val_MSE: 0.2212 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 45/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 6.6550 - accuracy: 0.3480 - MSE: 0.2222 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 6.7332 - val_accuracy: 0.3676 - val_MSE: 0.2209 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 46/50\n",
      "102/102 [==============================] - 2s 17ms/step - loss: 5.1219 - accuracy: 0.3591 - MSE: 0.2219 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 4.5285 - val_accuracy: 0.3456 - val_MSE: 0.2231 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 47/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 4.6335 - accuracy: 0.3615 - MSE: 0.2218 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 4.4517 - val_accuracy: 0.3382 - val_MSE: 0.2219 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 48/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 4.3597 - accuracy: 0.3321 - MSE: 0.2227 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 4.1275 - val_accuracy: 0.3897 - val_MSE: 0.2220 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 49/50\n",
      "102/102 [==============================] - 2s 16ms/step - loss: 5.1506 - accuracy: 0.3493 - MSE: 0.2219 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 4.7407 - val_accuracy: 0.3676 - val_MSE: 0.2221 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 50/50\n",
      "102/102 [==============================] - 2s 17ms/step - loss: 4.7546 - accuracy: 0.3554 - MSE: 0.2222 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 4.0463 - val_accuracy: 0.3897 - val_MSE: 0.2209 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (64, 128)                 3138560   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (64, 128)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (64, 128)                 512       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (64, 3)                   387       \n",
      "=================================================================\n",
      "Total params: 3,139,459\n",
      "Trainable params: 3,139,203\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Starting: \n",
      "{'batch_size': 64, 'epochs': 80, 'learning_rate': 1e-05, 'optimizer': 'sgd'}\n",
      "---------------------------------------------------------------------------------\n",
      "{   'activation': 'softmax',\n",
      "    'dropout_rate': 0.1,\n",
      "    'filters': 17,\n",
      "    'kernel_size': 3,\n",
      "    'l1_r': 0.01,\n",
      "    'l2_r': 0.01,\n",
      "    'output_layer_activation': 'softmax',\n",
      "    'padding': 'same',\n",
      "    'start_neurons': 128}\n",
      "Epoch 1/80\n",
      " 2/12 [====>.........................] - ETA: 9s - loss: 477.8434 - accuracy: 0.2969 - MSE: 0.2245 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1218s vs `on_train_batch_end` time: 1.7469s). Check your callbacks.\n",
      "12/12 [==============================] - 5s 382ms/step - loss: 477.8295 - accuracy: 0.3294 - MSE: 0.2247 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 477.7958 - val_accuracy: 0.3906 - val_MSE: 0.2220 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 2/80\n",
      "12/12 [==============================] - 2s 166ms/step - loss: 477.7896 - accuracy: 0.3229 - MSE: 0.2246 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 477.7567 - val_accuracy: 0.3750 - val_MSE: 0.2220 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 3/80\n",
      "12/12 [==============================] - 2s 165ms/step - loss: 477.7555 - accuracy: 0.3281 - MSE: 0.2258 - precision_2: 1.0000 - recall_2: 0.0013 - val_loss: 477.7175 - val_accuracy: 0.3828 - val_MSE: 0.2220 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 4/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 2s 169ms/step - loss: 477.7127 - accuracy: 0.3086 - MSE: 0.2250 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 477.6783 - val_accuracy: 0.3828 - val_MSE: 0.2220 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 5/80\n",
      "12/12 [==============================] - 2s 163ms/step - loss: 477.6703 - accuracy: 0.3190 - MSE: 0.2243 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 477.6391 - val_accuracy: 0.3828 - val_MSE: 0.2220 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 6/80\n",
      "12/12 [==============================] - 2s 166ms/step - loss: 477.6294 - accuracy: 0.3177 - MSE: 0.2239 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 477.6000 - val_accuracy: 0.3750 - val_MSE: 0.2220 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 7/80\n",
      "12/12 [==============================] - 2s 165ms/step - loss: 477.5912 - accuracy: 0.3294 - MSE: 0.2240 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 477.5608 - val_accuracy: 0.3828 - val_MSE: 0.2220 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 8/80\n",
      "12/12 [==============================] - 2s 174ms/step - loss: 477.5532 - accuracy: 0.3216 - MSE: 0.2243 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 477.5216 - val_accuracy: 0.3750 - val_MSE: 0.2220 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 9/80\n",
      "12/12 [==============================] - 2s 164ms/step - loss: 477.5128 - accuracy: 0.3529 - MSE: 0.2241 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 477.4824 - val_accuracy: 0.3906 - val_MSE: 0.2220 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 10/80\n",
      "12/12 [==============================] - 2s 162ms/step - loss: 477.4760 - accuracy: 0.3177 - MSE: 0.2245 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 477.4432 - val_accuracy: 0.3828 - val_MSE: 0.2220 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 11/80\n",
      "12/12 [==============================] - 2s 163ms/step - loss: 477.4327 - accuracy: 0.3424 - MSE: 0.2236 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 477.4040 - val_accuracy: 0.3828 - val_MSE: 0.2220 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 12/80\n",
      "12/12 [==============================] - 2s 166ms/step - loss: 477.3948 - accuracy: 0.3398 - MSE: 0.2240 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 477.3648 - val_accuracy: 0.3828 - val_MSE: 0.2220 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 13/80\n",
      "12/12 [==============================] - 2s 165ms/step - loss: 477.3522 - accuracy: 0.3307 - MSE: 0.2231 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 477.3256 - val_accuracy: 0.3828 - val_MSE: 0.2219 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 14/80\n",
      "12/12 [==============================] - 2s 169ms/step - loss: 477.3167 - accuracy: 0.3411 - MSE: 0.2239 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 477.2864 - val_accuracy: 0.3828 - val_MSE: 0.2219 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 15/80\n",
      "12/12 [==============================] - 2s 178ms/step - loss: 477.2786 - accuracy: 0.3346 - MSE: 0.2241 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 477.2472 - val_accuracy: 0.3828 - val_MSE: 0.2219 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 16/80\n",
      "12/12 [==============================] - 2s 165ms/step - loss: 477.2367 - accuracy: 0.3203 - MSE: 0.2237 - precision_2: 1.0000 - recall_2: 0.0026 - val_loss: 477.2081 - val_accuracy: 0.3906 - val_MSE: 0.2219 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 17/80\n",
      "12/12 [==============================] - 2s 168ms/step - loss: 477.2008 - accuracy: 0.3216 - MSE: 0.2243 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 477.1688 - val_accuracy: 0.3906 - val_MSE: 0.2219 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 18/80\n",
      "12/12 [==============================] - 2s 167ms/step - loss: 477.1581 - accuracy: 0.3516 - MSE: 0.2235 - precision_2: 0.5000 - recall_2: 0.0013 - val_loss: 477.1296 - val_accuracy: 0.3828 - val_MSE: 0.2219 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 19/80\n",
      "12/12 [==============================] - 2s 164ms/step - loss: 477.1166 - accuracy: 0.3542 - MSE: 0.2231 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 477.0904 - val_accuracy: 0.3828 - val_MSE: 0.2219 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 20/80\n",
      "12/12 [==============================] - 2s 168ms/step - loss: 477.0781 - accuracy: 0.3229 - MSE: 0.2232 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 477.0512 - val_accuracy: 0.3906 - val_MSE: 0.2218 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 21/80\n",
      "12/12 [==============================] - 2s 167ms/step - loss: 477.0412 - accuracy: 0.3359 - MSE: 0.2236 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 477.0120 - val_accuracy: 0.3828 - val_MSE: 0.2218 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 22/80\n",
      "12/12 [==============================] - 2s 176ms/step - loss: 476.9971 - accuracy: 0.3229 - MSE: 0.2226 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 476.9728 - val_accuracy: 0.3828 - val_MSE: 0.2218 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 23/80\n",
      "12/12 [==============================] - 2s 166ms/step - loss: 476.9628 - accuracy: 0.3372 - MSE: 0.2235 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 476.9335 - val_accuracy: 0.3828 - val_MSE: 0.2218 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 24/80\n",
      "12/12 [==============================] - 2s 167ms/step - loss: 476.9209 - accuracy: 0.3320 - MSE: 0.2230 - precision_2: 1.0000 - recall_2: 0.0013 - val_loss: 476.8943 - val_accuracy: 0.3906 - val_MSE: 0.2218 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 25/80\n",
      "12/12 [==============================] - 2s 166ms/step - loss: 476.8836 - accuracy: 0.3411 - MSE: 0.2234 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 476.8551 - val_accuracy: 0.3906 - val_MSE: 0.2217 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 26/80\n",
      "12/12 [==============================] - 2s 165ms/step - loss: 476.8494 - accuracy: 0.3294 - MSE: 0.2245 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 476.8158 - val_accuracy: 0.3906 - val_MSE: 0.2217 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 27/80\n",
      "12/12 [==============================] - 2s 162ms/step - loss: 476.8128 - accuracy: 0.3060 - MSE: 0.2251 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 476.7766 - val_accuracy: 0.3828 - val_MSE: 0.2217 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 28/80\n",
      "12/12 [==============================] - 2s 163ms/step - loss: 476.7647 - accuracy: 0.3268 - MSE: 0.2230 - precision_2: 1.0000 - recall_2: 0.0013 - val_loss: 476.7374 - val_accuracy: 0.3828 - val_MSE: 0.2217 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 29/80\n",
      "12/12 [==============================] - 2s 172ms/step - loss: 476.7298 - accuracy: 0.3203 - MSE: 0.2241 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 476.6981 - val_accuracy: 0.3828 - val_MSE: 0.2216 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 30/80\n",
      "12/12 [==============================] - 2s 168ms/step - loss: 476.6921 - accuracy: 0.3281 - MSE: 0.2243 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 476.6589 - val_accuracy: 0.3828 - val_MSE: 0.2216 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 31/80\n",
      "12/12 [==============================] - 2s 163ms/step - loss: 476.6490 - accuracy: 0.3451 - MSE: 0.2233 - precision_2: 0.5000 - recall_2: 0.0013 - val_loss: 476.6196 - val_accuracy: 0.3828 - val_MSE: 0.2216 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 32/80\n",
      "12/12 [==============================] - 2s 164ms/step - loss: 476.6081 - accuracy: 0.3594 - MSE: 0.2230 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 476.5804 - val_accuracy: 0.3828 - val_MSE: 0.2216 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/80\n",
      "12/12 [==============================] - 2s 161ms/step - loss: 476.5719 - accuracy: 0.3281 - MSE: 0.2237 - precision_2: 0.5000 - recall_2: 0.0013 - val_loss: 476.5411 - val_accuracy: 0.3828 - val_MSE: 0.2215 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 34/80\n",
      "12/12 [==============================] - 2s 160ms/step - loss: 476.5319 - accuracy: 0.3542 - MSE: 0.2235 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 476.5019 - val_accuracy: 0.3828 - val_MSE: 0.2215 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 35/80\n",
      "12/12 [==============================] - 2s 166ms/step - loss: 476.4906 - accuracy: 0.3451 - MSE: 0.2231 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 476.4626 - val_accuracy: 0.3828 - val_MSE: 0.2215 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 36/80\n",
      "12/12 [==============================] - 2s 168ms/step - loss: 476.4521 - accuracy: 0.3490 - MSE: 0.2230 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 476.4234 - val_accuracy: 0.3750 - val_MSE: 0.2214 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 37/80\n",
      "12/12 [==============================] - 2s 176ms/step - loss: 476.4110 - accuracy: 0.3320 - MSE: 0.2227 - precision_2: 0.5000 - recall_2: 0.0013 - val_loss: 476.3841 - val_accuracy: 0.3750 - val_MSE: 0.2214 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 38/80\n",
      "12/12 [==============================] - 2s 162ms/step - loss: 476.3731 - accuracy: 0.3490 - MSE: 0.2230 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 476.3449 - val_accuracy: 0.3750 - val_MSE: 0.2214 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 39/80\n",
      "12/12 [==============================] - 2s 168ms/step - loss: 476.3340 - accuracy: 0.3268 - MSE: 0.2229 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 476.3056 - val_accuracy: 0.3750 - val_MSE: 0.2213 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 40/80\n",
      "12/12 [==============================] - 2s 165ms/step - loss: 476.2940 - accuracy: 0.3633 - MSE: 0.2228 - precision_2: 1.0000 - recall_2: 0.0013 - val_loss: 476.2664 - val_accuracy: 0.3750 - val_MSE: 0.2213 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 41/80\n",
      "12/12 [==============================] - 2s 165ms/step - loss: 476.2548 - accuracy: 0.3359 - MSE: 0.2227 - precision_2: 1.0000 - recall_2: 0.0013 - val_loss: 476.2271 - val_accuracy: 0.3750 - val_MSE: 0.2212 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 42/80\n",
      "12/12 [==============================] - 2s 165ms/step - loss: 476.2174 - accuracy: 0.3372 - MSE: 0.2231 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 476.1878 - val_accuracy: 0.3750 - val_MSE: 0.2212 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 43/80\n",
      "12/12 [==============================] - 2s 164ms/step - loss: 476.1795 - accuracy: 0.3242 - MSE: 0.2234 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 476.1485 - val_accuracy: 0.3750 - val_MSE: 0.2212 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 44/80\n",
      "12/12 [==============================] - 2s 174ms/step - loss: 476.1412 - accuracy: 0.3411 - MSE: 0.2236 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 476.1094 - val_accuracy: 0.3750 - val_MSE: 0.2212 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 45/80\n",
      "12/12 [==============================] - 2s 167ms/step - loss: 476.0961 - accuracy: 0.3320 - MSE: 0.2224 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 476.0701 - val_accuracy: 0.3750 - val_MSE: 0.2211 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 46/80\n",
      "12/12 [==============================] - 2s 165ms/step - loss: 476.0575 - accuracy: 0.3411 - MSE: 0.2222 - precision_2: 1.0000 - recall_2: 0.0026 - val_loss: 476.0309 - val_accuracy: 0.3750 - val_MSE: 0.2211 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 47/80\n",
      "12/12 [==============================] - 2s 167ms/step - loss: 476.0165 - accuracy: 0.3555 - MSE: 0.2219 - precision_2: 0.6667 - recall_2: 0.0026 - val_loss: 475.9917 - val_accuracy: 0.3750 - val_MSE: 0.2211 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 48/80\n",
      "12/12 [==============================] - 2s 165ms/step - loss: 475.9797 - accuracy: 0.3542 - MSE: 0.2224 - precision_2: 0.5000 - recall_2: 0.0013 - val_loss: 475.9525 - val_accuracy: 0.3750 - val_MSE: 0.2210 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 49/80\n",
      "12/12 [==============================] - 2s 172ms/step - loss: 475.9434 - accuracy: 0.3359 - MSE: 0.2231 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 475.9133 - val_accuracy: 0.3750 - val_MSE: 0.2210 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 50/80\n",
      "12/12 [==============================] - 2s 165ms/step - loss: 475.9043 - accuracy: 0.3464 - MSE: 0.2230 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 475.8741 - val_accuracy: 0.3750 - val_MSE: 0.2210 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 51/80\n",
      "12/12 [==============================] - 2s 172ms/step - loss: 475.8629 - accuracy: 0.3477 - MSE: 0.2225 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 475.8349 - val_accuracy: 0.3750 - val_MSE: 0.2210 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 52/80\n",
      "12/12 [==============================] - 2s 165ms/step - loss: 475.8259 - accuracy: 0.3672 - MSE: 0.2229 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 475.7957 - val_accuracy: 0.3750 - val_MSE: 0.2209 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 53/80\n",
      "12/12 [==============================] - 2s 164ms/step - loss: 475.7832 - accuracy: 0.3438 - MSE: 0.2222 - precision_2: 1.0000 - recall_2: 0.0039 - val_loss: 475.7565 - val_accuracy: 0.3750 - val_MSE: 0.2209 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 54/80\n",
      "12/12 [==============================] - 2s 166ms/step - loss: 475.7434 - accuracy: 0.3398 - MSE: 0.2220 - precision_2: 0.5000 - recall_2: 0.0013 - val_loss: 475.7175 - val_accuracy: 0.3750 - val_MSE: 0.2209 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 55/80\n",
      "12/12 [==============================] - 2s 170ms/step - loss: 475.7065 - accuracy: 0.3385 - MSE: 0.2226 - precision_2: 0.3333 - recall_2: 0.0013 - val_loss: 475.6782 - val_accuracy: 0.3750 - val_MSE: 0.2209 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 56/80\n",
      "12/12 [==============================] - 2s 170ms/step - loss: 475.6688 - accuracy: 0.3398 - MSE: 0.2228 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 475.6392 - val_accuracy: 0.3750 - val_MSE: 0.2209 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 57/80\n",
      "12/12 [==============================] - 2s 168ms/step - loss: 475.6285 - accuracy: 0.3503 - MSE: 0.2225 - precision_2: 1.0000 - recall_2: 0.0013 - val_loss: 475.6001 - val_accuracy: 0.3750 - val_MSE: 0.2209 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 58/80\n",
      "12/12 [==============================] - 2s 173ms/step - loss: 475.5844 - accuracy: 0.3477 - MSE: 0.2214 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 475.5610 - val_accuracy: 0.3750 - val_MSE: 0.2209 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 59/80\n",
      "12/12 [==============================] - 2s 164ms/step - loss: 475.5507 - accuracy: 0.3451 - MSE: 0.2227 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 475.5219 - val_accuracy: 0.3750 - val_MSE: 0.2209 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 60/80\n",
      "12/12 [==============================] - 2s 164ms/step - loss: 475.5077 - accuracy: 0.3776 - MSE: 0.2218 - precision_2: 1.0000 - recall_2: 0.0026 - val_loss: 475.4828 - val_accuracy: 0.3750 - val_MSE: 0.2209 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 61/80\n",
      "12/12 [==============================] - 2s 165ms/step - loss: 475.4724 - accuracy: 0.3555 - MSE: 0.2226 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 475.4437 - val_accuracy: 0.3750 - val_MSE: 0.2209 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 62/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 2s 165ms/step - loss: 475.4352 - accuracy: 0.3542 - MSE: 0.2230 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 475.4047 - val_accuracy: 0.3750 - val_MSE: 0.2209 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 63/80\n",
      "12/12 [==============================] - 2s 186ms/step - loss: 475.3897 - accuracy: 0.3516 - MSE: 0.2216 - precision_2: 1.0000 - recall_2: 0.0026 - val_loss: 475.3657 - val_accuracy: 0.3750 - val_MSE: 0.2209 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 64/80\n",
      "12/12 [==============================] - 3s 208ms/step - loss: 475.3535 - accuracy: 0.3633 - MSE: 0.2223 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 475.3267 - val_accuracy: 0.3750 - val_MSE: 0.2209 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 65/80\n",
      "12/12 [==============================] - 2s 180ms/step - loss: 475.3164 - accuracy: 0.3438 - MSE: 0.2225 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 475.2876 - val_accuracy: 0.3750 - val_MSE: 0.2209 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 66/80\n",
      "12/12 [==============================] - 2s 166ms/step - loss: 475.2734 - accuracy: 0.3607 - MSE: 0.2218 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 475.2486 - val_accuracy: 0.3750 - val_MSE: 0.2209 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 67/80\n",
      "12/12 [==============================] - 2s 168ms/step - loss: 475.2369 - accuracy: 0.3372 - MSE: 0.2223 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 475.2096 - val_accuracy: 0.3750 - val_MSE: 0.2209 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 68/80\n",
      "12/12 [==============================] - 2s 168ms/step - loss: 475.1914 - accuracy: 0.3620 - MSE: 0.2209 - precision_2: 0.5000 - recall_2: 0.0013 - val_loss: 475.1705 - val_accuracy: 0.3750 - val_MSE: 0.2209 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 69/80\n",
      "12/12 [==============================] - 2s 170ms/step - loss: 475.1582 - accuracy: 0.3346 - MSE: 0.2222 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 475.1315 - val_accuracy: 0.3750 - val_MSE: 0.2209 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 70/80\n",
      "12/12 [==============================] - 2s 163ms/step - loss: 475.1161 - accuracy: 0.3594 - MSE: 0.2215 - precision_2: 1.0000 - recall_2: 0.0013 - val_loss: 475.0926 - val_accuracy: 0.3750 - val_MSE: 0.2209 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 71/80\n",
      "12/12 [==============================] - 2s 165ms/step - loss: 475.0772 - accuracy: 0.3464 - MSE: 0.2217 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 475.0536 - val_accuracy: 0.3750 - val_MSE: 0.2210 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 72/80\n",
      "12/12 [==============================] - 2s 169ms/step - loss: 475.0424 - accuracy: 0.3490 - MSE: 0.2225 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 475.0146 - val_accuracy: 0.3750 - val_MSE: 0.2210 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 73/80\n",
      "12/12 [==============================] - 2s 172ms/step - loss: 475.0031 - accuracy: 0.3398 - MSE: 0.2224 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 474.9755 - val_accuracy: 0.3750 - val_MSE: 0.2210 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 74/80\n",
      "12/12 [==============================] - 2s 163ms/step - loss: 474.9608 - accuracy: 0.3685 - MSE: 0.2217 - precision_2: 1.0000 - recall_2: 0.0013 - val_loss: 474.9365 - val_accuracy: 0.3750 - val_MSE: 0.2210 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 75/80\n",
      "12/12 [==============================] - 2s 162ms/step - loss: 474.9234 - accuracy: 0.3594 - MSE: 0.2221 - precision_2: 1.0000 - recall_2: 0.0013 - val_loss: 474.8974 - val_accuracy: 0.3750 - val_MSE: 0.2210 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 76/80\n",
      "12/12 [==============================] - 2s 167ms/step - loss: 474.8822 - accuracy: 0.3594 - MSE: 0.2216 - precision_2: 1.0000 - recall_2: 0.0026 - val_loss: 474.8584 - val_accuracy: 0.3750 - val_MSE: 0.2210 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 77/80\n",
      "12/12 [==============================] - 2s 164ms/step - loss: 474.8449 - accuracy: 0.3568 - MSE: 0.2221 - precision_2: 0.5000 - recall_2: 0.0013 - val_loss: 474.8194 - val_accuracy: 0.3750 - val_MSE: 0.2210 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 78/80\n",
      "12/12 [==============================] - 2s 164ms/step - loss: 474.8066 - accuracy: 0.3555 - MSE: 0.2222 - precision_2: 1.0000 - recall_2: 0.0013 - val_loss: 474.7803 - val_accuracy: 0.3750 - val_MSE: 0.2210 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 79/80\n",
      "12/12 [==============================] - 2s 164ms/step - loss: 474.7682 - accuracy: 0.3685 - MSE: 0.2224 - precision_2: 0.5000 - recall_2: 0.0013 - val_loss: 474.7413 - val_accuracy: 0.3750 - val_MSE: 0.2210 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 80/80\n",
      "12/12 [==============================] - 2s 180ms/step - loss: 474.7268 - accuracy: 0.3568 - MSE: 0.2217 - precision_2: 0.6667 - recall_2: 0.0026 - val_loss: 474.7024 - val_accuracy: 0.3750 - val_MSE: 0.2210 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (64, 32)                  772352    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (64, 32)                  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (64, 32)                  128       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (64, 3)                   99        \n",
      "=================================================================\n",
      "Total params: 772,579\n",
      "Trainable params: 772,515\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "Starting: \n",
      "{'batch_size': 64, 'epochs': 50, 'learning_rate': 1e-05, 'optimizer': 'rmsprop'}\n",
      "---------------------------------------------------------------------------------\n",
      "{   'activation': 'tanh',\n",
      "    'dropout_rate': 0.5,\n",
      "    'filters': 17,\n",
      "    'kernel_size': 3,\n",
      "    'l1_r': 0.01,\n",
      "    'l2_r': 0.001,\n",
      "    'output_layer_activation': 'softmax',\n",
      "    'padding': 'valid',\n",
      "    'start_neurons': 32}\n",
      "Epoch 1/50\n",
      " 2/12 [====>.........................] - ETA: 8s - loss: 121.8359 - accuracy: 0.2969 - MSE: 0.3005 - precision_3: 0.2818 - recall_3: 0.2422WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0280s vs `on_train_batch_end` time: 1.7497s). Check your callbacks.\n",
      "12/12 [==============================] - 4s 361ms/step - loss: 121.4513 - accuracy: 0.3216 - MSE: 0.2920 - precision_3: 0.3066 - recall_3: 0.2344 - val_loss: 120.7769 - val_accuracy: 0.3672 - val_MSE: 0.2391 - val_precision_3: 0.4138 - val_recall_3: 0.1875\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 2s 139ms/step - loss: 120.8452 - accuracy: 0.3724 - MSE: 0.2684 - precision_3: 0.3746 - recall_3: 0.2878 - val_loss: 120.4169 - val_accuracy: 0.3672 - val_MSE: 0.2402 - val_precision_3: 0.3934 - val_recall_3: 0.1875\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 2s 133ms/step - loss: 120.4343 - accuracy: 0.3828 - MSE: 0.2647 - precision_3: 0.3897 - recall_3: 0.3151 - val_loss: 120.0562 - val_accuracy: 0.3672 - val_MSE: 0.2415 - val_precision_3: 0.3871 - val_recall_3: 0.1875\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 2s 137ms/step - loss: 120.0871 - accuracy: 0.3750 - MSE: 0.2674 - precision_3: 0.3791 - recall_3: 0.2982 - val_loss: 119.6749 - val_accuracy: 0.3672 - val_MSE: 0.2424 - val_precision_3: 0.3906 - val_recall_3: 0.1953\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 2s 130ms/step - loss: 119.6225 - accuracy: 0.4089 - MSE: 0.2568 - precision_3: 0.4178 - recall_3: 0.3242 - val_loss: 119.2675 - val_accuracy: 0.3672 - val_MSE: 0.2433 - val_precision_3: 0.3824 - val_recall_3: 0.2031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "12/12 [==============================] - 2s 134ms/step - loss: 119.1801 - accuracy: 0.4062 - MSE: 0.2553 - precision_3: 0.4164 - recall_3: 0.3307 - val_loss: 118.8275 - val_accuracy: 0.3594 - val_MSE: 0.2448 - val_precision_3: 0.4000 - val_recall_3: 0.2188\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 1s 125ms/step - loss: 118.6910 - accuracy: 0.4284 - MSE: 0.2480 - precision_3: 0.4439 - recall_3: 0.3398 - val_loss: 118.3508 - val_accuracy: 0.3594 - val_MSE: 0.2460 - val_precision_3: 0.3784 - val_recall_3: 0.2188\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 2s 130ms/step - loss: 118.1875 - accuracy: 0.4167 - MSE: 0.2487 - precision_3: 0.4255 - recall_3: 0.3307 - val_loss: 117.8504 - val_accuracy: 0.3672 - val_MSE: 0.2470 - val_precision_3: 0.3684 - val_recall_3: 0.2188\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 2s 129ms/step - loss: 117.5886 - accuracy: 0.4349 - MSE: 0.2399 - precision_3: 0.4486 - recall_3: 0.3464 - val_loss: 117.3261 - val_accuracy: 0.3672 - val_MSE: 0.2480 - val_precision_3: 0.3733 - val_recall_3: 0.2188\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 2s 129ms/step - loss: 117.0359 - accuracy: 0.4505 - MSE: 0.2335 - precision_3: 0.4733 - recall_3: 0.3698 - val_loss: 116.7727 - val_accuracy: 0.3672 - val_MSE: 0.2488 - val_precision_3: 0.3846 - val_recall_3: 0.2344\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 2s 128ms/step - loss: 116.4496 - accuracy: 0.4466 - MSE: 0.2316 - precision_3: 0.4876 - recall_3: 0.3828 - val_loss: 116.1874 - val_accuracy: 0.3672 - val_MSE: 0.2499 - val_precision_3: 0.3797 - val_recall_3: 0.2344\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 2s 145ms/step - loss: 115.8680 - accuracy: 0.4544 - MSE: 0.2325 - precision_3: 0.4907 - recall_3: 0.3789 - val_loss: 115.5838 - val_accuracy: 0.3672 - val_MSE: 0.2508 - val_precision_3: 0.3735 - val_recall_3: 0.2422\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 2s 129ms/step - loss: 115.1875 - accuracy: 0.4909 - MSE: 0.2259 - precision_3: 0.5133 - recall_3: 0.4023 - val_loss: 114.9447 - val_accuracy: 0.3672 - val_MSE: 0.2513 - val_precision_3: 0.3735 - val_recall_3: 0.2422\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 2s 130ms/step - loss: 114.5116 - accuracy: 0.4870 - MSE: 0.2212 - precision_3: 0.4983 - recall_3: 0.3919 - val_loss: 114.2978 - val_accuracy: 0.3594 - val_MSE: 0.2526 - val_precision_3: 0.3780 - val_recall_3: 0.2422\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 2s 128ms/step - loss: 113.9141 - accuracy: 0.4492 - MSE: 0.2321 - precision_3: 0.4788 - recall_3: 0.3685 - val_loss: 113.6549 - val_accuracy: 0.3594 - val_MSE: 0.2535 - val_precision_3: 0.3735 - val_recall_3: 0.2422\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 1s 125ms/step - loss: 113.2840 - accuracy: 0.4427 - MSE: 0.2344 - precision_3: 0.4602 - recall_3: 0.3542 - val_loss: 113.0101 - val_accuracy: 0.3594 - val_MSE: 0.2545 - val_precision_3: 0.3690 - val_recall_3: 0.2422\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 2s 131ms/step - loss: 112.6457 - accuracy: 0.4427 - MSE: 0.2387 - precision_3: 0.4814 - recall_3: 0.3711 - val_loss: 112.3511 - val_accuracy: 0.3672 - val_MSE: 0.2557 - val_precision_3: 0.3494 - val_recall_3: 0.2266\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 2s 128ms/step - loss: 111.9444 - accuracy: 0.4727 - MSE: 0.2287 - precision_3: 0.4874 - recall_3: 0.3763 - val_loss: 111.7186 - val_accuracy: 0.3672 - val_MSE: 0.2565 - val_precision_3: 0.3494 - val_recall_3: 0.2266\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 2s 131ms/step - loss: 111.2870 - accuracy: 0.4831 - MSE: 0.2241 - precision_3: 0.5096 - recall_3: 0.4128 - val_loss: 111.0880 - val_accuracy: 0.3672 - val_MSE: 0.2577 - val_precision_3: 0.3373 - val_recall_3: 0.2188\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 2s 129ms/step - loss: 110.6266 - accuracy: 0.4974 - MSE: 0.2188 - precision_3: 0.5358 - recall_3: 0.4089 - val_loss: 110.4510 - val_accuracy: 0.3516 - val_MSE: 0.2590 - val_precision_3: 0.3373 - val_recall_3: 0.2188\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 2s 137ms/step - loss: 109.9629 - accuracy: 0.4935 - MSE: 0.2189 - precision_3: 0.5270 - recall_3: 0.4193 - val_loss: 109.8124 - val_accuracy: 0.3516 - val_MSE: 0.2596 - val_precision_3: 0.3571 - val_recall_3: 0.2344\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 2s 132ms/step - loss: 109.3376 - accuracy: 0.4844 - MSE: 0.2201 - precision_3: 0.5190 - recall_3: 0.3919 - val_loss: 109.1710 - val_accuracy: 0.3594 - val_MSE: 0.2603 - val_precision_3: 0.3614 - val_recall_3: 0.2344\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 2s 130ms/step - loss: 108.6795 - accuracy: 0.4857 - MSE: 0.2238 - precision_3: 0.5141 - recall_3: 0.4036 - val_loss: 108.5130 - val_accuracy: 0.3594 - val_MSE: 0.2611 - val_precision_3: 0.3373 - val_recall_3: 0.2188\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 2s 130ms/step - loss: 108.0475 - accuracy: 0.4688 - MSE: 0.2242 - precision_3: 0.4967 - recall_3: 0.3893 - val_loss: 107.8649 - val_accuracy: 0.3594 - val_MSE: 0.2611 - val_precision_3: 0.3373 - val_recall_3: 0.2188\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 2s 130ms/step - loss: 107.3214 - accuracy: 0.4922 - MSE: 0.2115 - precision_3: 0.5429 - recall_3: 0.4284 - val_loss: 107.2294 - val_accuracy: 0.3516 - val_MSE: 0.2618 - val_precision_3: 0.3294 - val_recall_3: 0.2188\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 2s 131ms/step - loss: 106.6769 - accuracy: 0.5091 - MSE: 0.2108 - precision_3: 0.5523 - recall_3: 0.4401 - val_loss: 106.5943 - val_accuracy: 0.3516 - val_MSE: 0.2623 - val_precision_3: 0.3494 - val_recall_3: 0.2266\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 2s 127ms/step - loss: 106.0818 - accuracy: 0.4935 - MSE: 0.2201 - precision_3: 0.5208 - recall_3: 0.3906 - val_loss: 105.9563 - val_accuracy: 0.3438 - val_MSE: 0.2630 - val_precision_3: 0.3452 - val_recall_3: 0.2266\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 2s 129ms/step - loss: 105.4147 - accuracy: 0.5091 - MSE: 0.2124 - precision_3: 0.5400 - recall_3: 0.4219 - val_loss: 105.3168 - val_accuracy: 0.3438 - val_MSE: 0.2635 - val_precision_3: 0.3372 - val_recall_3: 0.2266\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 2s 131ms/step - loss: 104.7526 - accuracy: 0.5065 - MSE: 0.2114 - precision_3: 0.5378 - recall_3: 0.4349 - val_loss: 104.6725 - val_accuracy: 0.3359 - val_MSE: 0.2643 - val_precision_3: 0.3294 - val_recall_3: 0.2188\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 2s 132ms/step - loss: 104.1232 - accuracy: 0.5000 - MSE: 0.2121 - precision_3: 0.5391 - recall_3: 0.4128 - val_loss: 104.0282 - val_accuracy: 0.3359 - val_MSE: 0.2649 - val_precision_3: 0.3218 - val_recall_3: 0.2188\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 2s 139ms/step - loss: 103.5148 - accuracy: 0.4714 - MSE: 0.2209 - precision_3: 0.5093 - recall_3: 0.3932 - val_loss: 103.3993 - val_accuracy: 0.3359 - val_MSE: 0.2654 - val_precision_3: 0.3294 - val_recall_3: 0.2188\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 2s 130ms/step - loss: 102.8242 - accuracy: 0.5208 - MSE: 0.2085 - precision_3: 0.5571 - recall_3: 0.4258 - val_loss: 102.7847 - val_accuracy: 0.3438 - val_MSE: 0.2660 - val_precision_3: 0.3333 - val_recall_3: 0.2188\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 2s 129ms/step - loss: 102.2228 - accuracy: 0.5130 - MSE: 0.2117 - precision_3: 0.5179 - recall_3: 0.4141 - val_loss: 102.1594 - val_accuracy: 0.3359 - val_MSE: 0.2662 - val_precision_3: 0.3373 - val_recall_3: 0.2188\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 2s 126ms/step - loss: 101.5883 - accuracy: 0.5221 - MSE: 0.2086 - precision_3: 0.5502 - recall_3: 0.4427 - val_loss: 101.5432 - val_accuracy: 0.3438 - val_MSE: 0.2661 - val_precision_3: 0.3333 - val_recall_3: 0.2188\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 2s 129ms/step - loss: 100.9624 - accuracy: 0.5391 - MSE: 0.2047 - precision_3: 0.5891 - recall_3: 0.4518 - val_loss: 100.9258 - val_accuracy: 0.3516 - val_MSE: 0.2663 - val_precision_3: 0.3372 - val_recall_3: 0.2266\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 2s 130ms/step - loss: 100.3175 - accuracy: 0.5417 - MSE: 0.2006 - precision_3: 0.5866 - recall_3: 0.4674 - val_loss: 100.3070 - val_accuracy: 0.3438 - val_MSE: 0.2659 - val_precision_3: 0.3372 - val_recall_3: 0.2266\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 2s 129ms/step - loss: 99.7528 - accuracy: 0.4948 - MSE: 0.2119 - precision_3: 0.5140 - recall_3: 0.4076 - val_loss: 99.7054 - val_accuracy: 0.3594 - val_MSE: 0.2656 - val_precision_3: 0.3372 - val_recall_3: 0.2266\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 2s 130ms/step - loss: 99.1304 - accuracy: 0.5430 - MSE: 0.2019 - precision_3: 0.5835 - recall_3: 0.4505 - val_loss: 99.1091 - val_accuracy: 0.3516 - val_MSE: 0.2656 - val_precision_3: 0.3412 - val_recall_3: 0.2266\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 2s 131ms/step - loss: 98.5211 - accuracy: 0.5299 - MSE: 0.2032 - precision_3: 0.5594 - recall_3: 0.4414 - val_loss: 98.5120 - val_accuracy: 0.3516 - val_MSE: 0.2653 - val_precision_3: 0.3412 - val_recall_3: 0.2266\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 2s 136ms/step - loss: 97.8975 - accuracy: 0.5312 - MSE: 0.1962 - precision_3: 0.5849 - recall_3: 0.4531 - val_loss: 97.9064 - val_accuracy: 0.3516 - val_MSE: 0.2648 - val_precision_3: 0.3333 - val_recall_3: 0.2188\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 2s 129ms/step - loss: 97.3045 - accuracy: 0.5391 - MSE: 0.2014 - precision_3: 0.5563 - recall_3: 0.4375 - val_loss: 97.3040 - val_accuracy: 0.3438 - val_MSE: 0.2646 - val_precision_3: 0.3253 - val_recall_3: 0.2109\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 2s 127ms/step - loss: 96.7409 - accuracy: 0.5352 - MSE: 0.2052 - precision_3: 0.5755 - recall_3: 0.4518 - val_loss: 96.7082 - val_accuracy: 0.3359 - val_MSE: 0.2643 - val_precision_3: 0.3253 - val_recall_3: 0.2109\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 2s 131ms/step - loss: 96.1571 - accuracy: 0.5065 - MSE: 0.2073 - precision_3: 0.5411 - recall_3: 0.4284 - val_loss: 96.1148 - val_accuracy: 0.3438 - val_MSE: 0.2639 - val_precision_3: 0.3210 - val_recall_3: 0.2031\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 2s 130ms/step - loss: 95.5245 - accuracy: 0.5495 - MSE: 0.1991 - precision_3: 0.5879 - recall_3: 0.4701 - val_loss: 95.5131 - val_accuracy: 0.3359 - val_MSE: 0.2635 - val_precision_3: 0.3125 - val_recall_3: 0.1953\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 2s 130ms/step - loss: 94.9254 - accuracy: 0.5534 - MSE: 0.1958 - precision_3: 0.6047 - recall_3: 0.4661 - val_loss: 94.9174 - val_accuracy: 0.3516 - val_MSE: 0.2635 - val_precision_3: 0.3125 - val_recall_3: 0.1953\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 2s 126ms/step - loss: 94.2750 - accuracy: 0.5521 - MSE: 0.1935 - precision_3: 0.5819 - recall_3: 0.4531 - val_loss: 94.3122 - val_accuracy: 0.3438 - val_MSE: 0.2624 - val_precision_3: 0.3210 - val_recall_3: 0.2031\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 2s 130ms/step - loss: 93.7671 - accuracy: 0.5456 - MSE: 0.2032 - precision_3: 0.5876 - recall_3: 0.4583 - val_loss: 93.7117 - val_accuracy: 0.3516 - val_MSE: 0.2613 - val_precision_3: 0.3165 - val_recall_3: 0.1953\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 2s 129ms/step - loss: 93.0980 - accuracy: 0.5638 - MSE: 0.1928 - precision_3: 0.5946 - recall_3: 0.4622 - val_loss: 93.1106 - val_accuracy: 0.3516 - val_MSE: 0.2606 - val_precision_3: 0.3171 - val_recall_3: 0.2031\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 2s 145ms/step - loss: 92.5422 - accuracy: 0.5508 - MSE: 0.1986 - precision_3: 0.5855 - recall_3: 0.4727 - val_loss: 92.5070 - val_accuracy: 0.3594 - val_MSE: 0.2597 - val_precision_3: 0.3333 - val_recall_3: 0.2109\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 2s 134ms/step - loss: 91.9095 - accuracy: 0.5443 - MSE: 0.1948 - precision_3: 0.5897 - recall_3: 0.4492 - val_loss: 91.9074 - val_accuracy: 0.3594 - val_MSE: 0.2595 - val_precision_3: 0.3293 - val_recall_3: 0.2109\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (32, 32)                  772352    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (32, 32)                  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (32, 32)                  128       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (32, 3)                   99        \n",
      "=================================================================\n",
      "Total params: 772,579\n",
      "Trainable params: 772,515\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "Starting: \n",
      "{   'batch_size': 32,\n",
      "    'epochs': 75,\n",
      "    'learning_rate': 0.0001,\n",
      "    'optimizer': 'rmsprop'}\n",
      "---------------------------------------------------------------------------------\n",
      "{   'activation': 'relu',\n",
      "    'dropout_rate': 0.2,\n",
      "    'filters': 15,\n",
      "    'kernel_size': 3,\n",
      "    'l1_r': 0.2,\n",
      "    'l2_r': 0.2,\n",
      "    'output_layer_activation': 'softmax',\n",
      "    'padding': 'valid',\n",
      "    'start_neurons': 32}\n",
      "Epoch 1/75\n",
      " 2/25 [=>............................] - ETA: 22s - loss: 9710.8799 - accuracy: 0.3594 - MSE: 0.2644 - precision_4: 0.3673 - recall_4: 0.2812WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0517s vs `on_train_batch_end` time: 1.8714s). Check your callbacks.\n",
      "25/25 [==============================] - 4s 179ms/step - loss: 20108.5801 - accuracy: 0.3200 - MSE: 0.2895 - precision_4: 0.3261 - recall_4: 0.2425 - val_loss: 60792.8867 - val_accuracy: 0.3047 - val_MSE: 0.2843 - val_precision_4: 0.2647 - val_recall_4: 0.1406\n",
      "Epoch 2/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 10882.1279 - accuracy: 0.3250 - MSE: 0.2834 - precision_4: 0.3401 - recall_4: 0.2525 - val_loss: 61181.5703 - val_accuracy: 0.3203 - val_MSE: 0.2790 - val_precision_4: 0.2545 - val_recall_4: 0.1094E: 0.2834 - precision_4: 0.3401 - recall_4: 0.252\n",
      "Epoch 3/75\n",
      "25/25 [==============================] - 2s 80ms/step - loss: 14322.4551 - accuracy: 0.3113 - MSE: 0.2922 - precision_4: 0.3208 - recall_4: 0.2463 - val_loss: 61741.3789 - val_accuracy: 0.3125 - val_MSE: 0.2757 - val_precision_4: 0.2653 - val_recall_4: 0.1016uracy: 0.2981 - MSE: 0.2965 - precision_4: 0.3065 -\n",
      "Epoch 4/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 7783.3262 - accuracy: 0.3237 - MSE: 0.2900 - precision_4: 0.3238 - recall_4: 0.2400 - val_loss: 61549.5000 - val_accuracy: 0.3125 - val_MSE: 0.2809 - val_precision_4: 0.2353 - val_recall_4: 0.0938\n",
      "Epoch 5/75\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 7190.6968 - accuracy: 0.3075 - MSE: 0.2930 - precision_4: 0.3002 - recall_4: 0.2262 - val_loss: 61689.8125 - val_accuracy: 0.3047 - val_MSE: 0.2777 - val_precision_4: 0.2830 - val_recall_4: 0.1172\n",
      "Epoch 6/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 5098.9414 - accuracy: 0.3438 - MSE: 0.2886 - precision_4: 0.3333 - recall_4: 0.2475 - val_loss: 62922.4883 - val_accuracy: 0.3125 - val_MSE: 0.2786 - val_precision_4: 0.2778 - val_recall_4: 0.1172\n",
      "Epoch 7/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 5124.2881 - accuracy: 0.3338 - MSE: 0.2777 - precision_4: 0.3484 - recall_4: 0.2500 - val_loss: 62491.7656 - val_accuracy: 0.3281 - val_MSE: 0.2830 - val_precision_4: 0.2759 - val_recall_4: 0.1250\n",
      "Epoch 8/75\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 2617.3188 - accuracy: 0.3425 - MSE: 0.2759 - precision_4: 0.3488 - recall_4: 0.2450 - val_loss: 62632.8203 - val_accuracy: 0.3359 - val_MSE: 0.2808 - val_precision_4: 0.3000 - val_recall_4: 0.1406\n",
      "Epoch 9/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 4028.7815 - accuracy: 0.3475 - MSE: 0.2792 - precision_4: 0.3367 - recall_4: 0.2475 - val_loss: 89520.2344 - val_accuracy: 0.3594 - val_MSE: 0.2797 - val_precision_4: 0.3226 - val_recall_4: 0.1562\n",
      "Epoch 10/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 2s 73ms/step - loss: 4452.5464 - accuracy: 0.3638 - MSE: 0.2689 - precision_4: 0.3656 - recall_4: 0.2600 - val_loss: 89526.5234 - val_accuracy: 0.3828 - val_MSE: 0.2789 - val_precision_4: 0.3571 - val_recall_4: 0.1953\n",
      "Epoch 11/75\n",
      "25/25 [==============================] - 2s 80ms/step - loss: 3619.3223 - accuracy: 0.3550 - MSE: 0.2717 - precision_4: 0.3603 - recall_4: 0.2562 - val_loss: 89018.2578 - val_accuracy: 0.3594 - val_MSE: 0.2791 - val_precision_4: 0.3380 - val_recall_4: 0.1875\n",
      "Epoch 12/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 3172.8291 - accuracy: 0.3288 - MSE: 0.2806 - precision_4: 0.3309 - recall_4: 0.2288 - val_loss: 86934.6172 - val_accuracy: 0.3906 - val_MSE: 0.2796 - val_precision_4: 0.3467 - val_recall_4: 0.2031 - accuracy: 0.3344 - MSE: 0.2776 - precision_4: 0.3295 - reca\n",
      "Epoch 13/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 3188.1531 - accuracy: 0.3500 - MSE: 0.2726 - precision_4: 0.3383 - recall_4: 0.2275 - val_loss: 83986.6953 - val_accuracy: 0.3672 - val_MSE: 0.2871 - val_precision_4: 0.3288 - val_recall_4: 0.18756548 - accuracy: 0.3382 - MSE: 0.2769 - precision_4: 0.3203 \n",
      "Epoch 14/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 2681.2961 - accuracy: 0.3725 - MSE: 0.2623 - precision_4: 0.3711 - recall_4: 0.2500 - val_loss: 78051.3047 - val_accuracy: 0.3672 - val_MSE: 0.2923 - val_precision_4: 0.3472 - val_recall_4: 0.1953 accuracy: 0.3551 - MSE: 0.2721 - precisio\n",
      "Epoch 15/75\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 2439.5461 - accuracy: 0.3487 - MSE: 0.2691 - precision_4: 0.3504 - recall_4: 0.2138 - val_loss: 82465.4219 - val_accuracy: 0.3828 - val_MSE: 0.2905 - val_precision_4: 0.3671 - val_recall_4: 0.2266\n",
      "Epoch 16/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 2221.9705 - accuracy: 0.3512 - MSE: 0.2632 - precision_4: 0.3498 - recall_4: 0.2212 - val_loss: 65171.3203 - val_accuracy: 0.3672 - val_MSE: 0.2963 - val_precision_4: 0.3333 - val_recall_4: 0.2188y: 0.3569 - MSE: 0.2653 - precision_4: 0.3497 - recall - ETA: 0s - loss: 2235.8101 - accuracy: 0.3516 - MSE: 0.2636 - precision_4: 0.3469 - recall_4: 0.\n",
      "Epoch 17/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 2114.2876 - accuracy: 0.3525 - MSE: 0.2622 - precision_4: 0.3543 - recall_4: 0.2037 - val_loss: 74026.9141 - val_accuracy: 0.3438 - val_MSE: 0.3022 - val_precision_4: 0.3068 - val_recall_4: 0.2109\n",
      "Epoch 18/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1951.0095 - accuracy: 0.3825 - MSE: 0.2560 - precision_4: 0.4038 - recall_4: 0.2362 - val_loss: 68155.3594 - val_accuracy: 0.3672 - val_MSE: 0.3029 - val_precision_4: 0.3373 - val_recall_4: 0.2188\n",
      "Epoch 19/75\n",
      "25/25 [==============================] - 2s 78ms/step - loss: 1953.8363 - accuracy: 0.3812 - MSE: 0.2504 - precision_4: 0.4014 - recall_4: 0.2212 - val_loss: 66614.2734 - val_accuracy: 0.3594 - val_MSE: 0.3165 - val_precision_4: 0.3333 - val_recall_4: 0.2188\n",
      "Epoch 20/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1738.4595 - accuracy: 0.3625 - MSE: 0.2501 - precision_4: 0.4014 - recall_4: 0.2138 - val_loss: 64364.9219 - val_accuracy: 0.3672 - val_MSE: 0.3148 - val_precision_4: 0.3111 - val_recall_4: 0.2188\n",
      "Epoch 21/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1644.3335 - accuracy: 0.3887 - MSE: 0.2447 - precision_4: 0.4198 - recall_4: 0.2062 - val_loss: 61695.2656 - val_accuracy: 0.3594 - val_MSE: 0.3166 - val_precision_4: 0.3263 - val_recall_4: 0.2422\n",
      "Epoch 22/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1680.2114 - accuracy: 0.4250 - MSE: 0.2386 - precision_4: 0.4487 - recall_4: 0.2350 - val_loss: 58551.0508 - val_accuracy: 0.3594 - val_MSE: 0.3223 - val_precision_4: 0.3462 - val_recall_4: 0.2812\n",
      "Epoch 23/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 2221.5479 - accuracy: 0.3963 - MSE: 0.2340 - precision_4: 0.4476 - recall_4: 0.2138 - val_loss: 58389.0039 - val_accuracy: 0.3594 - val_MSE: 0.3331 - val_precision_4: 0.3196 - val_recall_4: 0.2422\n",
      "Epoch 24/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 2213.3916 - accuracy: 0.4238 - MSE: 0.2270 - precision_4: 0.4880 - recall_4: 0.2288 - val_loss: 60174.6680 - val_accuracy: 0.3359 - val_MSE: 0.3280 - val_precision_4: 0.3333 - val_recall_4: 0.2578\n",
      "Epoch 25/75\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 1548.8625 - accuracy: 0.4187 - MSE: 0.2274 - precision_4: 0.4726 - recall_4: 0.2262 - val_loss: 59212.2617 - val_accuracy: 0.3438 - val_MSE: 0.3272 - val_precision_4: 0.3469 - val_recall_4: 0.2656\n",
      "Epoch 26/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1503.5764 - accuracy: 0.4112 - MSE: 0.2273 - precision_4: 0.4737 - recall_4: 0.2250 - val_loss: 55169.3164 - val_accuracy: 0.3281 - val_MSE: 0.3350 - val_precision_4: 0.2929 - val_recall_4: 0.2266\n",
      "Epoch 27/75\n",
      "25/25 [==============================] - 2s 79ms/step - loss: 1505.7708 - accuracy: 0.4087 - MSE: 0.2331 - precision_4: 0.4505 - recall_4: 0.2050 - val_loss: 53847.1953 - val_accuracy: 0.3359 - val_MSE: 0.3193 - val_precision_4: 0.3229 - val_recall_4: 0.2422\n",
      "Epoch 28/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1288.3329 - accuracy: 0.4475 - MSE: 0.2198 - precision_4: 0.4904 - recall_4: 0.2225 - val_loss: 53140.0742 - val_accuracy: 0.2734 - val_MSE: 0.3343 - val_precision_4: 0.2947 - val_recall_4: 0.2188\n",
      "Epoch 29/75\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 2966.6782 - accuracy: 0.4200 - MSE: 0.2252 - precision_4: 0.4803 - recall_4: 0.2138 - val_loss: 52242.3594 - val_accuracy: 0.3125 - val_MSE: 0.3330 - val_precision_4: 0.3438 - val_recall_4: 0.2578\n",
      "Epoch 30/75\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 1218.0083 - accuracy: 0.4338 - MSE: 0.2218 - precision_4: 0.4918 - recall_4: 0.2237 - val_loss: 46639.1445 - val_accuracy: 0.3047 - val_MSE: 0.3356 - val_precision_4: 0.3301 - val_recall_4: 0.26569243 - accuracy: 0.4604 - MSE: 0.2133 - precision_4: 0.5221 - recall_4:  - ETA: 0s - loss: 1232.8713 - accuracy: 0.4444 - MSE: 0.2178 - precision_4: 0.5037 - \n",
      "Epoch 31/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1675.7437 - accuracy: 0.4275 - MSE: 0.2282 - precision_4: 0.4580 - recall_4: 0.2113 - val_loss: 48362.5352 - val_accuracy: 0.3203 - val_MSE: 0.3384 - val_precision_4: 0.3208 - val_recall_4: 0.2656\n",
      "Epoch 32/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1392.6919 - accuracy: 0.4387 - MSE: 0.2221 - precision_4: 0.5134 - recall_4: 0.2400 - val_loss: 46741.5703 - val_accuracy: 0.2812 - val_MSE: 0.3490 - val_precision_4: 0.2946 - val_recall_4: 0.2578\n",
      "Epoch 33/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1091.7690 - accuracy: 0.4400 - MSE: 0.2240 - precision_4: 0.4957 - recall_4: 0.2150 - val_loss: 44891.5430 - val_accuracy: 0.3125 - val_MSE: 0.3499 - val_precision_4: 0.3186 - val_recall_4: 0.2812acy: 0.4432 - MSE: 0.2233 - precision_4: 0.4935 - recall_4\n",
      "Epoch 34/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1135.8883 - accuracy: 0.4288 - MSE: 0.2255 - precision_4: 0.4715 - recall_4: 0.2375 - val_loss: 36928.0352 - val_accuracy: 0.3438 - val_MSE: 0.3358 - val_precision_4: 0.3246 - val_recall_4: 0.2891\n",
      "Epoch 35/75\n",
      "25/25 [==============================] - 2s 80ms/step - loss: 1066.6925 - accuracy: 0.4425 - MSE: 0.2174 - precision_4: 0.5228 - recall_4: 0.2438 - val_loss: 35807.1016 - val_accuracy: 0.3594 - val_MSE: 0.3253 - val_precision_4: 0.3571 - val_recall_4: 0.3125\n",
      "Epoch 36/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1043.5753 - accuracy: 0.4325 - MSE: 0.2269 - precision_4: 0.4806 - recall_4: 0.2163 - val_loss: 35302.3711 - val_accuracy: 0.3125 - val_MSE: 0.3400 - val_precision_4: 0.3036 - val_recall_4: 0.2656\n",
      "Epoch 37/75\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 6770.3638 - accuracy: 0.4437 - MSE: 0.2222 - precision_4: 0.4791 - recall_4: 0.2150 - val_loss: 34812.1953 - val_accuracy: 0.3281 - val_MSE: 0.3452 - val_precision_4: 0.3246 - val_recall_4: 0.2891\n",
      "Epoch 38/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 2s 71ms/step - loss: 3200.6504 - accuracy: 0.4475 - MSE: 0.2188 - precision_4: 0.5144 - recall_4: 0.2237 - val_loss: 34045.9492 - val_accuracy: 0.3281 - val_MSE: 0.3375 - val_precision_4: 0.3113 - val_recall_4: 0.2578\n",
      "Epoch 39/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1459.8187 - accuracy: 0.4575 - MSE: 0.2195 - precision_4: 0.5082 - recall_4: 0.2338 - val_loss: 20958.4238 - val_accuracy: 0.3125 - val_MSE: 0.3275 - val_precision_4: 0.3333 - val_recall_4: 0.2734\n",
      "Epoch 40/75\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 946.2941 - accuracy: 0.4363 - MSE: 0.2182 - precision_4: 0.5014 - recall_4: 0.2300 - val_loss: 20627.0547 - val_accuracy: 0.3047 - val_MSE: 0.3413 - val_precision_4: 0.3178 - val_recall_4: 0.2656 - accuracy: 0.4160 - MSE: 0.2217 - precision_4: 0.4874 - recall\n",
      "Epoch 41/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1270.0406 - accuracy: 0.4313 - MSE: 0.2194 - precision_4: 0.4759 - recall_4: 0.2100 - val_loss: 20615.3770 - val_accuracy: 0.2734 - val_MSE: 0.3485 - val_precision_4: 0.2857 - val_recall_4: 0.2500\n",
      "Epoch 42/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1476.8248 - accuracy: 0.4613 - MSE: 0.2124 - precision_4: 0.5155 - recall_4: 0.2488 - val_loss: 19167.5508 - val_accuracy: 0.2969 - val_MSE: 0.3445 - val_precision_4: 0.2870 - val_recall_4: 0.2422\n",
      "Epoch 43/75\n",
      "25/25 [==============================] - 2s 78ms/step - loss: 1215.6893 - accuracy: 0.4550 - MSE: 0.2148 - precision_4: 0.5160 - recall_4: 0.2425 - val_loss: 28273.1855 - val_accuracy: 0.3047 - val_MSE: 0.3407 - val_precision_4: 0.2970 - val_recall_4: 0.2344\n",
      "Epoch 44/75\n",
      "25/25 [==============================] - 2s 70ms/step - loss: 866.2102 - accuracy: 0.4563 - MSE: 0.2135 - precision_4: 0.5339 - recall_4: 0.2463 - val_loss: 18086.2949 - val_accuracy: 0.3047 - val_MSE: 0.3444 - val_precision_4: 0.2883 - val_recall_4: 0.2500\n",
      "Epoch 45/75\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1093.5159 - accuracy: 0.4613 - MSE: 0.2117 - precision_4: 0.5285 - recall_4: 0.2438 - val_loss: 18927.3496 - val_accuracy: 0.3672 - val_MSE: 0.3325 - val_precision_4: 0.3365 - val_recall_4: 0.2734\n",
      "Epoch 46/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 843.5789 - accuracy: 0.4425 - MSE: 0.2164 - precision_4: 0.5135 - recall_4: 0.2375 - val_loss: 18986.8730 - val_accuracy: 0.3594 - val_MSE: 0.3343 - val_precision_4: 0.3465 - val_recall_4: 0.2734ccuracy: 0.4323 - MSE: 0.2189 - precision_4: 0.5000 - recall_4\n",
      "Epoch 47/75\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 883.4608 - accuracy: 0.4363 - MSE: 0.2130 - precision_4: 0.5415 - recall_4: 0.2362 - val_loss: 17718.2090 - val_accuracy: 0.3516 - val_MSE: 0.3182 - val_precision_4: 0.3500 - val_recall_4: 0.2734\n",
      "Epoch 48/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 765.9964 - accuracy: 0.4588 - MSE: 0.2096 - precision_4: 0.5423 - recall_4: 0.2562 - val_loss: 18188.2441 - val_accuracy: 0.3359 - val_MSE: 0.3336 - val_precision_4: 0.3366 - val_recall_4: 0.2656\n",
      "Epoch 49/75\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 1087.9489 - accuracy: 0.4725 - MSE: 0.2117 - precision_4: 0.5412 - recall_4: 0.2625 - val_loss: 16792.5820 - val_accuracy: 0.3359 - val_MSE: 0.3372 - val_precision_4: 0.3010 - val_recall_4: 0.2422\n",
      "Epoch 50/75\n",
      "25/25 [==============================] - 2s 70ms/step - loss: 797.0096 - accuracy: 0.4450 - MSE: 0.2168 - precision_4: 0.5182 - recall_4: 0.2488 - val_loss: 16109.8525 - val_accuracy: 0.3516 - val_MSE: 0.3155 - val_precision_4: 0.3267 - val_recall_4: 0.2578\n",
      "Epoch 51/75\n",
      "25/25 [==============================] - 2s 79ms/step - loss: 9502.7627 - accuracy: 0.4613 - MSE: 0.2103 - precision_4: 0.5430 - recall_4: 0.2525 - val_loss: 13434.8252 - val_accuracy: 0.3281 - val_MSE: 0.3296 - val_precision_4: 0.3100 - val_recall_4: 0.2422\n",
      "Epoch 52/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 742.2438 - accuracy: 0.4762 - MSE: 0.2064 - precision_4: 0.5741 - recall_4: 0.2663 - val_loss: 23901.6836 - val_accuracy: 0.3438 - val_MSE: 0.3155 - val_precision_4: 0.3431 - val_recall_4: 0.2734\n",
      "Epoch 53/75\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1672.4396 - accuracy: 0.4588 - MSE: 0.2096 - precision_4: 0.5405 - recall_4: 0.2587 - val_loss: 19388.3652 - val_accuracy: 0.3516 - val_MSE: 0.3073 - val_precision_4: 0.3587 - val_recall_4: 0.2578\n",
      "Epoch 54/75\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 1850.8170 - accuracy: 0.4600 - MSE: 0.2160 - precision_4: 0.5270 - recall_4: 0.2438 - val_loss: 18202.5020 - val_accuracy: 0.3594 - val_MSE: 0.2989 - val_precision_4: 0.3488 - val_recall_4: 0.2344\n",
      "Epoch 55/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1149.3899 - accuracy: 0.4588 - MSE: 0.2158 - precision_4: 0.5316 - recall_4: 0.2525 - val_loss: 30908.7520 - val_accuracy: 0.3203 - val_MSE: 0.3026 - val_precision_4: 0.3516 - val_recall_4: 0.2500\n",
      "Epoch 56/75\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1151.3424 - accuracy: 0.4688 - MSE: 0.2083 - precision_4: 0.5337 - recall_4: 0.2575 - val_loss: 22707.1680 - val_accuracy: 0.3516 - val_MSE: 0.3050 - val_precision_4: 0.3516 - val_recall_4: 0.2500\n",
      "Epoch 57/75\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 633.4688 - accuracy: 0.4863 - MSE: 0.2078 - precision_4: 0.5462 - recall_4: 0.2663 - val_loss: 23186.2500 - val_accuracy: 0.3438 - val_MSE: 0.3079 - val_precision_4: 0.3673 - val_recall_4: 0.2812\n",
      "Epoch 58/75\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1931.6373 - accuracy: 0.4575 - MSE: 0.2148 - precision_4: 0.5127 - recall_4: 0.2525 - val_loss: 17770.2637 - val_accuracy: 0.3750 - val_MSE: 0.2952 - val_precision_4: 0.3763 - val_recall_4: 0.2734\n",
      "Epoch 59/75\n",
      "25/25 [==============================] - 2s 79ms/step - loss: 995.4670 - accuracy: 0.4363 - MSE: 0.2208 - precision_4: 0.4824 - recall_4: 0.2400 - val_loss: 3150.4131 - val_accuracy: 0.3438 - val_MSE: 0.3080 - val_precision_4: 0.3636 - val_recall_4: 0.2812\n",
      "Epoch 60/75\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 789.2563 - accuracy: 0.4800 - MSE: 0.2072 - precision_4: 0.5598 - recall_4: 0.2750 - val_loss: 3348.2100 - val_accuracy: 0.3516 - val_MSE: 0.3008 - val_precision_4: 0.3711 - val_recall_4: 0.2812\n",
      "Epoch 61/75\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 1403.6804 - accuracy: 0.4588 - MSE: 0.2132 - precision_4: 0.5156 - recall_4: 0.2475 - val_loss: 5392.6465 - val_accuracy: 0.3438 - val_MSE: 0.3062 - val_precision_4: 0.3333 - val_recall_4: 0.2344\n",
      "Epoch 62/75\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 624.8481 - accuracy: 0.4787 - MSE: 0.2088 - precision_4: 0.5434 - recall_4: 0.2663 - val_loss: 21309.5469 - val_accuracy: 0.3594 - val_MSE: 0.3152 - val_precision_4: 0.3261 - val_recall_4: 0.2344\n",
      "Epoch 63/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 577.0038 - accuracy: 0.4563 - MSE: 0.2105 - precision_4: 0.5161 - recall_4: 0.2600 - val_loss: 3455.4409 - val_accuracy: 0.3203 - val_MSE: 0.3032 - val_precision_4: 0.3511 - val_recall_4: 0.2578\n",
      "Epoch 64/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 593.5771 - accuracy: 0.4988 - MSE: 0.2060 - precision_4: 0.5564 - recall_4: 0.2775 - val_loss: 1285.1289 - val_accuracy: 0.3828 - val_MSE: 0.3010 - val_precision_4: 0.4130 - val_recall_4: 0.2969\n",
      "Epoch 65/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 622.5665 - accuracy: 0.4525 - MSE: 0.2134 - precision_4: 0.5129 - recall_4: 0.2488 - val_loss: 11772.8086 - val_accuracy: 0.3906 - val_MSE: 0.2923 - val_precision_4: 0.3933 - val_recall_4: 0.2734\n",
      "Epoch 66/75\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 806.4277 - accuracy: 0.4525 - MSE: 0.2146 - precision_4: 0.5061 - recall_4: 0.2600 - val_loss: 13373.0596 - val_accuracy: 0.3750 - val_MSE: 0.3006 - val_precision_4: 0.3837 - val_recall_4: 0.2578\n",
      "Epoch 67/75\n",
      "25/25 [==============================] - 2s 79ms/step - loss: 859.7643 - accuracy: 0.4475 - MSE: 0.2193 - precision_4: 0.5257 - recall_4: 0.2425 - val_loss: 5555.0376 - val_accuracy: 0.3828 - val_MSE: 0.2942 - val_precision_4: 0.3810 - val_recall_4: 0.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 955.1658 - accuracy: 0.4487 - MSE: 0.2145 - precision_4: 0.4922 - recall_4: 0.2375 - val_loss: 12751.9561 - val_accuracy: 0.3125 - val_MSE: 0.3237 - val_precision_4: 0.3444 - val_recall_4: 0.2422\n",
      "Epoch 69/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 753.9281 - accuracy: 0.4538 - MSE: 0.2102 - precision_4: 0.5396 - recall_4: 0.2725 - val_loss: 2848.1702 - val_accuracy: 0.2969 - val_MSE: 0.3181 - val_precision_4: 0.3146 - val_recall_4: 0.2188\n",
      "Epoch 70/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 596.8755 - accuracy: 0.4925 - MSE: 0.2015 - precision_4: 0.5649 - recall_4: 0.2775 - val_loss: 2550.3491 - val_accuracy: 0.3359 - val_MSE: 0.3188 - val_precision_4: 0.3500 - val_recall_4: 0.2734\n",
      "Epoch 71/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 867.4701 - accuracy: 0.4650 - MSE: 0.2111 - precision_4: 0.5214 - recall_4: 0.2438 - val_loss: 2490.6199 - val_accuracy: 0.3203 - val_MSE: 0.3124 - val_precision_4: 0.3191 - val_recall_4: 0.2344accuracy: 0.4504 - MSE: 0.2131 - precision_4: 0.5119 - recall_4\n",
      "Epoch 72/75\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 497.3844 - accuracy: 0.4875 - MSE: 0.2069 - precision_4: 0.5573 - recall_4: 0.2675 - val_loss: 2393.2458 - val_accuracy: 0.3516 - val_MSE: 0.3102 - val_precision_4: 0.3333 - val_recall_4: 0.2344601 - accuracy: 0.4908 - MSE: 0.2089 - precision_4: 0.5595 - recall_\n",
      "Epoch 73/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 864.3328 - accuracy: 0.4725 - MSE: 0.2080 - precision_4: 0.5352 - recall_4: 0.2562 - val_loss: 2276.9590 - val_accuracy: 0.3672 - val_MSE: 0.3144 - val_precision_4: 0.3367 - val_recall_4: 0.2578\n",
      "Epoch 74/75\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 1645.0337 - accuracy: 0.4638 - MSE: 0.2086 - precision_4: 0.5387 - recall_4: 0.2612 - val_loss: 3260.4666 - val_accuracy: 0.3359 - val_MSE: 0.3274 - val_precision_4: 0.3265 - val_recall_4: 0.2500\n",
      "Epoch 75/75\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1118.0532 - accuracy: 0.4825 - MSE: 0.2027 - precision_4: 0.5595 - recall_4: 0.2763 - val_loss: 2004.9076 - val_accuracy: 0.3750 - val_MSE: 0.3145 - val_precision_4: 0.3333 - val_recall_4: 0.2422\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (8, 128)                  3138560   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (8, 128)                  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (8, 128)                  512       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (8, 3)                    387       \n",
      "=================================================================\n",
      "Total params: 3,139,459\n",
      "Trainable params: 3,139,203\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Starting: \n",
      "{'batch_size': 8, 'epochs': 80, 'learning_rate': 0.1, 'optimizer': 'adam'}\n",
      "---------------------------------------------------------------------------------\n",
      "{   'activation': 'tanh',\n",
      "    'dropout_rate': 0.1,\n",
      "    'filters': 15,\n",
      "    'kernel_size': 3,\n",
      "    'l1_r': 0.001,\n",
      "    'l2_r': 0.1,\n",
      "    'output_layer_activation': 'softmax',\n",
      "    'padding': 'valid',\n",
      "    'start_neurons': 128}\n",
      "Epoch 1/80\n",
      "  2/102 [..............................] - ETA: 1:21 - loss: 1410.1970 - accuracy: 0.4375 - MSE: 0.2889 - precision_5: 0.4286 - recall_5: 0.3750WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0540s vs `on_train_batch_end` time: 1.5739s). Check your callbacks.\n",
      "102/102 [==============================] - 9s 88ms/step - loss: 2752.1582 - accuracy: 0.3199 - MSE: 0.3343 - precision_5: 0.3202 - recall_5: 0.2794 - val_loss: 1640.3787 - val_accuracy: 0.3382 - val_MSE: 0.2388 - val_precision_5: 0.4082 - val_recall_5: 0.1471\n",
      "Epoch 2/80\n",
      "102/102 [==============================] - 6s 61ms/step - loss: 1163.2537 - accuracy: 0.3272 - MSE: 0.2542 - precision_5: 0.3038 - recall_5: 0.1471 - val_loss: 1022.7259 - val_accuracy: 0.3309 - val_MSE: 0.2343 - val_precision_5: 0.3256 - val_recall_5: 0.1029\n",
      "Epoch 3/80\n",
      "102/102 [==============================] - 6s 62ms/step - loss: 1371.6384 - accuracy: 0.3174 - MSE: 0.2626 - precision_5: 0.3201 - recall_5: 0.1777 - val_loss: 906.5286 - val_accuracy: 0.3382 - val_MSE: 0.2401 - val_precision_5: 0.3774 - val_recall_5: 0.1471\n",
      "Epoch 4/80\n",
      "102/102 [==============================] - 7s 64ms/step - loss: 2342.3972 - accuracy: 0.3260 - MSE: 0.2722 - precision_5: 0.3333 - recall_5: 0.2194 - val_loss: 2297.9089 - val_accuracy: 0.3382 - val_MSE: 0.2485 - val_precision_5: 0.3108 - val_recall_5: 0.1691\n",
      "Epoch 5/80\n",
      "102/102 [==============================] - 6s 61ms/step - loss: 2082.4385 - accuracy: 0.3137 - MSE: 0.2698 - precision_5: 0.3255 - recall_5: 0.2047 - val_loss: 1628.5641 - val_accuracy: 0.3529 - val_MSE: 0.2566 - val_precision_5: 0.3656 - val_recall_5: 0.2500\n",
      "Epoch 6/80\n",
      "102/102 [==============================] - 7s 64ms/step - loss: 2842.5442 - accuracy: 0.3407 - MSE: 0.2816 - precision_5: 0.3477 - recall_5: 0.2574 - val_loss: 3576.2346 - val_accuracy: 0.3456 - val_MSE: 0.2715 - val_precision_5: 0.3366 - val_recall_5: 0.2500\n",
      "Epoch 7/80\n",
      "102/102 [==============================] - 6s 61ms/step - loss: 2953.0215 - accuracy: 0.3333 - MSE: 0.2915 - precision_5: 0.3261 - recall_5: 0.2586 - val_loss: 6905.3540 - val_accuracy: 0.4044 - val_MSE: 0.3008 - val_precision_5: 0.4113 - val_recall_5: 0.3750\n",
      "Epoch 8/80\n",
      "102/102 [==============================] - 6s 63ms/step - loss: 4458.7129 - accuracy: 0.3051 - MSE: 0.3191 - precision_5: 0.2969 - recall_5: 0.2561 - val_loss: 3186.8145 - val_accuracy: 0.3750 - val_MSE: 0.2814 - val_precision_5: 0.3738 - val_recall_5: 0.2941\n",
      "Epoch 9/80\n",
      "102/102 [==============================] - 6s 62ms/step - loss: 3199.9199 - accuracy: 0.3186 - MSE: 0.2992 - precision_5: 0.3082 - recall_5: 0.2402 - val_loss: 6361.5239 - val_accuracy: 0.3309 - val_MSE: 0.3021 - val_precision_5: 0.3333 - val_recall_5: 0.2941\n",
      "Epoch 10/80\n",
      "102/102 [==============================] - 6s 61ms/step - loss: 3680.9795 - accuracy: 0.3137 - MSE: 0.2981 - precision_5: 0.3054 - recall_5: 0.2414 - val_loss: 1887.6155 - val_accuracy: 0.3676 - val_MSE: 0.2711 - val_precision_5: 0.3491 - val_recall_5: 0.2721\n",
      "Epoch 11/80\n",
      "102/102 [==============================] - 7s 64ms/step - loss: 2613.3257 - accuracy: 0.3137 - MSE: 0.2754 - precision_5: 0.3201 - recall_5: 0.2181 - val_loss: 3690.2888 - val_accuracy: 0.3015 - val_MSE: 0.2705 - val_precision_5: 0.3371 - val_recall_5: 0.2206\n",
      "Epoch 12/80\n",
      "102/102 [==============================] - 6s 61ms/step - loss: 3152.3008 - accuracy: 0.3272 - MSE: 0.2700 - precision_5: 0.3283 - recall_5: 0.2145 - val_loss: 2491.9612 - val_accuracy: 0.3088 - val_MSE: 0.2726 - val_precision_5: 0.3265 - val_recall_5: 0.2353\n",
      "Epoch 13/80\n",
      "102/102 [==============================] - 6s 63ms/step - loss: 12298.6582 - accuracy: 0.3137 - MSE: 0.2863 - precision_5: 0.2973 - recall_5: 0.2194 - val_loss: 17750.0391 - val_accuracy: 0.2500 - val_MSE: 0.3407 - val_precision_5: 0.2397 - val_recall_5: 0.2132\n",
      "Epoch 14/80\n",
      "102/102 [==============================] - 6s 61ms/step - loss: 11005.3496 - accuracy: 0.3211 - MSE: 0.2814 - precision_5: 0.3246 - recall_5: 0.2279 - val_loss: 6939.6909 - val_accuracy: 0.3162 - val_MSE: 0.3316 - val_precision_5: 0.2895 - val_recall_5: 0.2426\n",
      "Epoch 15/80\n",
      "102/102 [==============================] - 6s 63ms/step - loss: 6908.7061 - accuracy: 0.3333 - MSE: 0.2875 - precision_5: 0.3364 - recall_5: 0.2708 - val_loss: 7363.6968 - val_accuracy: 0.3309 - val_MSE: 0.3083 - val_precision_5: 0.3478 - val_recall_5: 0.2941\n",
      "Epoch 16/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 6s 61ms/step - loss: 6030.9775 - accuracy: 0.3480 - MSE: 0.3045 - precision_5: 0.3442 - recall_5: 0.2966 - val_loss: 7680.0068 - val_accuracy: 0.2794 - val_MSE: 0.3610 - val_precision_5: 0.2756 - val_recall_5: 0.2574\n",
      "Epoch 17/80\n",
      "102/102 [==============================] - 6s 61ms/step - loss: 6898.3467 - accuracy: 0.3125 - MSE: 0.3202 - precision_5: 0.3045 - recall_5: 0.2549 - val_loss: 6739.8555 - val_accuracy: 0.3382 - val_MSE: 0.2984 - val_precision_5: 0.3386 - val_recall_5: 0.3162\n",
      "Epoch 18/80\n",
      "102/102 [==============================] - 7s 64ms/step - loss: 6000.9937 - accuracy: 0.3150 - MSE: 0.3067 - precision_5: 0.3098 - recall_5: 0.2475 - val_loss: 3243.6868 - val_accuracy: 0.4044 - val_MSE: 0.2564 - val_precision_5: 0.4059 - val_recall_5: 0.3015\n",
      "Epoch 19/80\n",
      "102/102 [==============================] - 6s 61ms/step - loss: 4738.5898 - accuracy: 0.3260 - MSE: 0.2863 - precision_5: 0.3275 - recall_5: 0.2512 - val_loss: 4191.1045 - val_accuracy: 0.3456 - val_MSE: 0.3221 - val_precision_5: 0.3520 - val_recall_5: 0.3235\n",
      "Epoch 20/80\n",
      "102/102 [==============================] - 6s 63ms/step - loss: 5492.1099 - accuracy: 0.3272 - MSE: 0.2830 - precision_5: 0.3389 - recall_5: 0.2500 - val_loss: 3198.4512 - val_accuracy: 0.3676 - val_MSE: 0.2664 - val_precision_5: 0.3846 - val_recall_5: 0.2941\n",
      "Epoch 21/80\n",
      "102/102 [==============================] - 6s 62ms/step - loss: 3730.1125 - accuracy: 0.3346 - MSE: 0.2760 - precision_5: 0.3446 - recall_5: 0.2500 - val_loss: 4519.9502 - val_accuracy: 0.3382 - val_MSE: 0.2644 - val_precision_5: 0.3229 - val_recall_5: 0.2279\n",
      "Epoch 22/80\n",
      "102/102 [==============================] - 6s 63ms/step - loss: 4246.1616 - accuracy: 0.3199 - MSE: 0.2907 - precision_5: 0.3307 - recall_5: 0.2586 - val_loss: 6789.5767 - val_accuracy: 0.3897 - val_MSE: 0.2635 - val_precision_5: 0.4070 - val_recall_5: 0.2574\n",
      "Epoch 23/80\n",
      "102/102 [==============================] - 6s 63ms/step - loss: 6544.4512 - accuracy: 0.3235 - MSE: 0.2972 - precision_5: 0.3145 - recall_5: 0.2525 - val_loss: 4706.5581 - val_accuracy: 0.2941 - val_MSE: 0.2858 - val_precision_5: 0.2857 - val_recall_5: 0.2059\n",
      "Epoch 24/80\n",
      "102/102 [==============================] - 7s 65ms/step - loss: 5193.0430 - accuracy: 0.3382 - MSE: 0.2878 - precision_5: 0.3412 - recall_5: 0.2659 - val_loss: 7339.9175 - val_accuracy: 0.3015 - val_MSE: 0.3095 - val_precision_5: 0.2909 - val_recall_5: 0.2353\n",
      "Epoch 25/80\n",
      "102/102 [==============================] - 7s 67ms/step - loss: 4792.3267 - accuracy: 0.3113 - MSE: 0.3095 - precision_5: 0.2920 - recall_5: 0.2365 - val_loss: 5317.6616 - val_accuracy: 0.3603 - val_MSE: 0.2814 - val_precision_5: 0.3486 - val_recall_5: 0.2794\n",
      "Epoch 26/80\n",
      "102/102 [==============================] - 6s 61ms/step - loss: 5593.4282 - accuracy: 0.3088 - MSE: 0.3067 - precision_5: 0.3113 - recall_5: 0.2537 - val_loss: 4756.6616 - val_accuracy: 0.4338 - val_MSE: 0.2670 - val_precision_5: 0.4074 - val_recall_5: 0.3235\n",
      "Epoch 27/80\n",
      "102/102 [==============================] - 6s 64ms/step - loss: 8629.0557 - accuracy: 0.3444 - MSE: 0.3100 - precision_5: 0.3333 - recall_5: 0.2831 - val_loss: 4457.6113 - val_accuracy: 0.3676 - val_MSE: 0.3057 - val_precision_5: 0.3471 - val_recall_5: 0.3088\n",
      "Epoch 28/80\n",
      "102/102 [==============================] - 6s 62ms/step - loss: 5289.6426 - accuracy: 0.3162 - MSE: 0.3019 - precision_5: 0.2883 - recall_5: 0.2304 - val_loss: 4568.6440 - val_accuracy: 0.3015 - val_MSE: 0.3040 - val_precision_5: 0.3009 - val_recall_5: 0.2500\n",
      "Epoch 29/80\n",
      "102/102 [==============================] - 6s 63ms/step - loss: 10289.5752 - accuracy: 0.3088 - MSE: 0.2846 - precision_5: 0.3018 - recall_5: 0.2108 - val_loss: 7585.3149 - val_accuracy: 0.2574 - val_MSE: 0.2907 - val_precision_5: 0.2755 - val_recall_5: 0.1985\n",
      "Epoch 30/80\n",
      "102/102 [==============================] - 6s 62ms/step - loss: 5240.7788 - accuracy: 0.3419 - MSE: 0.2875 - precision_5: 0.3394 - recall_5: 0.2721 - val_loss: 6136.9170 - val_accuracy: 0.3456 - val_MSE: 0.3080 - val_precision_5: 0.3148 - val_recall_5: 0.2500\n",
      "Epoch 31/80\n",
      "102/102 [==============================] - 6s 61ms/step - loss: 4673.3076 - accuracy: 0.3125 - MSE: 0.3008 - precision_5: 0.3178 - recall_5: 0.2500 - val_loss: 5897.7690 - val_accuracy: 0.3750 - val_MSE: 0.2732 - val_precision_5: 0.3738 - val_recall_5: 0.2941\n",
      "Epoch 32/80\n",
      "102/102 [==============================] - 7s 64ms/step - loss: 5189.9946 - accuracy: 0.3235 - MSE: 0.3038 - precision_5: 0.3219 - recall_5: 0.2537 - val_loss: 4965.2183 - val_accuracy: 0.3088 - val_MSE: 0.2820 - val_precision_5: 0.2925 - val_recall_5: 0.2279\n",
      "Epoch 33/80\n",
      "102/102 [==============================] - 6s 62ms/step - loss: 4195.3125 - accuracy: 0.2868 - MSE: 0.2998 - precision_5: 0.2978 - recall_5: 0.2328 - val_loss: 5231.1284 - val_accuracy: 0.3309 - val_MSE: 0.3042 - val_precision_5: 0.3543 - val_recall_5: 0.3309\n",
      "Epoch 34/80\n",
      "102/102 [==============================] - 6s 64ms/step - loss: 5921.7212 - accuracy: 0.3407 - MSE: 0.2910 - precision_5: 0.3349 - recall_5: 0.2610 - val_loss: 6704.0713 - val_accuracy: 0.3676 - val_MSE: 0.3304 - val_precision_5: 0.3594 - val_recall_5: 0.3382\n",
      "Epoch 35/80\n",
      "102/102 [==============================] - 6s 61ms/step - loss: 3684.4792 - accuracy: 0.3027 - MSE: 0.2934 - precision_5: 0.3078 - recall_5: 0.2365 - val_loss: 3179.9963 - val_accuracy: 0.2941 - val_MSE: 0.3178 - val_precision_5: 0.2857 - val_recall_5: 0.2500\n",
      "Epoch 36/80\n",
      "102/102 [==============================] - 6s 63ms/step - loss: 4770.8774 - accuracy: 0.3517 - MSE: 0.2776 - precision_5: 0.3485 - recall_5: 0.2635 - val_loss: 6700.9629 - val_accuracy: 0.3382 - val_MSE: 0.2951 - val_precision_5: 0.3519 - val_recall_5: 0.2794\n",
      "Epoch 37/80\n",
      "102/102 [==============================] - 6s 62ms/step - loss: 3751.3777 - accuracy: 0.3382 - MSE: 0.2842 - precision_5: 0.3236 - recall_5: 0.2451 - val_loss: 3624.4395 - val_accuracy: 0.3456 - val_MSE: 0.2868 - val_precision_5: 0.3394 - val_recall_5: 0.2721\n",
      "Epoch 38/80\n",
      "102/102 [==============================] - 6s 62ms/step - loss: 4462.4849 - accuracy: 0.3211 - MSE: 0.2812 - precision_5: 0.3095 - recall_5: 0.2230 - val_loss: 4909.8535 - val_accuracy: 0.4191 - val_MSE: 0.2626 - val_precision_5: 0.4200 - val_recall_5: 0.3088\n",
      "Epoch 39/80\n",
      "102/102 [==============================] - 6s 63ms/step - loss: 6323.1289 - accuracy: 0.3248 - MSE: 0.2967 - precision_5: 0.3235 - recall_5: 0.2684 - val_loss: 5805.1177 - val_accuracy: 0.3824 - val_MSE: 0.2899 - val_precision_5: 0.3710 - val_recall_5: 0.3382\n",
      "Epoch 40/80\n",
      "102/102 [==============================] - 6s 61ms/step - loss: 3957.9399 - accuracy: 0.3015 - MSE: 0.2891 - precision_5: 0.3040 - recall_5: 0.2328 - val_loss: 3691.1975 - val_accuracy: 0.3309 - val_MSE: 0.2825 - val_precision_5: 0.3402 - val_recall_5: 0.2426\n",
      "Epoch 41/80\n",
      "102/102 [==============================] - 7s 64ms/step - loss: 8270.6250 - accuracy: 0.3260 - MSE: 0.2913 - precision_5: 0.3264 - recall_5: 0.2488 - val_loss: 8629.6074 - val_accuracy: 0.3162 - val_MSE: 0.3025 - val_precision_5: 0.2881 - val_recall_5: 0.2500\n",
      "Epoch 42/80\n",
      "102/102 [==============================] - 6s 61ms/step - loss: 4856.7783 - accuracy: 0.2917 - MSE: 0.3014 - precision_5: 0.2902 - recall_5: 0.2255 - val_loss: 2388.7437 - val_accuracy: 0.2941 - val_MSE: 0.2713 - val_precision_5: 0.2989 - val_recall_5: 0.1912\n",
      "Epoch 43/80\n",
      "102/102 [==============================] - 7s 66ms/step - loss: 5179.5688 - accuracy: 0.3235 - MSE: 0.2976 - precision_5: 0.3170 - recall_5: 0.2451 - val_loss: 8086.0542 - val_accuracy: 0.2941 - val_MSE: 0.3328 - val_precision_5: 0.2522 - val_recall_5: 0.2132\n",
      "Epoch 44/80\n",
      "102/102 [==============================] - 6s 62ms/step - loss: 7404.8423 - accuracy: 0.3309 - MSE: 0.3039 - precision_5: 0.3289 - recall_5: 0.2757 - val_loss: 11283.4072 - val_accuracy: 0.3382 - val_MSE: 0.2923 - val_precision_5: 0.3305 - val_recall_5: 0.2868\n",
      "Epoch 45/80\n",
      "102/102 [==============================] - 7s 65ms/step - loss: 6947.9932 - accuracy: 0.3223 - MSE: 0.3068 - precision_5: 0.3318 - recall_5: 0.2708 - val_loss: 6355.5356 - val_accuracy: 0.3382 - val_MSE: 0.2739 - val_precision_5: 0.2935 - val_recall_5: 0.1985\n",
      "Epoch 46/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 6s 61ms/step - loss: 7900.3047 - accuracy: 0.3064 - MSE: 0.2847 - precision_5: 0.3017 - recall_5: 0.2181 - val_loss: 7918.9321 - val_accuracy: 0.3603 - val_MSE: 0.2648 - val_precision_5: 0.3535 - val_recall_5: 0.2574\n",
      "Epoch 47/80\n",
      "102/102 [==============================] - 6s 62ms/step - loss: 5106.6270 - accuracy: 0.3419 - MSE: 0.2857 - precision_5: 0.3387 - recall_5: 0.2574 - val_loss: 2706.3511 - val_accuracy: 0.3750 - val_MSE: 0.2623 - val_precision_5: 0.3673 - val_recall_5: 0.2647\n",
      "Epoch 48/80\n",
      "102/102 [==============================] - 7s 64ms/step - loss: 7480.2881 - accuracy: 0.3100 - MSE: 0.2961 - precision_5: 0.3043 - recall_5: 0.2316 - val_loss: 4554.3774 - val_accuracy: 0.3676 - val_MSE: 0.2965 - val_precision_5: 0.3750 - val_recall_5: 0.3309\n",
      "Epoch 49/80\n",
      "102/102 [==============================] - 6s 61ms/step - loss: 4931.3750 - accuracy: 0.3137 - MSE: 0.2924 - precision_5: 0.3051 - recall_5: 0.2292 - val_loss: 4058.5635 - val_accuracy: 0.3382 - val_MSE: 0.3094 - val_precision_5: 0.3248 - val_recall_5: 0.2794\n",
      "Epoch 50/80\n",
      "102/102 [==============================] - 7s 65ms/step - loss: 3324.4087 - accuracy: 0.2978 - MSE: 0.2969 - precision_5: 0.2848 - recall_5: 0.2157 - val_loss: 2686.5349 - val_accuracy: 0.3750 - val_MSE: 0.2918 - val_precision_5: 0.3333 - val_recall_5: 0.2868\n",
      "Epoch 51/80\n",
      "102/102 [==============================] - 6s 61ms/step - loss: 7947.6650 - accuracy: 0.2978 - MSE: 0.2909 - precision_5: 0.2907 - recall_5: 0.2230 - val_loss: 7729.8345 - val_accuracy: 0.3382 - val_MSE: 0.2990 - val_precision_5: 0.3274 - val_recall_5: 0.2721\n",
      "Epoch 52/80\n",
      "102/102 [==============================] - 6s 63ms/step - loss: 5619.7148 - accuracy: 0.3113 - MSE: 0.2914 - precision_5: 0.3167 - recall_5: 0.2414 - val_loss: 2988.9214 - val_accuracy: 0.2794 - val_MSE: 0.2627 - val_precision_5: 0.3247 - val_recall_5: 0.1838\n",
      "Epoch 53/80\n",
      "102/102 [==============================] - 7s 64ms/step - loss: 6857.8608 - accuracy: 0.3211 - MSE: 0.2840 - precision_5: 0.3121 - recall_5: 0.2218 - val_loss: 12088.9590 - val_accuracy: 0.3750 - val_MSE: 0.2697 - val_precision_5: 0.4151 - val_recall_5: 0.3235\n",
      "Epoch 54/80\n",
      "102/102 [==============================] - 6s 61ms/step - loss: 10188.0840 - accuracy: 0.3468 - MSE: 0.3036 - precision_5: 0.3431 - recall_5: 0.2880 - val_loss: 15830.4893 - val_accuracy: 0.3309 - val_MSE: 0.2972 - val_precision_5: 0.3048 - val_recall_5: 0.2353\n",
      "Epoch 55/80\n",
      "102/102 [==============================] - 6s 64ms/step - loss: 7755.4224 - accuracy: 0.3480 - MSE: 0.2871 - precision_5: 0.3429 - recall_5: 0.2635 - val_loss: 4164.4331 - val_accuracy: 0.2647 - val_MSE: 0.3090 - val_precision_5: 0.2321 - val_recall_5: 0.1912\n",
      "Epoch 56/80\n",
      "102/102 [==============================] - 6s 61ms/step - loss: 4465.7896 - accuracy: 0.3297 - MSE: 0.2783 - precision_5: 0.3288 - recall_5: 0.2390 - val_loss: 10442.9180 - val_accuracy: 0.3162 - val_MSE: 0.2812 - val_precision_5: 0.2621 - val_recall_5: 0.1985\n",
      "Epoch 57/80\n",
      "102/102 [==============================] - 7s 66ms/step - loss: 7389.3350 - accuracy: 0.2990 - MSE: 0.2982 - precision_5: 0.2955 - recall_5: 0.2230 - val_loss: 8915.6328 - val_accuracy: 0.3162 - val_MSE: 0.3086 - val_precision_5: 0.3273 - val_recall_5: 0.2647\n",
      "Epoch 58/80\n",
      "102/102 [==============================] - 7s 65ms/step - loss: 9260.2109 - accuracy: 0.3137 - MSE: 0.3064 - precision_5: 0.3076 - recall_5: 0.2537 - val_loss: 9332.9561 - val_accuracy: 0.3676 - val_MSE: 0.3062 - val_precision_5: 0.3217 - val_recall_5: 0.2721\n",
      "Epoch 59/80\n",
      "102/102 [==============================] - 7s 65ms/step - loss: 6531.1440 - accuracy: 0.3260 - MSE: 0.3022 - precision_5: 0.3338 - recall_5: 0.2782 - val_loss: 7038.2666 - val_accuracy: 0.3456 - val_MSE: 0.2789 - val_precision_5: 0.3398 - val_recall_5: 0.2574\n",
      "Epoch 60/80\n",
      "102/102 [==============================] - 7s 64ms/step - loss: 7455.4014 - accuracy: 0.3321 - MSE: 0.2940 - precision_5: 0.3328 - recall_5: 0.2745 - val_loss: 5184.5435 - val_accuracy: 0.3824 - val_MSE: 0.2561 - val_precision_5: 0.4040 - val_recall_5: 0.2941\n",
      "Epoch 61/80\n",
      "102/102 [==============================] - 6s 62ms/step - loss: 5201.0112 - accuracy: 0.3076 - MSE: 0.2848 - precision_5: 0.3012 - recall_5: 0.2108 - val_loss: 3091.8359 - val_accuracy: 0.3382 - val_MSE: 0.2822 - val_precision_5: 0.3143 - val_recall_5: 0.2426\n",
      "Epoch 62/80\n",
      "102/102 [==============================] - 6s 64ms/step - loss: 9515.2539 - accuracy: 0.3137 - MSE: 0.3080 - precision_5: 0.3134 - recall_5: 0.2500 - val_loss: 7082.2368 - val_accuracy: 0.2941 - val_MSE: 0.2857 - val_precision_5: 0.3084 - val_recall_5: 0.2426\n",
      "Epoch 63/80\n",
      "102/102 [==============================] - 6s 61ms/step - loss: 11767.5957 - accuracy: 0.3039 - MSE: 0.2885 - precision_5: 0.3091 - recall_5: 0.2292 - val_loss: 10322.5830 - val_accuracy: 0.3824 - val_MSE: 0.3232 - val_precision_5: 0.3780 - val_recall_5: 0.3529\n",
      "Epoch 64/80\n",
      "102/102 [==============================] - 7s 64ms/step - loss: 13095.7559 - accuracy: 0.3370 - MSE: 0.3173 - precision_5: 0.3366 - recall_5: 0.2941 - val_loss: 12388.2480 - val_accuracy: 0.2794 - val_MSE: 0.3269 - val_precision_5: 0.2589 - val_recall_5: 0.2132\n",
      "Epoch 65/80\n",
      "102/102 [==============================] - 6s 62ms/step - loss: 7535.9463 - accuracy: 0.3186 - MSE: 0.2965 - precision_5: 0.3193 - recall_5: 0.2598 - val_loss: 4243.1714 - val_accuracy: 0.3603 - val_MSE: 0.2850 - val_precision_5: 0.3694 - val_recall_5: 0.3015\n",
      "Epoch 66/80\n",
      "102/102 [==============================] - 6s 63ms/step - loss: 9015.3389 - accuracy: 0.3039 - MSE: 0.2913 - precision_5: 0.3193 - recall_5: 0.2414 - val_loss: 8015.4688 - val_accuracy: 0.3824 - val_MSE: 0.2744 - val_precision_5: 0.3879 - val_recall_5: 0.3309\n",
      "Epoch 67/80\n",
      "102/102 [==============================] - 6s 63ms/step - loss: 5552.8140 - accuracy: 0.3150 - MSE: 0.2925 - precision_5: 0.3207 - recall_5: 0.2377 - val_loss: 6699.4453 - val_accuracy: 0.3309 - val_MSE: 0.2927 - val_precision_5: 0.3363 - val_recall_5: 0.2794\n",
      "Epoch 68/80\n",
      "102/102 [==============================] - 6s 62ms/step - loss: 5118.8096 - accuracy: 0.3211 - MSE: 0.2873 - precision_5: 0.3162 - recall_5: 0.2341 - val_loss: 8874.6738 - val_accuracy: 0.3235 - val_MSE: 0.2857 - val_precision_5: 0.3211 - val_recall_5: 0.2574\n",
      "Epoch 69/80\n",
      "102/102 [==============================] - 7s 64ms/step - loss: 6856.5464 - accuracy: 0.3199 - MSE: 0.3029 - precision_5: 0.3192 - recall_5: 0.2586 - val_loss: 7169.7666 - val_accuracy: 0.3529 - val_MSE: 0.3135 - val_precision_5: 0.3307 - val_recall_5: 0.3088\n",
      "Epoch 70/80\n",
      "102/102 [==============================] - 6s 63ms/step - loss: 8393.2266 - accuracy: 0.3088 - MSE: 0.3109 - precision_5: 0.3043 - recall_5: 0.2488 - val_loss: 9264.4834 - val_accuracy: 0.3456 - val_MSE: 0.3060 - val_precision_5: 0.3391 - val_recall_5: 0.2868\n",
      "Epoch 71/80\n",
      "102/102 [==============================] - 6s 64ms/step - loss: 6900.3086 - accuracy: 0.3395 - MSE: 0.2888 - precision_5: 0.3391 - recall_5: 0.2647 - val_loss: 6778.8896 - val_accuracy: 0.3456 - val_MSE: 0.2672 - val_precision_5: 0.3696 - val_recall_5: 0.2500\n",
      "Epoch 72/80\n",
      "102/102 [==============================] - 7s 65ms/step - loss: 7847.3276 - accuracy: 0.3284 - MSE: 0.2881 - precision_5: 0.3317 - recall_5: 0.2561 - val_loss: 7870.8252 - val_accuracy: 0.2941 - val_MSE: 0.2743 - val_precision_5: 0.2529 - val_recall_5: 0.1618\n",
      "Epoch 73/80\n",
      "102/102 [==============================] - 7s 69ms/step - loss: 8712.9482 - accuracy: 0.3309 - MSE: 0.2894 - precision_5: 0.3298 - recall_5: 0.2635 - val_loss: 9651.4727 - val_accuracy: 0.4265 - val_MSE: 0.2570 - val_precision_5: 0.4312 - val_recall_5: 0.3456\n",
      "Epoch 74/80\n",
      "102/102 [==============================] - 7s 66ms/step - loss: 9290.2705 - accuracy: 0.3186 - MSE: 0.2824 - precision_5: 0.3166 - recall_5: 0.2316 - val_loss: 6089.1982 - val_accuracy: 0.2721 - val_MSE: 0.2979 - val_precision_5: 0.2685 - val_recall_5: 0.2132\n",
      "Epoch 75/80\n",
      "102/102 [==============================] - 6s 63ms/step - loss: 6000.0293 - accuracy: 0.3174 - MSE: 0.2830 - precision_5: 0.3077 - recall_5: 0.2157 - val_loss: 4770.7695 - val_accuracy: 0.2574 - val_MSE: 0.3606 - val_precision_5: 0.2602 - val_recall_5: 0.2353\n",
      "Epoch 76/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 6s 61ms/step - loss: 7637.0464 - accuracy: 0.3113 - MSE: 0.2882 - precision_5: 0.2862 - recall_5: 0.2132 - val_loss: 3301.2708 - val_accuracy: 0.2794 - val_MSE: 0.3148 - val_precision_5: 0.2627 - val_recall_5: 0.2279\n",
      "Epoch 77/80\n",
      "102/102 [==============================] - 6s 61ms/step - loss: 4887.9180 - accuracy: 0.3248 - MSE: 0.2767 - precision_5: 0.3287 - recall_5: 0.2316 - val_loss: 2454.6667 - val_accuracy: 0.3529 - val_MSE: 0.2639 - val_precision_5: 0.3483 - val_recall_5: 0.2279\n",
      "Epoch 78/80\n",
      "102/102 [==============================] - 7s 64ms/step - loss: 4304.3926 - accuracy: 0.3211 - MSE: 0.2807 - precision_5: 0.3245 - recall_5: 0.2414 - val_loss: 3539.5525 - val_accuracy: 0.2941 - val_MSE: 0.3069 - val_precision_5: 0.3000 - val_recall_5: 0.2426\n",
      "Epoch 79/80\n",
      "102/102 [==============================] - 6s 63ms/step - loss: 8596.5635 - accuracy: 0.3382 - MSE: 0.2964 - precision_5: 0.3238 - recall_5: 0.2647 - val_loss: 9661.9863 - val_accuracy: 0.3088 - val_MSE: 0.2764 - val_precision_5: 0.3333 - val_recall_5: 0.2279\n",
      "Epoch 80/80\n",
      "102/102 [==============================] - 7s 64ms/step - loss: 7649.7290 - accuracy: 0.3468 - MSE: 0.2944 - precision_5: 0.3424 - recall_5: 0.2782 - val_loss: 7421.6196 - val_accuracy: 0.3824 - val_MSE: 0.2673 - val_precision_5: 0.3604 - val_recall_5: 0.2941\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (64, 8)                   192320    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (64, 8)                   0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (64, 8)                   32        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (64, 3)                   27        \n",
      "=================================================================\n",
      "Total params: 192,379\n",
      "Trainable params: 192,363\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n",
      "Starting: \n",
      "{   'batch_size': 64,\n",
      "    'epochs': 70,\n",
      "    'learning_rate': 0.0001,\n",
      "    'optimizer': 'rmsprop'}\n",
      "---------------------------------------------------------------------------------\n",
      "{   'activation': 'softmax',\n",
      "    'dropout_rate': 0,\n",
      "    'filters': 3,\n",
      "    'kernel_size': 3,\n",
      "    'l1_r': 0.3,\n",
      "    'l2_r': 0.01,\n",
      "    'output_layer_activation': 'softmax',\n",
      "    'padding': 'valid',\n",
      "    'start_neurons': 8}\n",
      "Epoch 1/70\n",
      " 2/12 [====>.........................] - ETA: 10s - loss: 902.2135 - accuracy: 0.2891 - MSE: 0.2937 - precision_6: 0.2717 - recall_6: 0.1953WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0904s vs `on_train_batch_end` time: 1.9216s). Check your callbacks.\n",
      "12/12 [==============================] - 4s 346ms/step - loss: 852.6205 - accuracy: 0.3346 - MSE: 0.2774 - precision_6: 0.3244 - recall_6: 0.2357 - val_loss: 804.0022 - val_accuracy: 0.2969 - val_MSE: 0.2245 - val_precision_6: 0.0000e+00 - val_recall_6: 0.0000e+00\n",
      "Epoch 2/70\n",
      "12/12 [==============================] - 1s 121ms/step - loss: 772.9664 - accuracy: 0.3555 - MSE: 0.2689 - precision_6: 0.3579 - recall_6: 0.2591 - val_loss: 737.8057 - val_accuracy: 0.2969 - val_MSE: 0.2243 - val_precision_6: 0.0000e+00 - val_recall_6: 0.0000e+00\n",
      "Epoch 3/70\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 710.6852 - accuracy: 0.3490 - MSE: 0.2658 - precision_6: 0.3702 - recall_6: 0.2656 - val_loss: 678.6340 - val_accuracy: 0.2891 - val_MSE: 0.2242 - val_precision_6: 0.0000e+00 - val_recall_6: 0.0000e+00\n",
      "Epoch 4/70\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 652.8760 - accuracy: 0.3594 - MSE: 0.2600 - precision_6: 0.3757 - recall_6: 0.2617 - val_loss: 622.4419 - val_accuracy: 0.2891 - val_MSE: 0.2236 - val_precision_6: 0.0000e+00 - val_recall_6: 0.0000e+00\n",
      "Epoch 5/70\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 597.8408 - accuracy: 0.3659 - MSE: 0.2568 - precision_6: 0.3949 - recall_6: 0.2812 - val_loss: 568.6948 - val_accuracy: 0.3047 - val_MSE: 0.2230 - val_precision_6: 0.0000e+00 - val_recall_6: 0.0000e+00\n",
      "Epoch 6/70\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 545.0927 - accuracy: 0.3841 - MSE: 0.2539 - precision_6: 0.3982 - recall_6: 0.2852 - val_loss: 517.2594 - val_accuracy: 0.3281 - val_MSE: 0.2231 - val_precision_6: 0.0000e+00 - val_recall_6: 0.0000e+00\n",
      "Epoch 7/70\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 494.8215 - accuracy: 0.3893 - MSE: 0.2518 - precision_6: 0.4054 - recall_6: 0.2956 - val_loss: 468.4818 - val_accuracy: 0.3203 - val_MSE: 0.2232 - val_precision_6: 0.0000e+00 - val_recall_6: 0.0000e+00\n",
      "Epoch 8/70\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 447.3275 - accuracy: 0.3919 - MSE: 0.2479 - precision_6: 0.4109 - recall_6: 0.2943 - val_loss: 422.3963 - val_accuracy: 0.3359 - val_MSE: 0.2228 - val_precision_6: 0.0000e+00 - val_recall_6: 0.0000e+00\n",
      "Epoch 9/70\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 402.3192 - accuracy: 0.3932 - MSE: 0.2450 - precision_6: 0.4124 - recall_6: 0.2943 - val_loss: 378.7821 - val_accuracy: 0.3281 - val_MSE: 0.2228 - val_precision_6: 0.0000e+00 - val_recall_6: 0.0000e+00\n",
      "Epoch 10/70\n",
      "12/12 [==============================] - 1s 118ms/step - loss: 359.7994 - accuracy: 0.4049 - MSE: 0.2418 - precision_6: 0.4288 - recall_6: 0.2982 - val_loss: 337.4566 - val_accuracy: 0.3281 - val_MSE: 0.2223 - val_precision_6: 0.0000e+00 - val_recall_6: 0.0000e+00\n",
      "Epoch 11/70\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 319.6874 - accuracy: 0.4036 - MSE: 0.2410 - precision_6: 0.4310 - recall_6: 0.2969 - val_loss: 298.8512 - val_accuracy: 0.3516 - val_MSE: 0.2221 - val_precision_6: 0.0000e+00 - val_recall_6: 0.0000e+00\n",
      "Epoch 12/70\n",
      "12/12 [==============================] - 2s 141ms/step - loss: 282.2310 - accuracy: 0.4232 - MSE: 0.2332 - precision_6: 0.4545 - recall_6: 0.3255 - val_loss: 262.8663 - val_accuracy: 0.3750 - val_MSE: 0.2215 - val_precision_6: 0.0000e+00 - val_recall_6: 0.0000e+00\n",
      "Epoch 13/70\n",
      "12/12 [==============================] - 1s 118ms/step - loss: 247.2433 - accuracy: 0.4479 - MSE: 0.2281 - precision_6: 0.4837 - recall_6: 0.3477 - val_loss: 229.0884 - val_accuracy: 0.3516 - val_MSE: 0.2209 - val_precision_6: 0.0000e+00 - val_recall_6: 0.0000e+00\n",
      "Epoch 14/70\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 214.6161 - accuracy: 0.4349 - MSE: 0.2298 - precision_6: 0.4667 - recall_6: 0.3281 - val_loss: 197.7930 - val_accuracy: 0.3750 - val_MSE: 0.2203 - val_precision_6: 0.0000e+00 - val_recall_6: 0.0000e+00\n",
      "Epoch 15/70\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 184.4893 - accuracy: 0.4544 - MSE: 0.2215 - precision_6: 0.4905 - recall_6: 0.3359 - val_loss: 169.0916 - val_accuracy: 0.3516 - val_MSE: 0.2200 - val_precision_6: 0.0000e+00 - val_recall_6: 0.0000e+00\n",
      "Epoch 16/70\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 156.8542 - accuracy: 0.4570 - MSE: 0.2235 - precision_6: 0.4945 - recall_6: 0.3490 - val_loss: 142.6003 - val_accuracy: 0.3672 - val_MSE: 0.2183 - val_precision_6: 0.5000 - val_recall_6: 0.0078\n",
      "Epoch 17/70\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 131.5132 - accuracy: 0.4701 - MSE: 0.2191 - precision_6: 0.5104 - recall_6: 0.3516 - val_loss: 118.8162 - val_accuracy: 0.3672 - val_MSE: 0.2184 - val_precision_6: 0.6667 - val_recall_6: 0.0156\n",
      "Epoch 18/70\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 108.8343 - accuracy: 0.4831 - MSE: 0.2140 - precision_6: 0.5134 - recall_6: 0.3490 - val_loss: 97.5847 - val_accuracy: 0.3984 - val_MSE: 0.2195 - val_precision_6: 0.1667 - val_recall_6: 0.0078\n",
      "Epoch 19/70\n",
      "12/12 [==============================] - 1s 118ms/step - loss: 88.9649 - accuracy: 0.4922 - MSE: 0.2091 - precision_6: 0.5408 - recall_6: 0.3542 - val_loss: 79.0763 - val_accuracy: 0.3984 - val_MSE: 0.2204 - val_precision_6: 0.4444 - val_recall_6: 0.0312\n",
      "Epoch 20/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 118ms/step - loss: 71.4517 - accuracy: 0.5143 - MSE: 0.2041 - precision_6: 0.5675 - recall_6: 0.3776 - val_loss: 62.7530 - val_accuracy: 0.3984 - val_MSE: 0.2190 - val_precision_6: 0.4444 - val_recall_6: 0.0312\n",
      "Epoch 21/70\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 56.1146 - accuracy: 0.5286 - MSE: 0.1974 - precision_6: 0.5870 - recall_6: 0.3867 - val_loss: 48.8319 - val_accuracy: 0.3828 - val_MSE: 0.2196 - val_precision_6: 0.4286 - val_recall_6: 0.0234\n",
      "Epoch 22/70\n",
      "12/12 [==============================] - 2s 132ms/step - loss: 43.1643 - accuracy: 0.5117 - MSE: 0.1956 - precision_6: 0.5977 - recall_6: 0.3984 - val_loss: 36.8552 - val_accuracy: 0.3516 - val_MSE: 0.2203 - val_precision_6: 0.3333 - val_recall_6: 0.0156\n",
      "Epoch 23/70\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 32.1851 - accuracy: 0.5638 - MSE: 0.1828 - precision_6: 0.6423 - recall_6: 0.4232 - val_loss: 27.3846 - val_accuracy: 0.4062 - val_MSE: 0.2197 - val_precision_6: 0.3333 - val_recall_6: 0.0234\n",
      "Epoch 24/70\n",
      "12/12 [==============================] - 1s 118ms/step - loss: 23.6121 - accuracy: 0.6003 - MSE: 0.1780 - precision_6: 0.6550 - recall_6: 0.4401 - val_loss: 19.9728 - val_accuracy: 0.3906 - val_MSE: 0.2207 - val_precision_6: 0.3636 - val_recall_6: 0.0312\n",
      "Epoch 25/70\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 17.3263 - accuracy: 0.5951 - MSE: 0.1722 - precision_6: 0.6673 - recall_6: 0.4570 - val_loss: 14.6004 - val_accuracy: 0.3984 - val_MSE: 0.2181 - val_precision_6: 0.3750 - val_recall_6: 0.0234\n",
      "Epoch 26/70\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 12.9490 - accuracy: 0.6042 - MSE: 0.1679 - precision_6: 0.6825 - recall_6: 0.4674 - val_loss: 11.8805 - val_accuracy: 0.3984 - val_MSE: 0.2162 - val_precision_6: 0.5000 - val_recall_6: 0.0391\n",
      "Epoch 27/70\n",
      "12/12 [==============================] - 1s 118ms/step - loss: 10.5232 - accuracy: 0.6289 - MSE: 0.1625 - precision_6: 0.7135 - recall_6: 0.4896 - val_loss: 9.2591 - val_accuracy: 0.3828 - val_MSE: 0.2187 - val_precision_6: 0.4615 - val_recall_6: 0.0469\n",
      "Epoch 28/70\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 8.9465 - accuracy: 0.6380 - MSE: 0.1588 - precision_6: 0.7111 - recall_6: 0.5000 - val_loss: 8.4388 - val_accuracy: 0.3828 - val_MSE: 0.2198 - val_precision_6: 0.6111 - val_recall_6: 0.0859\n",
      "Epoch 29/70\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 8.1246 - accuracy: 0.6315 - MSE: 0.1632 - precision_6: 0.7030 - recall_6: 0.4961 - val_loss: 7.5464 - val_accuracy: 0.3984 - val_MSE: 0.2206 - val_precision_6: 0.5417 - val_recall_6: 0.10162629 - accuracy: 0.6285 - MSE: 0.1660 - precision_6: 0.6968 - recall_6: 0.\n",
      "Epoch 30/70\n",
      "12/12 [==============================] - 1s 118ms/step - loss: 7.0680 - accuracy: 0.6549 - MSE: 0.1570 - precision_6: 0.7384 - recall_6: 0.5182 - val_loss: 6.8895 - val_accuracy: 0.3828 - val_MSE: 0.2246 - val_precision_6: 0.4800 - val_recall_6: 0.0938\n",
      "Epoch 31/70\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 6.9085 - accuracy: 0.6406 - MSE: 0.1632 - precision_6: 0.6929 - recall_6: 0.5052 - val_loss: 7.1285 - val_accuracy: 0.3906 - val_MSE: 0.2164 - val_precision_6: 0.6923 - val_recall_6: 0.1406\n",
      "Epoch 32/70\n",
      "12/12 [==============================] - 2s 126ms/step - loss: 6.5855 - accuracy: 0.6719 - MSE: 0.1511 - precision_6: 0.7469 - recall_6: 0.5573 - val_loss: 6.1795 - val_accuracy: 0.4219 - val_MSE: 0.2190 - val_precision_6: 0.5517 - val_recall_6: 0.1250\n",
      "Epoch 33/70\n",
      "12/12 [==============================] - 1s 123ms/step - loss: 6.2217 - accuracy: 0.6276 - MSE: 0.1606 - precision_6: 0.6920 - recall_6: 0.4974 - val_loss: 6.3533 - val_accuracy: 0.3672 - val_MSE: 0.2202 - val_precision_6: 0.5000 - val_recall_6: 0.1406\n",
      "Epoch 34/70\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 6.3362 - accuracy: 0.6393 - MSE: 0.1586 - precision_6: 0.6950 - recall_6: 0.5221 - val_loss: 7.0642 - val_accuracy: 0.3125 - val_MSE: 0.2336 - val_precision_6: 0.2903 - val_recall_6: 0.0703\n",
      "Epoch 35/70\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 6.2615 - accuracy: 0.6445 - MSE: 0.1549 - precision_6: 0.7035 - recall_6: 0.5221 - val_loss: 6.5533 - val_accuracy: 0.3281 - val_MSE: 0.2354 - val_precision_6: 0.4118 - val_recall_6: 0.1094\n",
      "Epoch 36/70\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 6.0957 - accuracy: 0.6589 - MSE: 0.1528 - precision_6: 0.7418 - recall_6: 0.5573 - val_loss: 6.6270 - val_accuracy: 0.4062 - val_MSE: 0.2215 - val_precision_6: 0.4634 - val_recall_6: 0.1484\n",
      "Epoch 37/70\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 6.5654 - accuracy: 0.6510 - MSE: 0.1536 - precision_6: 0.7211 - recall_6: 0.5352 - val_loss: 6.8838 - val_accuracy: 0.3828 - val_MSE: 0.2241 - val_precision_6: 0.4615 - val_recall_6: 0.1406\n",
      "Epoch 38/70\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 5.9377 - accuracy: 0.6497 - MSE: 0.1555 - precision_6: 0.7099 - recall_6: 0.5417 - val_loss: 6.5789 - val_accuracy: 0.3828 - val_MSE: 0.2325 - val_precision_6: 0.4694 - val_recall_6: 0.1797\n",
      "Epoch 39/70\n",
      "12/12 [==============================] - 1s 123ms/step - loss: 5.6405 - accuracy: 0.6771 - MSE: 0.1484 - precision_6: 0.7435 - recall_6: 0.5547 - val_loss: 5.7734 - val_accuracy: 0.4297 - val_MSE: 0.2277 - val_precision_6: 0.4762 - val_recall_6: 0.2344\n",
      "Epoch 40/70\n",
      "12/12 [==============================] - 1s 118ms/step - loss: 6.0098 - accuracy: 0.6471 - MSE: 0.1615 - precision_6: 0.6942 - recall_6: 0.5469 - val_loss: 6.8205 - val_accuracy: 0.3438 - val_MSE: 0.2328 - val_precision_6: 0.4912 - val_recall_6: 0.2188\n",
      "Epoch 41/70\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 6.2699 - accuracy: 0.6706 - MSE: 0.1520 - precision_6: 0.7338 - recall_6: 0.5599 - val_loss: 6.2975 - val_accuracy: 0.3438 - val_MSE: 0.2405 - val_precision_6: 0.3793 - val_recall_6: 0.1719\n",
      "Epoch 42/70\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 6.1422 - accuracy: 0.6719 - MSE: 0.1493 - precision_6: 0.7462 - recall_6: 0.5703 - val_loss: 6.0514 - val_accuracy: 0.3906 - val_MSE: 0.2351 - val_precision_6: 0.4462 - val_recall_6: 0.2266\n",
      "Epoch 43/70\n",
      "12/12 [==============================] - 2s 135ms/step - loss: 5.5908 - accuracy: 0.6862 - MSE: 0.1467 - precision_6: 0.7446 - recall_6: 0.5807 - val_loss: 6.1932 - val_accuracy: 0.3281 - val_MSE: 0.2471 - val_precision_6: 0.3390 - val_recall_6: 0.1562\n",
      "Epoch 44/70\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 5.9241 - accuracy: 0.6549 - MSE: 0.1537 - precision_6: 0.7274 - recall_6: 0.5664 - val_loss: 6.6065 - val_accuracy: 0.4219 - val_MSE: 0.2284 - val_precision_6: 0.4462 - val_recall_6: 0.2266\n",
      "Epoch 45/70\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 5.9311 - accuracy: 0.6589 - MSE: 0.1551 - precision_6: 0.7247 - recall_6: 0.5312 - val_loss: 6.7812 - val_accuracy: 0.3984 - val_MSE: 0.2412 - val_precision_6: 0.4247 - val_recall_6: 0.2422\n",
      "Epoch 46/70\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 5.7529 - accuracy: 0.6562 - MSE: 0.1469 - precision_6: 0.7412 - recall_6: 0.5742 - val_loss: 6.0291 - val_accuracy: 0.3672 - val_MSE: 0.2435 - val_precision_6: 0.3803 - val_recall_6: 0.2109\n",
      "Epoch 47/70\n",
      "12/12 [==============================] - 1s 118ms/step - loss: 5.6626 - accuracy: 0.6680 - MSE: 0.1486 - precision_6: 0.7341 - recall_6: 0.5716 - val_loss: 6.5322 - val_accuracy: 0.3047 - val_MSE: 0.2702 - val_precision_6: 0.2963 - val_recall_6: 0.1875\n",
      "Epoch 48/70\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 5.6163 - accuracy: 0.6549 - MSE: 0.1524 - precision_6: 0.7224 - recall_6: 0.5456 - val_loss: 6.1792 - val_accuracy: 0.3516 - val_MSE: 0.2601 - val_precision_6: 0.3529 - val_recall_6: 0.2344\n",
      "Epoch 49/70\n",
      "12/12 [==============================] - 1s 118ms/step - loss: 5.8429 - accuracy: 0.6628 - MSE: 0.1509 - precision_6: 0.7103 - recall_6: 0.5586 - val_loss: 6.4325 - val_accuracy: 0.3906 - val_MSE: 0.2528 - val_precision_6: 0.4471 - val_recall_6: 0.2969\n",
      "Epoch 50/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 119ms/step - loss: 5.8397 - accuracy: 0.6745 - MSE: 0.1484 - precision_6: 0.7454 - recall_6: 0.5794 - val_loss: 6.6130 - val_accuracy: 0.3516 - val_MSE: 0.2562 - val_precision_6: 0.4048 - val_recall_6: 0.2656\n",
      "Epoch 51/70\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 5.7694 - accuracy: 0.6927 - MSE: 0.1388 - precision_6: 0.7671 - recall_6: 0.6003 - val_loss: 5.8862 - val_accuracy: 0.3438 - val_MSE: 0.2655 - val_precision_6: 0.3614 - val_recall_6: 0.2344270 - accuracy: 0.6932 - MSE: 0.1388 - precision_6: 0.7673 - recall_6: 0.59\n",
      "Epoch 52/70\n",
      "12/12 [==============================] - 1s 118ms/step - loss: 5.7302 - accuracy: 0.6823 - MSE: 0.1458 - precision_6: 0.7491 - recall_6: 0.5716 - val_loss: 6.1491 - val_accuracy: 0.3594 - val_MSE: 0.2546 - val_precision_6: 0.4535 - val_recall_6: 0.3047\n",
      "Epoch 53/70\n",
      "12/12 [==============================] - 2s 133ms/step - loss: 5.6520 - accuracy: 0.6797 - MSE: 0.1470 - precision_6: 0.7471 - recall_6: 0.5807 - val_loss: 6.8873 - val_accuracy: 0.3438 - val_MSE: 0.2511 - val_precision_6: 0.4062 - val_recall_6: 0.3047\n",
      "Epoch 54/70\n",
      "12/12 [==============================] - 1s 118ms/step - loss: 5.5604 - accuracy: 0.6784 - MSE: 0.1473 - precision_6: 0.7454 - recall_6: 0.5833 - val_loss: 5.7204 - val_accuracy: 0.3047 - val_MSE: 0.2688 - val_precision_6: 0.3846 - val_recall_6: 0.2344\n",
      "Epoch 55/70\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 5.8756 - accuracy: 0.6693 - MSE: 0.1531 - precision_6: 0.7141 - recall_6: 0.5690 - val_loss: 6.0834 - val_accuracy: 0.3906 - val_MSE: 0.2546 - val_precision_6: 0.4505 - val_recall_6: 0.3203\n",
      "Epoch 56/70\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 5.6123 - accuracy: 0.6979 - MSE: 0.1418 - precision_6: 0.7744 - recall_6: 0.5990 - val_loss: 6.1975 - val_accuracy: 0.3750 - val_MSE: 0.2657 - val_precision_6: 0.3882 - val_recall_6: 0.2578\n",
      "Epoch 57/70\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 5.6454 - accuracy: 0.6602 - MSE: 0.1547 - precision_6: 0.7209 - recall_6: 0.5482 - val_loss: 6.9147 - val_accuracy: 0.3984 - val_MSE: 0.2546 - val_precision_6: 0.3854 - val_recall_6: 0.2891\n",
      "Epoch 58/70\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 5.6473 - accuracy: 0.6680 - MSE: 0.1459 - precision_6: 0.7424 - recall_6: 0.5742 - val_loss: 6.1557 - val_accuracy: 0.3750 - val_MSE: 0.2582 - val_precision_6: 0.4545 - val_recall_6: 0.3125\n",
      "Epoch 59/70\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 5.6654 - accuracy: 0.6836 - MSE: 0.1476 - precision_6: 0.7583 - recall_6: 0.5964 - val_loss: 6.4041 - val_accuracy: 0.4219 - val_MSE: 0.2484 - val_precision_6: 0.4773 - val_recall_6: 0.3281\n",
      "Epoch 60/70\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 5.4519 - accuracy: 0.7005 - MSE: 0.1402 - precision_6: 0.7623 - recall_6: 0.5846 - val_loss: 6.9857 - val_accuracy: 0.3047 - val_MSE: 0.2842 - val_precision_6: 0.3368 - val_recall_6: 0.2500\n",
      "Epoch 61/70\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 5.5795 - accuracy: 0.6914 - MSE: 0.1410 - precision_6: 0.7639 - recall_6: 0.5898 - val_loss: 6.6555 - val_accuracy: 0.3516 - val_MSE: 0.2736 - val_precision_6: 0.3295 - val_recall_6: 0.2266\n",
      "Epoch 62/70\n",
      "12/12 [==============================] - 1s 118ms/step - loss: 5.6293 - accuracy: 0.6992 - MSE: 0.1413 - precision_6: 0.7695 - recall_6: 0.5911 - val_loss: 5.7603 - val_accuracy: 0.4141 - val_MSE: 0.2602 - val_precision_6: 0.4314 - val_recall_6: 0.3438\n",
      "Epoch 63/70\n",
      "12/12 [==============================] - 1s 124ms/step - loss: 5.7018 - accuracy: 0.6888 - MSE: 0.1441 - precision_6: 0.7534 - recall_6: 0.5768 - val_loss: 6.5935 - val_accuracy: 0.4062 - val_MSE: 0.2581 - val_precision_6: 0.4583 - val_recall_6: 0.3438\n",
      "Epoch 64/70\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 5.8309 - accuracy: 0.7122 - MSE: 0.1394 - precision_6: 0.7752 - recall_6: 0.6016 - val_loss: 7.7500 - val_accuracy: 0.3750 - val_MSE: 0.2723 - val_precision_6: 0.3922 - val_recall_6: 0.3125\n",
      "Epoch 65/70\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 5.7486 - accuracy: 0.6888 - MSE: 0.1388 - precision_6: 0.7636 - recall_6: 0.6016 - val_loss: 5.7803 - val_accuracy: 0.3359 - val_MSE: 0.2671 - val_precision_6: 0.3627 - val_recall_6: 0.2891\n",
      "Epoch 66/70\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 5.6067 - accuracy: 0.6797 - MSE: 0.1479 - precision_6: 0.7449 - recall_6: 0.5703 - val_loss: 6.0720 - val_accuracy: 0.3594 - val_MSE: 0.2617 - val_precision_6: 0.3511 - val_recall_6: 0.2578\n",
      "Epoch 67/70\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 5.6862 - accuracy: 0.6732 - MSE: 0.1487 - precision_6: 0.7328 - recall_6: 0.5677 - val_loss: 6.4286 - val_accuracy: 0.3828 - val_MSE: 0.2702 - val_precision_6: 0.4062 - val_recall_6: 0.3047\n",
      "Epoch 68/70\n",
      "12/12 [==============================] - 1s 119ms/step - loss: 5.8771 - accuracy: 0.6784 - MSE: 0.1490 - precision_6: 0.7392 - recall_6: 0.5794 - val_loss: 6.0460 - val_accuracy: 0.3828 - val_MSE: 0.2687 - val_precision_6: 0.4239 - val_recall_6: 0.3047\n",
      "Epoch 69/70\n",
      "12/12 [==============================] - 1s 118ms/step - loss: 5.5194 - accuracy: 0.6992 - MSE: 0.1420 - precision_6: 0.7682 - recall_6: 0.5911 - val_loss: 6.8338 - val_accuracy: 0.3828 - val_MSE: 0.2736 - val_precision_6: 0.3684 - val_recall_6: 0.273491 - accuracy: 0.7000 - MSE: 0.1412 - precision_6: 0.7635 - recall_6: 0.5\n",
      "Epoch 70/70\n",
      "12/12 [==============================] - 1s 118ms/step - loss: 5.5769 - accuracy: 0.6914 - MSE: 0.1420 - precision_6: 0.7472 - recall_6: 0.6042 - val_loss: 6.2190 - val_accuracy: 0.4062 - val_MSE: 0.2646 - val_precision_6: 0.3846 - val_recall_6: 0.2734\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (32, 512)                 13340672  \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (32, 512)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (32, 512)                 2048      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (32, 3)                   1539      \n",
      "=================================================================\n",
      "Total params: 13,344,259\n",
      "Trainable params: 13,343,235\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "Starting: \n",
      "{'batch_size': 32, 'epochs': 75, 'learning_rate': 0.001, 'optimizer': 'sgd'}\n",
      "---------------------------------------------------------------------------------\n",
      "{   'activation': 'softmax',\n",
      "    'dropout_rate': 0.4,\n",
      "    'filters': 9,\n",
      "    'kernel_size': 3,\n",
      "    'l1_r': 0.0001,\n",
      "    'l2_r': 0.001,\n",
      "    'output_layer_activation': 'softmax',\n",
      "    'padding': 'same',\n",
      "    'start_neurons': 512}\n",
      "Epoch 1/75\n",
      " 2/25 [=>............................] - ETA: 24s - loss: 21.4545 - accuracy: 0.2500 - MSE: 0.2248 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2349s vs `on_train_batch_end` time: 1.8493s). Check your callbacks.\n",
      "25/25 [==============================] - 10s 400ms/step - loss: 21.4426 - accuracy: 0.3162 - MSE: 0.2227 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.4385 - val_accuracy: 0.2266 - val_MSE: 0.2223 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 2/75\n",
      "25/25 [==============================] - 8s 321ms/step - loss: 21.4351 - accuracy: 0.3413 - MSE: 0.2222 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.4335 - val_accuracy: 0.2578 - val_MSE: 0.2224 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 3/75\n",
      "25/25 [==============================] - 8s 304ms/step - loss: 21.4286 - accuracy: 0.3475 - MSE: 0.2218 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.4286 - val_accuracy: 0.2656 - val_MSE: 0.2224 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 4/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 8s 321ms/step - loss: 21.4215 - accuracy: 0.3887 - MSE: 0.2214 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.4238 - val_accuracy: 0.2656 - val_MSE: 0.2225 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 5/75\n",
      "25/25 [==============================] - 8s 304ms/step - loss: 21.4124 - accuracy: 0.3913 - MSE: 0.2205 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.4189 - val_accuracy: 0.2656 - val_MSE: 0.2225 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 6/75\n",
      "25/25 [==============================] - 8s 314ms/step - loss: 21.4054 - accuracy: 0.4225 - MSE: 0.2201 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.4139 - val_accuracy: 0.2656 - val_MSE: 0.2226 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 7/75\n",
      "25/25 [==============================] - 8s 309ms/step - loss: 21.4024 - accuracy: 0.3862 - MSE: 0.2205 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.4091 - val_accuracy: 0.2656 - val_MSE: 0.2226 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 8/75\n",
      "25/25 [==============================] - 8s 306ms/step - loss: 21.3951 - accuracy: 0.3938 - MSE: 0.2201 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.4042 - val_accuracy: 0.2656 - val_MSE: 0.2227 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 9/75\n",
      "25/25 [==============================] - 8s 312ms/step - loss: 21.3861 - accuracy: 0.4475 - MSE: 0.2192 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.3993 - val_accuracy: 0.2656 - val_MSE: 0.2227 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 10/75\n",
      "25/25 [==============================] - 8s 304ms/step - loss: 21.3781 - accuracy: 0.4437 - MSE: 0.2185 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.3945 - val_accuracy: 0.2656 - val_MSE: 0.2228 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 11/75\n",
      "25/25 [==============================] - 8s 330ms/step - loss: 21.3758 - accuracy: 0.4325 - MSE: 0.2192 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.3896 - val_accuracy: 0.2656 - val_MSE: 0.2228 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 12/75\n",
      "25/25 [==============================] - 8s 309ms/step - loss: 21.3699 - accuracy: 0.4400 - MSE: 0.2190 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.3848 - val_accuracy: 0.2656 - val_MSE: 0.2229 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 13/75\n",
      "25/25 [==============================] - 8s 318ms/step - loss: 21.3618 - accuracy: 0.4688 - MSE: 0.2183 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.3801 - val_accuracy: 0.2656 - val_MSE: 0.2230 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 14/75\n",
      "25/25 [==============================] - 8s 315ms/step - loss: 21.3578 - accuracy: 0.4462 - MSE: 0.2186 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.3753 - val_accuracy: 0.2656 - val_MSE: 0.2230 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 15/75\n",
      "25/25 [==============================] - 8s 318ms/step - loss: 21.3525 - accuracy: 0.4613 - MSE: 0.2185 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.3705 - val_accuracy: 0.2656 - val_MSE: 0.2231 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 16/75\n",
      "25/25 [==============================] - 8s 309ms/step - loss: 21.3437 - accuracy: 0.4638 - MSE: 0.2177 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.3658 - val_accuracy: 0.2656 - val_MSE: 0.2232 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 17/75\n",
      "25/25 [==============================] - 8s 326ms/step - loss: 21.3377 - accuracy: 0.4812 - MSE: 0.2175 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.3610 - val_accuracy: 0.2656 - val_MSE: 0.2233 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 18/75\n",
      "25/25 [==============================] - 8s 338ms/step - loss: 21.3353 - accuracy: 0.4450 - MSE: 0.2181 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.3563 - val_accuracy: 0.2578 - val_MSE: 0.2234 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 19/75\n",
      "25/25 [==============================] - 8s 334ms/step - loss: 21.3266 - accuracy: 0.5063 - MSE: 0.2173 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.3516 - val_accuracy: 0.2422 - val_MSE: 0.2234 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 20/75\n",
      "25/25 [==============================] - 8s 314ms/step - loss: 21.3227 - accuracy: 0.4850 - MSE: 0.2175 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.3469 - val_accuracy: 0.2344 - val_MSE: 0.2235 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 21/75\n",
      "25/25 [==============================] - 8s 315ms/step - loss: 21.3157 - accuracy: 0.5088 - MSE: 0.2171 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.3423 - val_accuracy: 0.2344 - val_MSE: 0.2236 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 22/75\n",
      "25/25 [==============================] - 8s 321ms/step - loss: 21.3100 - accuracy: 0.4888 - MSE: 0.2170 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.3378 - val_accuracy: 0.2344 - val_MSE: 0.2238 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 23/75\n",
      "25/25 [==============================] - 8s 303ms/step - loss: 21.3042 - accuracy: 0.5075 - MSE: 0.2168 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.3331 - val_accuracy: 0.2422 - val_MSE: 0.2239 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 24/75\n",
      "25/25 [==============================] - 8s 317ms/step - loss: 21.3000 - accuracy: 0.4850 - MSE: 0.2170 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.3286 - val_accuracy: 0.2344 - val_MSE: 0.2240 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 25/75\n",
      "25/25 [==============================] - 8s 308ms/step - loss: 21.2923 - accuracy: 0.5200 - MSE: 0.2164 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.3240 - val_accuracy: 0.2344 - val_MSE: 0.2241 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 26/75\n",
      "25/25 [==============================] - 8s 314ms/step - loss: 21.2889 - accuracy: 0.5088 - MSE: 0.2168 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.3194 - val_accuracy: 0.2422 - val_MSE: 0.2242 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 27/75\n",
      "25/25 [==============================] - 8s 307ms/step - loss: 21.2843 - accuracy: 0.4825 - MSE: 0.2169 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.3147 - val_accuracy: 0.2344 - val_MSE: 0.2243 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 28/75\n",
      "25/25 [==============================] - 8s 330ms/step - loss: 21.2760 - accuracy: 0.5225 - MSE: 0.2162 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.3101 - val_accuracy: 0.2344 - val_MSE: 0.2244 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 29/75\n",
      "25/25 [==============================] - 8s 317ms/step - loss: 21.2704 - accuracy: 0.5075 - MSE: 0.2161 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.3054 - val_accuracy: 0.2266 - val_MSE: 0.2245 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 30/75\n",
      "25/25 [==============================] - 8s 313ms/step - loss: 21.2658 - accuracy: 0.5188 - MSE: 0.2162 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.3008 - val_accuracy: 0.2344 - val_MSE: 0.2246 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 31/75\n",
      "25/25 [==============================] - 8s 319ms/step - loss: 21.2598 - accuracy: 0.5300 - MSE: 0.2160 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.2960 - val_accuracy: 0.2422 - val_MSE: 0.2246 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 32/75\n",
      "25/25 [==============================] - 8s 315ms/step - loss: 21.2570 - accuracy: 0.5125 - MSE: 0.2165 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.2912 - val_accuracy: 0.2422 - val_MSE: 0.2247 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 33/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 8s 328ms/step - loss: 21.2499 - accuracy: 0.5325 - MSE: 0.2160 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.2864 - val_accuracy: 0.2422 - val_MSE: 0.2248 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 34/75\n",
      "25/25 [==============================] - 8s 309ms/step - loss: 21.2416 - accuracy: 0.5412 - MSE: 0.2153 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.2816 - val_accuracy: 0.2422 - val_MSE: 0.2248 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 35/75\n",
      "25/25 [==============================] - 8s 320ms/step - loss: 21.2389 - accuracy: 0.5150 - MSE: 0.2158 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.2767 - val_accuracy: 0.2422 - val_MSE: 0.2249 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 36/75\n",
      "25/25 [==============================] - 8s 306ms/step - loss: 21.2333 - accuracy: 0.5263 - MSE: 0.2157 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.2719 - val_accuracy: 0.2422 - val_MSE: 0.2249 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 37/75\n",
      "25/25 [==============================] - 8s 321ms/step - loss: 21.2281 - accuracy: 0.5387 - MSE: 0.2157 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.2669 - val_accuracy: 0.2422 - val_MSE: 0.2250 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 38/75\n",
      "25/25 [==============================] - 8s 304ms/step - loss: 21.2211 - accuracy: 0.5400 - MSE: 0.2153 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.2620 - val_accuracy: 0.2422 - val_MSE: 0.2250 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 39/75\n",
      "25/25 [==============================] - 8s 327ms/step - loss: 21.2196 - accuracy: 0.5075 - MSE: 0.2161 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.2570 - val_accuracy: 0.2422 - val_MSE: 0.2250 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 40/75\n",
      "25/25 [==============================] - 8s 305ms/step - loss: 21.2090 - accuracy: 0.5412 - MSE: 0.2148 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.2521 - val_accuracy: 0.2422 - val_MSE: 0.2250 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 41/75\n",
      "25/25 [==============================] - 8s 325ms/step - loss: 21.2039 - accuracy: 0.5587 - MSE: 0.2148 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.2472 - val_accuracy: 0.2422 - val_MSE: 0.2251 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 42/75\n",
      "25/25 [==============================] - 8s 308ms/step - loss: 21.2003 - accuracy: 0.5362 - MSE: 0.2151 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.2423 - val_accuracy: 0.2344 - val_MSE: 0.2251 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 43/75\n",
      "25/25 [==============================] - 8s 302ms/step - loss: 21.1941 - accuracy: 0.5312 - MSE: 0.2149 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.2373 - val_accuracy: 0.2344 - val_MSE: 0.2251 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 44/75\n",
      "25/25 [==============================] - 8s 313ms/step - loss: 21.1892 - accuracy: 0.5412 - MSE: 0.2149 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.2324 - val_accuracy: 0.2266 - val_MSE: 0.2252 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 45/75\n",
      "25/25 [==============================] - 8s 313ms/step - loss: 21.1857 - accuracy: 0.5113 - MSE: 0.2153 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.2274 - val_accuracy: 0.2266 - val_MSE: 0.2252 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 46/75\n",
      "25/25 [==============================] - 8s 318ms/step - loss: 21.1785 - accuracy: 0.5375 - MSE: 0.2148 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.2224 - val_accuracy: 0.2266 - val_MSE: 0.2252 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 47/75\n",
      "25/25 [==============================] - 8s 308ms/step - loss: 21.1726 - accuracy: 0.5475 - MSE: 0.2146 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.2173 - val_accuracy: 0.2266 - val_MSE: 0.2252 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 48/75\n",
      "25/25 [==============================] - 8s 315ms/step - loss: 21.1659 - accuracy: 0.5500 - MSE: 0.2142 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.2124 - val_accuracy: 0.2344 - val_MSE: 0.2252 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 49/75\n",
      "25/25 [==============================] - 8s 311ms/step - loss: 21.1630 - accuracy: 0.5412 - MSE: 0.2147 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.2074 - val_accuracy: 0.2344 - val_MSE: 0.2253 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 50/75\n",
      "25/25 [==============================] - 8s 318ms/step - loss: 21.1557 - accuracy: 0.5412 - MSE: 0.2142 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.2025 - val_accuracy: 0.2344 - val_MSE: 0.2253 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 51/75\n",
      "25/25 [==============================] - 8s 314ms/step - loss: 21.1530 - accuracy: 0.5475 - MSE: 0.2147 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.1975 - val_accuracy: 0.2344 - val_MSE: 0.2253 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 52/75\n",
      "25/25 [==============================] - 8s 329ms/step - loss: 21.1454 - accuracy: 0.5487 - MSE: 0.2142 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.1925 - val_accuracy: 0.2344 - val_MSE: 0.2253 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 53/75\n",
      "25/25 [==============================] - 8s 317ms/step - loss: 21.1396 - accuracy: 0.5587 - MSE: 0.2140 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.1874 - val_accuracy: 0.2344 - val_MSE: 0.2253 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 54/75\n",
      "25/25 [==============================] - 8s 327ms/step - loss: 21.1365 - accuracy: 0.5425 - MSE: 0.2145 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.1823 - val_accuracy: 0.2344 - val_MSE: 0.2253 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 55/75\n",
      "25/25 [==============================] - 8s 318ms/step - loss: 21.1338 - accuracy: 0.5138 - MSE: 0.2150 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.1773 - val_accuracy: 0.2344 - val_MSE: 0.2253 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 56/75\n",
      "25/25 [==============================] - 8s 310ms/step - loss: 21.1230 - accuracy: 0.5512 - MSE: 0.2137 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.1723 - val_accuracy: 0.2344 - val_MSE: 0.2253 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 57/75\n",
      "25/25 [==============================] - 9s 343ms/step - loss: 21.1186 - accuracy: 0.5462 - MSE: 0.2138 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.1673 - val_accuracy: 0.2344 - val_MSE: 0.2253 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 58/75\n",
      "25/25 [==============================] - 8s 319ms/step - loss: 21.1145 - accuracy: 0.5375 - MSE: 0.2141 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.1622 - val_accuracy: 0.2344 - val_MSE: 0.2254 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 59/75\n",
      "25/25 [==============================] - 8s 317ms/step - loss: 21.1125 - accuracy: 0.5263 - MSE: 0.2148 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.1573 - val_accuracy: 0.2266 - val_MSE: 0.2254 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 60/75\n",
      "25/25 [==============================] - 8s 310ms/step - loss: 21.1024 - accuracy: 0.5425 - MSE: 0.2136 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.1522 - val_accuracy: 0.2344 - val_MSE: 0.2254 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 61/75\n",
      "25/25 [==============================] - 8s 333ms/step - loss: 21.0940 - accuracy: 0.5750 - MSE: 0.2129 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.1472 - val_accuracy: 0.2266 - val_MSE: 0.2254 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/75\n",
      "25/25 [==============================] - 8s 314ms/step - loss: 21.0942 - accuracy: 0.5288 - MSE: 0.2140 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.1422 - val_accuracy: 0.2266 - val_MSE: 0.2254 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 63/75\n",
      "25/25 [==============================] - 8s 323ms/step - loss: 21.0869 - accuracy: 0.5725 - MSE: 0.2135 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.1372 - val_accuracy: 0.2266 - val_MSE: 0.2254 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 64/75\n",
      "25/25 [==============================] - 8s 320ms/step - loss: 21.0851 - accuracy: 0.5312 - MSE: 0.2143 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.1321 - val_accuracy: 0.2266 - val_MSE: 0.2254 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 65/75\n",
      "25/25 [==============================] - 8s 315ms/step - loss: 21.0765 - accuracy: 0.5387 - MSE: 0.2135 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.1271 - val_accuracy: 0.2266 - val_MSE: 0.2254 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 66/75\n",
      "25/25 [==============================] - 8s 312ms/step - loss: 21.0726 - accuracy: 0.5450 - MSE: 0.2137 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.1221 - val_accuracy: 0.2344 - val_MSE: 0.2254 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 67/75\n",
      "25/25 [==============================] - 8s 313ms/step - loss: 21.0674 - accuracy: 0.5362 - MSE: 0.2137 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.1172 - val_accuracy: 0.2344 - val_MSE: 0.2254 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 68/75\n",
      "25/25 [==============================] - 8s 319ms/step - loss: 21.0609 - accuracy: 0.5525 - MSE: 0.2134 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.1122 - val_accuracy: 0.2344 - val_MSE: 0.2255 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 69/75\n",
      "25/25 [==============================] - 8s 307ms/step - loss: 21.0575 - accuracy: 0.5612 - MSE: 0.2138 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.1072 - val_accuracy: 0.2344 - val_MSE: 0.2255 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 70/75\n",
      "25/25 [==============================] - 8s 315ms/step - loss: 21.0501 - accuracy: 0.5738 - MSE: 0.2132 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.1022 - val_accuracy: 0.2344 - val_MSE: 0.2255 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 71/75\n",
      "25/25 [==============================] - 8s 309ms/step - loss: 21.0455 - accuracy: 0.5275 - MSE: 0.2133 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.0972 - val_accuracy: 0.2344 - val_MSE: 0.2255 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 72/75\n",
      "25/25 [==============================] - 8s 319ms/step - loss: 21.0392 - accuracy: 0.5587 - MSE: 0.2130 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.0920 - val_accuracy: 0.2344 - val_MSE: 0.2255 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 73/75\n",
      "25/25 [==============================] - 8s 329ms/step - loss: 21.0330 - accuracy: 0.5600 - MSE: 0.2128 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.0870 - val_accuracy: 0.2344 - val_MSE: 0.2255 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 74/75\n",
      "25/25 [==============================] - 8s 318ms/step - loss: 21.0303 - accuracy: 0.5600 - MSE: 0.2133 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.0820 - val_accuracy: 0.2344 - val_MSE: 0.2255 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 75/75\n",
      "25/25 [==============================] - 8s 313ms/step - loss: 21.0266 - accuracy: 0.5350 - MSE: 0.2136 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - val_loss: 21.0770 - val_accuracy: 0.2344 - val_MSE: 0.2255 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (32, 32)                  772352    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (32, 32)                  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (32, 32)                  128       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (32, 3)                   99        \n",
      "=================================================================\n",
      "Total params: 772,579\n",
      "Trainable params: 772,515\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "Starting: \n",
      "{'batch_size': 32, 'epochs': 80, 'learning_rate': 0.001, 'optimizer': 'rmsprop'}\n",
      "---------------------------------------------------------------------------------\n",
      "{   'activation': 'softmax',\n",
      "    'dropout_rate': 0,\n",
      "    'filters': 9,\n",
      "    'kernel_size': 3,\n",
      "    'l1_r': 0.001,\n",
      "    'l2_r': 0.001,\n",
      "    'output_layer_activation': 'softmax',\n",
      "    'padding': 'valid',\n",
      "    'start_neurons': 32}\n",
      "Epoch 1/80\n",
      " 2/25 [=>............................] - ETA: 25s - loss: 12.7428 - accuracy: 0.3906 - MSE: 0.2502 - precision_8: 0.3333 - recall_8: 0.1875WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0280s vs `on_train_batch_end` time: 2.1909s). Check your callbacks.\n",
      "25/25 [==============================] - 5s 197ms/step - loss: 8.3053 - accuracy: 0.3225 - MSE: 0.2559 - precision_8: 0.3357 - recall_8: 0.1750 - val_loss: 6.4742 - val_accuracy: 0.4219 - val_MSE: 0.2218 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00\n",
      "Epoch 2/80\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 6.2208 - accuracy: 0.4100 - MSE: 0.2238 - precision_8: 0.4651 - recall_8: 0.2250 - val_loss: 5.9652 - val_accuracy: 0.4219 - val_MSE: 0.2214 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00\n",
      "Epoch 3/80\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 5.6790 - accuracy: 0.5050 - MSE: 0.2070 - precision_8: 0.5766 - recall_8: 0.2962 - val_loss: 5.5531 - val_accuracy: 0.3984 - val_MSE: 0.2211 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00\n",
      "Epoch 4/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 5.2588 - accuracy: 0.4975 - MSE: 0.1993 - precision_8: 0.5725 - recall_8: 0.2962 - val_loss: 5.2102 - val_accuracy: 0.4219 - val_MSE: 0.2207 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00\n",
      "Epoch 5/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 4.9388 - accuracy: 0.5525 - MSE: 0.1883 - precision_8: 0.6402 - recall_8: 0.3425 - val_loss: 4.9487 - val_accuracy: 0.4062 - val_MSE: 0.2205 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00\n",
      "Epoch 6/80\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 4.6176 - accuracy: 0.5763 - MSE: 0.1798 - precision_8: 0.6667 - recall_8: 0.3875 - val_loss: 4.6724 - val_accuracy: 0.3984 - val_MSE: 0.2207 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00- accuracy: 0.5799 - MSE: 0.1788 - precision_8: 0.6850 - recall_8\n",
      "Epoch 7/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 4.3580 - accuracy: 0.6137 - MSE: 0.1690 - precision_8: 0.7115 - recall_8: 0.4100 - val_loss: 4.5108 - val_accuracy: 0.3984 - val_MSE: 0.2211 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00\n",
      "Epoch 8/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 4.2157 - accuracy: 0.6162 - MSE: 0.1658 - precision_8: 0.7282 - recall_8: 0.4487 - val_loss: 4.4073 - val_accuracy: 0.3984 - val_MSE: 0.2207 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00\n",
      "Epoch 9/80\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 4.0575 - accuracy: 0.6400 - MSE: 0.1602 - precision_8: 0.7252 - recall_8: 0.4850 - val_loss: 4.2465 - val_accuracy: 0.3516 - val_MSE: 0.2206 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00\n",
      "Epoch 10/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 2s 80ms/step - loss: 3.9416 - accuracy: 0.6463 - MSE: 0.1561 - precision_8: 0.7348 - recall_8: 0.5125 - val_loss: 4.1749 - val_accuracy: 0.3359 - val_MSE: 0.2222 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00\n",
      "Epoch 11/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 3.8027 - accuracy: 0.6762 - MSE: 0.1512 - precision_8: 0.7552 - recall_8: 0.5437 - val_loss: 4.0774 - val_accuracy: 0.3281 - val_MSE: 0.2223 - val_precision_8: 1.0000 - val_recall_8: 0.0078\n",
      "Epoch 12/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 3.6771 - accuracy: 0.6875 - MSE: 0.1446 - precision_8: 0.7616 - recall_8: 0.5550 - val_loss: 3.9463 - val_accuracy: 0.3750 - val_MSE: 0.2211 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00\n",
      "Epoch 13/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 3.5274 - accuracy: 0.7088 - MSE: 0.1407 - precision_8: 0.7791 - recall_8: 0.5775 - val_loss: 3.8774 - val_accuracy: 0.3594 - val_MSE: 0.2234 - val_precision_8: 0.5000 - val_recall_8: 0.0078\n",
      "Epoch 14/80\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 3.4953 - accuracy: 0.7013 - MSE: 0.1407 - precision_8: 0.7662 - recall_8: 0.5775 - val_loss: 3.8533 - val_accuracy: 0.3125 - val_MSE: 0.2254 - val_precision_8: 0.6000 - val_recall_8: 0.0234\n",
      "Epoch 15/80\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 3.4271 - accuracy: 0.7250 - MSE: 0.1341 - precision_8: 0.7844 - recall_8: 0.6050 - val_loss: 3.8050 - val_accuracy: 0.3672 - val_MSE: 0.2243 - val_precision_8: 0.5714 - val_recall_8: 0.0312\n",
      "Epoch 16/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 3.3351 - accuracy: 0.7412 - MSE: 0.1272 - precision_8: 0.8076 - recall_8: 0.6137 - val_loss: 3.7341 - val_accuracy: 0.4062 - val_MSE: 0.2218 - val_precision_8: 0.5714 - val_recall_8: 0.0625\n",
      "Epoch 17/80\n",
      "25/25 [==============================] - 2s 70ms/step - loss: 3.2512 - accuracy: 0.7362 - MSE: 0.1262 - precision_8: 0.8161 - recall_8: 0.6325 - val_loss: 3.6363 - val_accuracy: 0.3828 - val_MSE: 0.2236 - val_precision_8: 0.4500 - val_recall_8: 0.0703678 - accuracy: 0.7269 - MSE: 0.1288 - precision_8: 0.8094 - recall_8: 0.6\n",
      "Epoch 18/80\n",
      "25/25 [==============================] - 2s 81ms/step - loss: 3.1952 - accuracy: 0.7287 - MSE: 0.1262 - precision_8: 0.8109 - recall_8: 0.6325 - val_loss: 3.6385 - val_accuracy: 0.3594 - val_MSE: 0.2243 - val_precision_8: 0.4483 - val_recall_8: 0.1016\n",
      "Epoch 19/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 3.1837 - accuracy: 0.7212 - MSE: 0.1267 - precision_8: 0.8066 - recall_8: 0.6413 - val_loss: 3.6741 - val_accuracy: 0.3672 - val_MSE: 0.2307 - val_precision_8: 0.3750 - val_recall_8: 0.0938 - accuracy: 0.7188 - MSE: 0.1293 - precision_8: 0.8047 - recal\n",
      "Epoch 20/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 3.1818 - accuracy: 0.7437 - MSE: 0.1211 - precision_8: 0.8055 - recall_8: 0.6575 - val_loss: 3.7215 - val_accuracy: 0.3203 - val_MSE: 0.2350 - val_precision_8: 0.4510 - val_recall_8: 0.1797\n",
      "Epoch 21/80\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 3.1383 - accuracy: 0.7663 - MSE: 0.1136 - precision_8: 0.8412 - recall_8: 0.6888 - val_loss: 3.6827 - val_accuracy: 0.3594 - val_MSE: 0.2373 - val_precision_8: 0.4127 - val_recall_8: 0.2031\n",
      "Epoch 22/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 3.0438 - accuracy: 0.7850 - MSE: 0.1087 - precision_8: 0.8363 - recall_8: 0.6963 - val_loss: 3.6756 - val_accuracy: 0.3516 - val_MSE: 0.2528 - val_precision_8: 0.3200 - val_recall_8: 0.1875\n",
      "Epoch 23/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 3.0118 - accuracy: 0.7675 - MSE: 0.1085 - precision_8: 0.8306 - recall_8: 0.7050 - val_loss: 3.7303 - val_accuracy: 0.2969 - val_MSE: 0.2545 - val_precision_8: 0.3382 - val_recall_8: 0.1797\n",
      "Epoch 24/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 3.0162 - accuracy: 0.7750 - MSE: 0.1095 - precision_8: 0.8270 - recall_8: 0.7113 - val_loss: 3.7342 - val_accuracy: 0.3516 - val_MSE: 0.2601 - val_precision_8: 0.3375 - val_recall_8: 0.2109\n",
      "Epoch 25/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 2.9780 - accuracy: 0.7788 - MSE: 0.1081 - precision_8: 0.8266 - recall_8: 0.7212 - val_loss: 3.6814 - val_accuracy: 0.3047 - val_MSE: 0.2657 - val_precision_8: 0.2824 - val_recall_8: 0.1875\n",
      "Epoch 26/80\n",
      "25/25 [==============================] - 2s 81ms/step - loss: 2.9300 - accuracy: 0.7912 - MSE: 0.1054 - precision_8: 0.8383 - recall_8: 0.7325 - val_loss: 3.7182 - val_accuracy: 0.3516 - val_MSE: 0.2722 - val_precision_8: 0.2688 - val_recall_8: 0.1953\n",
      "Epoch 27/80\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 2.8874 - accuracy: 0.7887 - MSE: 0.1039 - precision_8: 0.8324 - recall_8: 0.7262 - val_loss: 3.7729 - val_accuracy: 0.3203 - val_MSE: 0.2828 - val_precision_8: 0.2857 - val_recall_8: 0.2188.8903 - accuracy: 0.8040 - MSE: 0.1021 - precision_8: 0.8424 - recall_8: 0.7 - ETA: 0s - loss: 2.8853 - accuracy: 0.8013 - MSE: 0.1027 - precision_8: 0.8384 - reca\n",
      "Epoch 28/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 2.9204 - accuracy: 0.7538 - MSE: 0.1118 - precision_8: 0.7997 - recall_8: 0.7088 - val_loss: 3.7802 - val_accuracy: 0.3594 - val_MSE: 0.2778 - val_precision_8: 0.3627 - val_recall_8: 0.28910 - accuracy: 0.7549 - MSE: 0.1114 - precision_8: 0.7978 - recall_8: 0 - ETA: 0s - loss: 2.9176 - accuracy: 0.7513 - MSE: 0.1122 - precision_8: 0.7985 - recall_8: 0.70\n",
      "Epoch 29/80\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 2.8845 - accuracy: 0.7862 - MSE: 0.1021 - precision_8: 0.8319 - recall_8: 0.7425 - val_loss: 3.7595 - val_accuracy: 0.3516 - val_MSE: 0.2717 - val_precision_8: 0.3800 - val_recall_8: 0.2969\n",
      "Epoch 30/80\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 2.8686 - accuracy: 0.7987 - MSE: 0.0992 - precision_8: 0.8471 - recall_8: 0.7550 - val_loss: 3.7326 - val_accuracy: 0.3906 - val_MSE: 0.2674 - val_precision_8: 0.4000 - val_recall_8: 0.2969\n",
      "Epoch 31/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 2.8303 - accuracy: 0.7975 - MSE: 0.0995 - precision_8: 0.8370 - recall_8: 0.7575 - val_loss: 3.7483 - val_accuracy: 0.3594 - val_MSE: 0.2715 - val_precision_8: 0.3750 - val_recall_8: 0.3047\n",
      "Epoch 32/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 2.8363 - accuracy: 0.8037 - MSE: 0.0974 - precision_8: 0.8416 - recall_8: 0.7638 - val_loss: 3.8314 - val_accuracy: 0.3672 - val_MSE: 0.2877 - val_precision_8: 0.3611 - val_recall_8: 0.3047\n",
      "Epoch 33/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 2.7910 - accuracy: 0.8150 - MSE: 0.0952 - precision_8: 0.8471 - recall_8: 0.7688 - val_loss: 3.8628 - val_accuracy: 0.3359 - val_MSE: 0.2969 - val_precision_8: 0.3333 - val_recall_8: 0.2969\n",
      "Epoch 34/80\n",
      "25/25 [==============================] - 2s 81ms/step - loss: 2.7712 - accuracy: 0.8037 - MSE: 0.0980 - precision_8: 0.8379 - recall_8: 0.7625 - val_loss: 3.8005 - val_accuracy: 0.3047 - val_MSE: 0.2958 - val_precision_8: 0.3364 - val_recall_8: 0.2891\n",
      "Epoch 35/80\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 2.7926 - accuracy: 0.7925 - MSE: 0.1002 - precision_8: 0.8354 - recall_8: 0.7613 - val_loss: 3.8397 - val_accuracy: 0.3125 - val_MSE: 0.3016 - val_precision_8: 0.3333 - val_recall_8: 0.2891\n",
      "Epoch 36/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 2.7572 - accuracy: 0.8150 - MSE: 0.0947 - precision_8: 0.8428 - recall_8: 0.7638 - val_loss: 3.8985 - val_accuracy: 0.3516 - val_MSE: 0.3027 - val_precision_8: 0.3652 - val_recall_8: 0.3281\n",
      "Epoch 37/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 2.7197 - accuracy: 0.8350 - MSE: 0.0873 - precision_8: 0.8609 - recall_8: 0.7738 - val_loss: 3.9187 - val_accuracy: 0.3672 - val_MSE: 0.2979 - val_precision_8: 0.3628 - val_recall_8: 0.3203\n",
      "Epoch 38/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 2s 73ms/step - loss: 2.7606 - accuracy: 0.8087 - MSE: 0.0946 - precision_8: 0.8467 - recall_8: 0.7800 - val_loss: 3.8647 - val_accuracy: 0.3906 - val_MSE: 0.2797 - val_precision_8: 0.3761 - val_recall_8: 0.32032.7606 - accuracy: 0.8087 - MSE: 0.0946 - precision_8: 0.8467 - recall_8: 0.780\n",
      "Epoch 39/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 2.7531 - accuracy: 0.8062 - MSE: 0.0924 - precision_8: 0.8565 - recall_8: 0.7613 - val_loss: 4.0253 - val_accuracy: 0.3359 - val_MSE: 0.3019 - val_precision_8: 0.3514 - val_recall_8: 0.3047\n",
      "Epoch 40/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 2.7495 - accuracy: 0.8200 - MSE: 0.0868 - precision_8: 0.8603 - recall_8: 0.7775 - val_loss: 4.0410 - val_accuracy: 0.3125 - val_MSE: 0.3132 - val_precision_8: 0.3190 - val_recall_8: 0.2891\n",
      "Epoch 41/80\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 2.7252 - accuracy: 0.8150 - MSE: 0.0903 - precision_8: 0.8532 - recall_8: 0.7775 - val_loss: 3.9069 - val_accuracy: 0.3672 - val_MSE: 0.2978 - val_precision_8: 0.3684 - val_recall_8: 0.3281\n",
      "Epoch 42/80\n",
      "25/25 [==============================] - 2s 81ms/step - loss: 2.6848 - accuracy: 0.8338 - MSE: 0.0842 - precision_8: 0.8722 - recall_8: 0.7763 - val_loss: 3.9627 - val_accuracy: 0.3828 - val_MSE: 0.2944 - val_precision_8: 0.3894 - val_recall_8: 0.3438\n",
      "Epoch 43/80\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 2.7107 - accuracy: 0.8213 - MSE: 0.0852 - precision_8: 0.8537 - recall_8: 0.7875 - val_loss: 4.0518 - val_accuracy: 0.3672 - val_MSE: 0.2991 - val_precision_8: 0.3684 - val_recall_8: 0.3281\n",
      "Epoch 44/80\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 2.7658 - accuracy: 0.8000 - MSE: 0.0924 - precision_8: 0.8363 - recall_8: 0.7663 - val_loss: 3.9937 - val_accuracy: 0.3438 - val_MSE: 0.3017 - val_precision_8: 0.3559 - val_recall_8: 0.3281\n",
      "Epoch 45/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 2.7191 - accuracy: 0.8350 - MSE: 0.0826 - precision_8: 0.8514 - recall_8: 0.7950 - val_loss: 4.0666 - val_accuracy: 0.3281 - val_MSE: 0.3108 - val_precision_8: 0.3333 - val_recall_8: 0.2891\n",
      "Epoch 46/80\n",
      "25/25 [==============================] - 2s 70ms/step - loss: 2.7056 - accuracy: 0.8175 - MSE: 0.0829 - precision_8: 0.8573 - recall_8: 0.7738 - val_loss: 3.8703 - val_accuracy: 0.3906 - val_MSE: 0.2804 - val_precision_8: 0.3894 - val_recall_8: 0.3438\n",
      "Epoch 47/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 2.7278 - accuracy: 0.8188 - MSE: 0.0867 - precision_8: 0.8548 - recall_8: 0.7800 - val_loss: 3.9103 - val_accuracy: 0.3984 - val_MSE: 0.2828 - val_precision_8: 0.4068 - val_recall_8: 0.3750\n",
      "Epoch 48/80\n",
      "25/25 [==============================] - 2s 70ms/step - loss: 2.7667 - accuracy: 0.8112 - MSE: 0.0876 - precision_8: 0.8433 - recall_8: 0.7738 - val_loss: 4.0503 - val_accuracy: 0.3438 - val_MSE: 0.3140 - val_precision_8: 0.3248 - val_recall_8: 0.2969\n",
      "Epoch 49/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 2.7287 - accuracy: 0.8400 - MSE: 0.0817 - precision_8: 0.8600 - recall_8: 0.8062 - val_loss: 4.1079 - val_accuracy: 0.3516 - val_MSE: 0.3179 - val_precision_8: 0.3534 - val_recall_8: 0.3203\n",
      "Epoch 50/80\n",
      "25/25 [==============================] - 2s 80ms/step - loss: 2.6991 - accuracy: 0.8400 - MSE: 0.0815 - precision_8: 0.8638 - recall_8: 0.8163 - val_loss: 4.0072 - val_accuracy: 0.3594 - val_MSE: 0.2962 - val_precision_8: 0.3739 - val_recall_8: 0.3359\n",
      "Epoch 51/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 2.6781 - accuracy: 0.8388 - MSE: 0.0777 - precision_8: 0.8697 - recall_8: 0.8012 - val_loss: 4.0609 - val_accuracy: 0.4297 - val_MSE: 0.2925 - val_precision_8: 0.4159 - val_recall_8: 0.3672\n",
      "Epoch 52/80\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 2.6877 - accuracy: 0.8388 - MSE: 0.0807 - precision_8: 0.8656 - recall_8: 0.8050 - val_loss: 4.0793 - val_accuracy: 0.3906 - val_MSE: 0.3068 - val_precision_8: 0.3802 - val_recall_8: 0.3594\n",
      "Epoch 53/80\n",
      "25/25 [==============================] - 2s 70ms/step - loss: 2.6908 - accuracy: 0.8413 - MSE: 0.0819 - precision_8: 0.8692 - recall_8: 0.8138 - val_loss: 3.9633 - val_accuracy: 0.4219 - val_MSE: 0.2926 - val_precision_8: 0.4118 - val_recall_8: 0.3828\n",
      "Epoch 54/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 2.6507 - accuracy: 0.8350 - MSE: 0.0813 - precision_8: 0.8541 - recall_8: 0.8050 - val_loss: 4.0837 - val_accuracy: 0.3750 - val_MSE: 0.3022 - val_precision_8: 0.3898 - val_recall_8: 0.3594\n",
      "Epoch 55/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 2.6835 - accuracy: 0.8325 - MSE: 0.0825 - precision_8: 0.8575 - recall_8: 0.8050 - val_loss: 4.1201 - val_accuracy: 0.3594 - val_MSE: 0.3117 - val_precision_8: 0.3750 - val_recall_8: 0.3516\n",
      "Epoch 56/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 2.6475 - accuracy: 0.8475 - MSE: 0.0757 - precision_8: 0.8763 - recall_8: 0.8238 - val_loss: 4.0387 - val_accuracy: 0.3750 - val_MSE: 0.3014 - val_precision_8: 0.3913 - val_recall_8: 0.3516\n",
      "Epoch 57/80\n",
      "25/25 [==============================] - 2s 70ms/step - loss: 2.6559 - accuracy: 0.8325 - MSE: 0.0805 - precision_8: 0.8556 - recall_8: 0.8150 - val_loss: 4.0082 - val_accuracy: 0.3750 - val_MSE: 0.3008 - val_precision_8: 0.3913 - val_recall_8: 0.3516\n",
      "Epoch 58/80\n",
      "25/25 [==============================] - 2s 78ms/step - loss: 2.6474 - accuracy: 0.8450 - MSE: 0.0755 - precision_8: 0.8757 - recall_8: 0.8188 - val_loss: 4.0277 - val_accuracy: 0.3828 - val_MSE: 0.2958 - val_precision_8: 0.3902 - val_recall_8: 0.3750\n",
      "Epoch 59/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 2.6767 - accuracy: 0.8313 - MSE: 0.0829 - precision_8: 0.8579 - recall_8: 0.8075 - val_loss: 3.9239 - val_accuracy: 0.3750 - val_MSE: 0.2999 - val_precision_8: 0.3717 - val_recall_8: 0.3281\n",
      "Epoch 60/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 2.6713 - accuracy: 0.8475 - MSE: 0.0802 - precision_8: 0.8692 - recall_8: 0.8225 - val_loss: 4.0212 - val_accuracy: 0.3828 - val_MSE: 0.2999 - val_precision_8: 0.3898 - val_recall_8: 0.3594\n",
      "Epoch 61/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 2.6702 - accuracy: 0.8438 - MSE: 0.0794 - precision_8: 0.8632 - recall_8: 0.8200 - val_loss: 3.9914 - val_accuracy: 0.3984 - val_MSE: 0.2902 - val_precision_8: 0.4153 - val_recall_8: 0.3828\n",
      "Epoch 62/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 2.6464 - accuracy: 0.8525 - MSE: 0.0753 - precision_8: 0.8765 - recall_8: 0.8338 - val_loss: 4.1069 - val_accuracy: 0.3672 - val_MSE: 0.3098 - val_precision_8: 0.3675 - val_recall_8: 0.3359\n",
      "Epoch 63/80\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 2.6497 - accuracy: 0.8462 - MSE: 0.0778 - precision_8: 0.8659 - recall_8: 0.8150 - val_loss: 3.9894 - val_accuracy: 0.3984 - val_MSE: 0.2886 - val_precision_8: 0.4188 - val_recall_8: 0.3828\n",
      "Epoch 64/80\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 2.6792 - accuracy: 0.8400 - MSE: 0.0777 - precision_8: 0.8670 - recall_8: 0.8150 - val_loss: 4.0750 - val_accuracy: 0.3672 - val_MSE: 0.3073 - val_precision_8: 0.3821 - val_recall_8: 0.3672\n",
      "Epoch 65/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 2.6815 - accuracy: 0.8388 - MSE: 0.0760 - precision_8: 0.8658 - recall_8: 0.8225 - val_loss: 4.0962 - val_accuracy: 0.3594 - val_MSE: 0.3101 - val_precision_8: 0.3689 - val_recall_8: 0.3516\n",
      "Epoch 66/80\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 2.6933 - accuracy: 0.8400 - MSE: 0.0762 - precision_8: 0.8648 - recall_8: 0.8075 - val_loss: 4.1672 - val_accuracy: 0.3594 - val_MSE: 0.3074 - val_precision_8: 0.3761 - val_recall_8: 0.3438\n",
      "Epoch 67/80\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 2.7501 - accuracy: 0.8562 - MSE: 0.0777 - precision_8: 0.8722 - recall_8: 0.8275 - val_loss: 4.2464 - val_accuracy: 0.3594 - val_MSE: 0.3098 - val_precision_8: 0.3629 - val_recall_8: 0.3516\n",
      "Epoch 68/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 2s 72ms/step - loss: 2.6900 - accuracy: 0.8525 - MSE: 0.0750 - precision_8: 0.8732 - recall_8: 0.8263 - val_loss: 4.1793 - val_accuracy: 0.3750 - val_MSE: 0.3088 - val_precision_8: 0.3866 - val_recall_8: 0.3594\n",
      "Epoch 69/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 2.6619 - accuracy: 0.8650 - MSE: 0.0728 - precision_8: 0.8833 - recall_8: 0.8325 - val_loss: 4.2393 - val_accuracy: 0.3672 - val_MSE: 0.3288 - val_precision_8: 0.3644 - val_recall_8: 0.3359\n",
      "Epoch 70/80\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 2.6503 - accuracy: 0.8413 - MSE: 0.0790 - precision_8: 0.8645 - recall_8: 0.8138 - val_loss: 4.2165 - val_accuracy: 0.3125 - val_MSE: 0.3182 - val_precision_8: 0.3250 - val_recall_8: 0.3047\n",
      "Epoch 71/80\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 2.6458 - accuracy: 0.8500 - MSE: 0.0761 - precision_8: 0.8627 - recall_8: 0.8250 - val_loss: 4.3015 - val_accuracy: 0.3203 - val_MSE: 0.3156 - val_precision_8: 0.3223 - val_recall_8: 0.3047\n",
      "Epoch 72/80\n",
      "25/25 [==============================] - 2s 70ms/step - loss: 2.6151 - accuracy: 0.8625 - MSE: 0.0689 - precision_8: 0.8801 - recall_8: 0.8350 - val_loss: 4.2705 - val_accuracy: 0.3672 - val_MSE: 0.3140 - val_precision_8: 0.3719 - val_recall_8: 0.3516\n",
      "Epoch 73/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 2.6150 - accuracy: 0.8600 - MSE: 0.0707 - precision_8: 0.8745 - recall_8: 0.8363 - val_loss: 4.2417 - val_accuracy: 0.3828 - val_MSE: 0.3226 - val_precision_8: 0.3902 - val_recall_8: 0.3750 - accuracy: 0.8521 - MSE: 0.0742 - precision_8: 0.8668 - recall_8:  - ETA: 0s - loss: 2.5960 - accuracy: 0.8661 - MSE: 0.0678 - precision_8: 0.8806 - recall_8: 0\n",
      "Epoch 74/80\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 2.6173 - accuracy: 0.8462 - MSE: 0.0742 - precision_8: 0.8710 - recall_8: 0.8188 - val_loss: 4.3120 - val_accuracy: 0.3594 - val_MSE: 0.3245 - val_precision_8: 0.3636 - val_recall_8: 0.3438\n",
      "Epoch 75/80\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 2.6672 - accuracy: 0.8363 - MSE: 0.0813 - precision_8: 0.8596 - recall_8: 0.8037 - val_loss: 4.2796 - val_accuracy: 0.3438 - val_MSE: 0.3198 - val_precision_8: 0.3451 - val_recall_8: 0.3047\n",
      "Epoch 76/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 2.6753 - accuracy: 0.8413 - MSE: 0.0789 - precision_8: 0.8547 - recall_8: 0.8238 - val_loss: 4.0561 - val_accuracy: 0.3828 - val_MSE: 0.2970 - val_precision_8: 0.3966 - val_recall_8: 0.3594\n",
      "Epoch 77/80\n",
      "25/25 [==============================] - 2s 70ms/step - loss: 2.6681 - accuracy: 0.8225 - MSE: 0.0838 - precision_8: 0.8386 - recall_8: 0.7987 - val_loss: 4.2449 - val_accuracy: 0.4219 - val_MSE: 0.2926 - val_precision_8: 0.4274 - val_recall_8: 0.3906\n",
      "Epoch 78/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 2.6643 - accuracy: 0.8450 - MSE: 0.0776 - precision_8: 0.8581 - recall_8: 0.8163 - val_loss: 4.3683 - val_accuracy: 0.3594 - val_MSE: 0.3215 - val_precision_8: 0.3750 - val_recall_8: 0.3516\n",
      "Epoch 79/80\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 2.7219 - accuracy: 0.8213 - MSE: 0.0848 - precision_8: 0.8397 - recall_8: 0.7987 - val_loss: 4.3183 - val_accuracy: 0.3281 - val_MSE: 0.3164 - val_precision_8: 0.3443 - val_recall_8: 0.3281\n",
      "Epoch 80/80\n",
      "25/25 [==============================] - 2s 73ms/step - loss: 2.6561 - accuracy: 0.8388 - MSE: 0.0793 - precision_8: 0.8653 - recall_8: 0.8112 - val_loss: 4.1185 - val_accuracy: 0.4062 - val_MSE: 0.2946 - val_precision_8: 0.4138 - val_recall_8: 0.3750\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (256, 4)                  96096     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (256, 4)                  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (256, 4)                  16        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (256, 3)                  15        \n",
      "=================================================================\n",
      "Total params: 96,127\n",
      "Trainable params: 96,119\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Starting: \n",
      "{'batch_size': 256, 'epochs': 70, 'learning_rate': 0.001, 'optimizer': 'sgd'}\n",
      "---------------------------------------------------------------------------------\n",
      "{   'activation': 'sigmoid',\n",
      "    'dropout_rate': 0.4,\n",
      "    'filters': 9,\n",
      "    'kernel_size': 3,\n",
      "    'l1_r': 0.0001,\n",
      "    'l2_r': 0.2,\n",
      "    'output_layer_activation': 'softmax',\n",
      "    'padding': 'same',\n",
      "    'start_neurons': 4}\n",
      "oof\n",
      "Epoch 1/70\n",
      "2/3 [===================>..........] - ETA: 1s - loss: 9.0001 - accuracy: 0.3242 - MSE: 0.2988 - precision_9: 0.3211 - recall_9: 0.2402WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.3708s vs `on_train_batch_end` time: 1.8584s). Check your callbacks.\n",
      "3/3 [==============================] - 4s 1s/step - loss: 8.9480 - accuracy: 0.3398 - MSE: 0.2926 - precision_9: 0.3379 - recall_9: 0.2578 - val_loss: 8.5897 - val_accuracy: 0.3828 - val_MSE: 0.2527 - val_precision_9: 0.4053 - val_recall_9: 0.3008\n",
      "Epoch 2/70\n",
      "3/3 [==============================] - 2s 556ms/step - loss: 8.8548 - accuracy: 0.3581 - MSE: 0.2789 - precision_9: 0.3759 - recall_9: 0.2839 - val_loss: 8.5675 - val_accuracy: 0.3789 - val_MSE: 0.2518 - val_precision_9: 0.4053 - val_recall_9: 0.3008\n",
      "Epoch 3/70\n",
      "3/3 [==============================] - 2s 551ms/step - loss: 8.8442 - accuracy: 0.3620 - MSE: 0.2798 - precision_9: 0.3831 - recall_9: 0.2773 - val_loss: 8.5489 - val_accuracy: 0.3789 - val_MSE: 0.2519 - val_precision_9: 0.4032 - val_recall_9: 0.2930\n",
      "Epoch 4/70\n",
      "3/3 [==============================] - 2s 558ms/step - loss: 8.8183 - accuracy: 0.3568 - MSE: 0.2798 - precision_9: 0.3872 - recall_9: 0.2839 - val_loss: 8.5314 - val_accuracy: 0.3789 - val_MSE: 0.2517 - val_precision_9: 0.4032 - val_recall_9: 0.2930\n",
      "Epoch 5/70\n",
      "3/3 [==============================] - 2s 550ms/step - loss: 8.7875 - accuracy: 0.3750 - MSE: 0.2764 - precision_9: 0.3763 - recall_9: 0.2812 - val_loss: 8.5102 - val_accuracy: 0.3867 - val_MSE: 0.2511 - val_precision_9: 0.4054 - val_recall_9: 0.2930\n",
      "Epoch 6/70\n",
      "3/3 [==============================] - 2s 663ms/step - loss: 8.7081 - accuracy: 0.3893 - MSE: 0.2668 - precision_9: 0.3930 - recall_9: 0.2917 - val_loss: 8.4900 - val_accuracy: 0.3906 - val_MSE: 0.2506 - val_precision_9: 0.4044 - val_recall_9: 0.2891\n",
      "Epoch 7/70\n",
      "3/3 [==============================] - 2s 567ms/step - loss: 8.6866 - accuracy: 0.3854 - MSE: 0.2719 - precision_9: 0.3739 - recall_9: 0.2878 - val_loss: 8.4676 - val_accuracy: 0.3828 - val_MSE: 0.2497 - val_precision_9: 0.4033 - val_recall_9: 0.2852\n",
      "Epoch 8/70\n",
      "3/3 [==============================] - 2s 552ms/step - loss: 8.6691 - accuracy: 0.3932 - MSE: 0.2657 - precision_9: 0.4129 - recall_9: 0.3242 - val_loss: 8.4478 - val_accuracy: 0.3750 - val_MSE: 0.2492 - val_precision_9: 0.4167 - val_recall_9: 0.2734\n",
      "Epoch 9/70\n",
      "3/3 [==============================] - 2s 557ms/step - loss: 8.6738 - accuracy: 0.3516 - MSE: 0.2730 - precision_9: 0.3721 - recall_9: 0.2878 - val_loss: 8.4281 - val_accuracy: 0.3672 - val_MSE: 0.2488 - val_precision_9: 0.4242 - val_recall_9: 0.2734\n",
      "Epoch 10/70\n",
      "3/3 [==============================] - 2s 559ms/step - loss: 8.6406 - accuracy: 0.3620 - MSE: 0.2746 - precision_9: 0.3851 - recall_9: 0.3034 - val_loss: 8.4093 - val_accuracy: 0.3633 - val_MSE: 0.2484 - val_precision_9: 0.4242 - val_recall_9: 0.2734\n",
      "Epoch 11/70\n",
      "3/3 [==============================] - 2s 550ms/step - loss: 8.6085 - accuracy: 0.4062 - MSE: 0.2650 - precision_9: 0.4115 - recall_9: 0.3086 - val_loss: 8.3898 - val_accuracy: 0.3594 - val_MSE: 0.2480 - val_precision_9: 0.4198 - val_recall_9: 0.2656\n",
      "Epoch 12/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 545ms/step - loss: 8.6268 - accuracy: 0.3659 - MSE: 0.2743 - precision_9: 0.3904 - recall_9: 0.3086 - val_loss: 8.3703 - val_accuracy: 0.3711 - val_MSE: 0.2476 - val_precision_9: 0.4214 - val_recall_9: 0.2617\n",
      "Epoch 13/70\n",
      "3/3 [==============================] - 2s 558ms/step - loss: 8.6088 - accuracy: 0.3815 - MSE: 0.2709 - precision_9: 0.3874 - recall_9: 0.2956 - val_loss: 8.3519 - val_accuracy: 0.3711 - val_MSE: 0.2473 - val_precision_9: 0.4231 - val_recall_9: 0.2578\n",
      "Epoch 14/70\n",
      "3/3 [==============================] - 2s 606ms/step - loss: 8.5500 - accuracy: 0.3685 - MSE: 0.2660 - precision_9: 0.3911 - recall_9: 0.2852 - val_loss: 8.3334 - val_accuracy: 0.3711 - val_MSE: 0.2472 - val_precision_9: 0.4167 - val_recall_9: 0.2539\n",
      "Epoch 15/70\n",
      "3/3 [==============================] - 2s 567ms/step - loss: 8.5054 - accuracy: 0.4115 - MSE: 0.2601 - precision_9: 0.4271 - recall_9: 0.3320 - val_loss: 8.3150 - val_accuracy: 0.3711 - val_MSE: 0.2470 - val_precision_9: 0.4129 - val_recall_9: 0.2500\n",
      "Epoch 16/70\n",
      "3/3 [==============================] - 2s 548ms/step - loss: 8.5550 - accuracy: 0.3763 - MSE: 0.2720 - precision_9: 0.3917 - recall_9: 0.3060 - val_loss: 8.2964 - val_accuracy: 0.3711 - val_MSE: 0.2466 - val_precision_9: 0.4097 - val_recall_9: 0.2305\n",
      "Epoch 17/70\n",
      "3/3 [==============================] - 2s 559ms/step - loss: 8.5045 - accuracy: 0.3932 - MSE: 0.2637 - precision_9: 0.4135 - recall_9: 0.3112 - val_loss: 8.2784 - val_accuracy: 0.3711 - val_MSE: 0.2464 - val_precision_9: 0.4126 - val_recall_9: 0.2305\n",
      "Epoch 18/70\n",
      "3/3 [==============================] - 2s 550ms/step - loss: 8.4808 - accuracy: 0.3932 - MSE: 0.2644 - precision_9: 0.4145 - recall_9: 0.3125 - val_loss: 8.2604 - val_accuracy: 0.3711 - val_MSE: 0.2463 - val_precision_9: 0.4126 - val_recall_9: 0.2305\n",
      "Epoch 19/70\n",
      "3/3 [==============================] - 2s 544ms/step - loss: 8.4800 - accuracy: 0.4271 - MSE: 0.2631 - precision_9: 0.4253 - recall_9: 0.3190 - val_loss: 8.2425 - val_accuracy: 0.3711 - val_MSE: 0.2461 - val_precision_9: 0.4043 - val_recall_9: 0.2227\n",
      "Epoch 20/70\n",
      "3/3 [==============================] - 2s 566ms/step - loss: 8.4134 - accuracy: 0.3867 - MSE: 0.2627 - precision_9: 0.4057 - recall_9: 0.3138 - val_loss: 8.2275 - val_accuracy: 0.3672 - val_MSE: 0.2464 - val_precision_9: 0.4000 - val_recall_9: 0.2188\n",
      "Epoch 21/70\n",
      "3/3 [==============================] - 2s 550ms/step - loss: 8.4366 - accuracy: 0.3854 - MSE: 0.2650 - precision_9: 0.4103 - recall_9: 0.3099 - val_loss: 8.2118 - val_accuracy: 0.3711 - val_MSE: 0.2467 - val_precision_9: 0.4044 - val_recall_9: 0.2148\n",
      "Epoch 22/70\n",
      "3/3 [==============================] - 2s 548ms/step - loss: 8.4565 - accuracy: 0.3672 - MSE: 0.2738 - precision_9: 0.3809 - recall_9: 0.2956 - val_loss: 8.1947 - val_accuracy: 0.3750 - val_MSE: 0.2467 - val_precision_9: 0.3955 - val_recall_9: 0.2070\n",
      "Epoch 23/70\n",
      "3/3 [==============================] - 2s 636ms/step - loss: 8.3752 - accuracy: 0.3971 - MSE: 0.2610 - precision_9: 0.4202 - recall_9: 0.3190 - val_loss: 8.1773 - val_accuracy: 0.3750 - val_MSE: 0.2466 - val_precision_9: 0.3929 - val_recall_9: 0.2148\n",
      "Epoch 24/70\n",
      "3/3 [==============================] - 2s 541ms/step - loss: 8.3863 - accuracy: 0.3828 - MSE: 0.2692 - precision_9: 0.3788 - recall_9: 0.2891 - val_loss: 8.1601 - val_accuracy: 0.3711 - val_MSE: 0.2465 - val_precision_9: 0.3857 - val_recall_9: 0.2109\n",
      "Epoch 25/70\n",
      "3/3 [==============================] - 2s 541ms/step - loss: 8.3544 - accuracy: 0.3880 - MSE: 0.2637 - precision_9: 0.4189 - recall_9: 0.3229 - val_loss: 8.1433 - val_accuracy: 0.3711 - val_MSE: 0.2465 - val_precision_9: 0.3869 - val_recall_9: 0.2070\n",
      "Epoch 26/70\n",
      "3/3 [==============================] - 2s 555ms/step - loss: 8.3486 - accuracy: 0.3932 - MSE: 0.2657 - precision_9: 0.4082 - recall_9: 0.3099 - val_loss: 8.1263 - val_accuracy: 0.3711 - val_MSE: 0.2464 - val_precision_9: 0.3869 - val_recall_9: 0.2070\n",
      "Epoch 27/70\n",
      "3/3 [==============================] - 2s 550ms/step - loss: 8.3196 - accuracy: 0.4167 - MSE: 0.2618 - precision_9: 0.4088 - recall_9: 0.3151 - val_loss: 8.1100 - val_accuracy: 0.3750 - val_MSE: 0.2464 - val_precision_9: 0.3824 - val_recall_9: 0.2031\n",
      "Epoch 28/70\n",
      "3/3 [==============================] - 2s 547ms/step - loss: 8.2717 - accuracy: 0.4049 - MSE: 0.2619 - precision_9: 0.4113 - recall_9: 0.3320 - val_loss: 8.0920 - val_accuracy: 0.3789 - val_MSE: 0.2461 - val_precision_9: 0.3910 - val_recall_9: 0.2031\n",
      "Epoch 29/70\n",
      "3/3 [==============================] - 2s 558ms/step - loss: 8.3440 - accuracy: 0.3555 - MSE: 0.2734 - precision_9: 0.3774 - recall_9: 0.2826 - val_loss: 8.0753 - val_accuracy: 0.3750 - val_MSE: 0.2461 - val_precision_9: 0.3910 - val_recall_9: 0.2031\n",
      "Epoch 30/70\n",
      "3/3 [==============================] - 2s 551ms/step - loss: 8.2635 - accuracy: 0.3828 - MSE: 0.2667 - precision_9: 0.3976 - recall_9: 0.3060 - val_loss: 8.0599 - val_accuracy: 0.3750 - val_MSE: 0.2463 - val_precision_9: 0.3798 - val_recall_9: 0.1914\n",
      "Epoch 31/70\n",
      "3/3 [==============================] - 2s 544ms/step - loss: 8.2346 - accuracy: 0.3984 - MSE: 0.2619 - precision_9: 0.4143 - recall_9: 0.3177 - val_loss: 8.0438 - val_accuracy: 0.3750 - val_MSE: 0.2464 - val_precision_9: 0.3701 - val_recall_9: 0.1836\n",
      "Epoch 32/70\n",
      "3/3 [==============================] - 2s 639ms/step - loss: 8.2550 - accuracy: 0.3958 - MSE: 0.2658 - precision_9: 0.4055 - recall_9: 0.3047 - val_loss: 8.0276 - val_accuracy: 0.3750 - val_MSE: 0.2465 - val_precision_9: 0.3750 - val_recall_9: 0.1875\n",
      "Epoch 33/70\n",
      "3/3 [==============================] - 2s 547ms/step - loss: 8.1942 - accuracy: 0.4076 - MSE: 0.2574 - precision_9: 0.4252 - recall_9: 0.3333 - val_loss: 8.0124 - val_accuracy: 0.3672 - val_MSE: 0.2467 - val_precision_9: 0.3750 - val_recall_9: 0.1875\n",
      "Epoch 34/70\n",
      "3/3 [==============================] - 2s 545ms/step - loss: 8.1776 - accuracy: 0.4036 - MSE: 0.2613 - precision_9: 0.4218 - recall_9: 0.3229 - val_loss: 7.9965 - val_accuracy: 0.3633 - val_MSE: 0.2468 - val_precision_9: 0.3497 - val_recall_9: 0.1953\n",
      "Epoch 35/70\n",
      "3/3 [==============================] - 2s 545ms/step - loss: 8.1773 - accuracy: 0.4141 - MSE: 0.2653 - precision_9: 0.4120 - recall_9: 0.3047 - val_loss: 7.9809 - val_accuracy: 0.3711 - val_MSE: 0.2469 - val_precision_9: 0.3497 - val_recall_9: 0.1953\n",
      "Epoch 36/70\n",
      "3/3 [==============================] - 2s 551ms/step - loss: 8.1356 - accuracy: 0.3828 - MSE: 0.2612 - precision_9: 0.3982 - recall_9: 0.2852 - val_loss: 7.9652 - val_accuracy: 0.3711 - val_MSE: 0.2471 - val_precision_9: 0.3497 - val_recall_9: 0.1953\n",
      "Epoch 37/70\n",
      "3/3 [==============================] - 2s 559ms/step - loss: 8.1166 - accuracy: 0.4076 - MSE: 0.2593 - precision_9: 0.4240 - recall_9: 0.3307 - val_loss: 7.9502 - val_accuracy: 0.3711 - val_MSE: 0.2473 - val_precision_9: 0.3475 - val_recall_9: 0.1914\n",
      "Epoch 38/70\n",
      "3/3 [==============================] - 2s 547ms/step - loss: 8.1105 - accuracy: 0.3997 - MSE: 0.2625 - precision_9: 0.4072 - recall_9: 0.3086 - val_loss: 7.9340 - val_accuracy: 0.3711 - val_MSE: 0.2474 - val_precision_9: 0.3525 - val_recall_9: 0.1914\n",
      "Epoch 39/70\n",
      "3/3 [==============================] - 2s 550ms/step - loss: 8.0916 - accuracy: 0.4128 - MSE: 0.2603 - precision_9: 0.4157 - recall_9: 0.3242 - val_loss: 7.9187 - val_accuracy: 0.3633 - val_MSE: 0.2475 - val_precision_9: 0.3525 - val_recall_9: 0.1914\n",
      "Epoch 40/70\n",
      "3/3 [==============================] - 2s 548ms/step - loss: 8.1069 - accuracy: 0.3906 - MSE: 0.2666 - precision_9: 0.3997 - recall_9: 0.3060 - val_loss: 7.9035 - val_accuracy: 0.3594 - val_MSE: 0.2477 - val_precision_9: 0.3525 - val_recall_9: 0.1914\n",
      "Epoch 41/70\n",
      "3/3 [==============================] - 2s 642ms/step - loss: 8.1042 - accuracy: 0.4115 - MSE: 0.2651 - precision_9: 0.4112 - recall_9: 0.3164 - val_loss: 7.8878 - val_accuracy: 0.3594 - val_MSE: 0.2478 - val_precision_9: 0.3577 - val_recall_9: 0.1914\n",
      "Epoch 42/70\n",
      "3/3 [==============================] - 2s 550ms/step - loss: 7.9985 - accuracy: 0.4102 - MSE: 0.2528 - precision_9: 0.4143 - recall_9: 0.3086 - val_loss: 7.8729 - val_accuracy: 0.3594 - val_MSE: 0.2480 - val_precision_9: 0.3529 - val_recall_9: 0.1875\n",
      "Epoch 43/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 551ms/step - loss: 8.0096 - accuracy: 0.4193 - MSE: 0.2559 - precision_9: 0.4338 - recall_9: 0.3242 - val_loss: 7.8575 - val_accuracy: 0.3594 - val_MSE: 0.2482 - val_precision_9: 0.3561 - val_recall_9: 0.1836\n",
      "Epoch 44/70\n",
      "3/3 [==============================] - 2s 552ms/step - loss: 8.0353 - accuracy: 0.3893 - MSE: 0.2660 - precision_9: 0.3842 - recall_9: 0.2917 - val_loss: 7.8423 - val_accuracy: 0.3594 - val_MSE: 0.2484 - val_precision_9: 0.3561 - val_recall_9: 0.1836\n",
      "Epoch 45/70\n",
      "3/3 [==============================] - 2s 544ms/step - loss: 7.9997 - accuracy: 0.3854 - MSE: 0.2613 - precision_9: 0.4083 - recall_9: 0.3216 - val_loss: 7.8281 - val_accuracy: 0.3594 - val_MSE: 0.2487 - val_precision_9: 0.3609 - val_recall_9: 0.1875\n",
      "Epoch 46/70\n",
      "3/3 [==============================] - 2s 549ms/step - loss: 7.9480 - accuracy: 0.4089 - MSE: 0.2539 - precision_9: 0.4327 - recall_9: 0.3346 - val_loss: 7.8128 - val_accuracy: 0.3594 - val_MSE: 0.2489 - val_precision_9: 0.3582 - val_recall_9: 0.1875\n",
      "Epoch 47/70\n",
      "3/3 [==============================] - 2s 559ms/step - loss: 7.9593 - accuracy: 0.4154 - MSE: 0.2592 - precision_9: 0.4190 - recall_9: 0.3164 - val_loss: 7.7979 - val_accuracy: 0.3555 - val_MSE: 0.2490 - val_precision_9: 0.3582 - val_recall_9: 0.1875\n",
      "Epoch 48/70\n",
      "3/3 [==============================] - 2s 542ms/step - loss: 8.0125 - accuracy: 0.3594 - MSE: 0.2728 - precision_9: 0.3642 - recall_9: 0.2865 - val_loss: 7.7830 - val_accuracy: 0.3516 - val_MSE: 0.2492 - val_precision_9: 0.3534 - val_recall_9: 0.1836\n",
      "Epoch 49/70\n",
      "3/3 [==============================] - 2s 546ms/step - loss: 7.9462 - accuracy: 0.3919 - MSE: 0.2644 - precision_9: 0.4134 - recall_9: 0.3203 - val_loss: 7.7682 - val_accuracy: 0.3516 - val_MSE: 0.2494 - val_precision_9: 0.3385 - val_recall_9: 0.1719\n",
      "Epoch 50/70\n",
      "3/3 [==============================] - 2s 633ms/step - loss: 7.9397 - accuracy: 0.3880 - MSE: 0.2646 - precision_9: 0.4034 - recall_9: 0.3073 - val_loss: 7.7536 - val_accuracy: 0.3516 - val_MSE: 0.2496 - val_precision_9: 0.3385 - val_recall_9: 0.1719\n",
      "Epoch 51/70\n",
      "3/3 [==============================] - 2s 558ms/step - loss: 7.8910 - accuracy: 0.4206 - MSE: 0.2566 - precision_9: 0.4245 - recall_9: 0.3294 - val_loss: 7.7386 - val_accuracy: 0.3477 - val_MSE: 0.2498 - val_precision_9: 0.3411 - val_recall_9: 0.1719\n",
      "Epoch 52/70\n",
      "3/3 [==============================] - 2s 553ms/step - loss: 7.9124 - accuracy: 0.3958 - MSE: 0.2658 - precision_9: 0.4003 - recall_9: 0.3086 - val_loss: 7.7239 - val_accuracy: 0.3477 - val_MSE: 0.2499 - val_precision_9: 0.3411 - val_recall_9: 0.1719\n",
      "Epoch 53/70\n",
      "3/3 [==============================] - 2s 545ms/step - loss: 7.8472 - accuracy: 0.4062 - MSE: 0.2578 - precision_9: 0.4269 - recall_9: 0.3229 - val_loss: 7.7090 - val_accuracy: 0.3477 - val_MSE: 0.2501 - val_precision_9: 0.3386 - val_recall_9: 0.1680\n",
      "Epoch 54/70\n",
      "3/3 [==============================] - 2s 555ms/step - loss: 7.8715 - accuracy: 0.3971 - MSE: 0.2620 - precision_9: 0.4024 - recall_9: 0.3034 - val_loss: 7.6946 - val_accuracy: 0.3477 - val_MSE: 0.2503 - val_precision_9: 0.3438 - val_recall_9: 0.1719\n",
      "Epoch 55/70\n",
      "3/3 [==============================] - 2s 558ms/step - loss: 7.7970 - accuracy: 0.4349 - MSE: 0.2508 - precision_9: 0.4523 - recall_9: 0.3398 - val_loss: 7.6810 - val_accuracy: 0.3477 - val_MSE: 0.2507 - val_precision_9: 0.3333 - val_recall_9: 0.1641\n",
      "Epoch 56/70\n",
      "3/3 [==============================] - 2s 548ms/step - loss: 7.8175 - accuracy: 0.3776 - MSE: 0.2633 - precision_9: 0.4007 - recall_9: 0.3047 - val_loss: 7.6667 - val_accuracy: 0.3438 - val_MSE: 0.2509 - val_precision_9: 0.3360 - val_recall_9: 0.1641\n",
      "Epoch 57/70\n",
      "3/3 [==============================] - 2s 552ms/step - loss: 7.7740 - accuracy: 0.3906 - MSE: 0.2564 - precision_9: 0.4266 - recall_9: 0.3255 - val_loss: 7.6527 - val_accuracy: 0.3477 - val_MSE: 0.2512 - val_precision_9: 0.3360 - val_recall_9: 0.1641\n",
      "Epoch 58/70\n",
      "3/3 [==============================] - 2s 607ms/step - loss: 7.8501 - accuracy: 0.3750 - MSE: 0.2706 - precision_9: 0.3938 - recall_9: 0.2995 - val_loss: 7.6385 - val_accuracy: 0.3477 - val_MSE: 0.2514 - val_precision_9: 0.3443 - val_recall_9: 0.1641\n",
      "Epoch 59/70\n",
      "3/3 [==============================] - 2s 567ms/step - loss: 7.6925 - accuracy: 0.4414 - MSE: 0.2442 - precision_9: 0.4544 - recall_9: 0.3503 - val_loss: 7.6242 - val_accuracy: 0.3477 - val_MSE: 0.2516 - val_precision_9: 0.3471 - val_recall_9: 0.1641\n",
      "Epoch 60/70\n",
      "3/3 [==============================] - 2s 552ms/step - loss: 7.7376 - accuracy: 0.3932 - MSE: 0.2622 - precision_9: 0.3894 - recall_9: 0.3047 - val_loss: 7.6103 - val_accuracy: 0.3477 - val_MSE: 0.2518 - val_precision_9: 0.3529 - val_recall_9: 0.1641\n",
      "Epoch 61/70\n",
      "3/3 [==============================] - 2s 549ms/step - loss: 7.7845 - accuracy: 0.3815 - MSE: 0.2676 - precision_9: 0.3898 - recall_9: 0.3086 - val_loss: 7.5962 - val_accuracy: 0.3477 - val_MSE: 0.2521 - val_precision_9: 0.3475 - val_recall_9: 0.1602\n",
      "Epoch 62/70\n",
      "3/3 [==============================] - 2s 545ms/step - loss: 7.7174 - accuracy: 0.4036 - MSE: 0.2585 - precision_9: 0.4201 - recall_9: 0.3151 - val_loss: 7.5831 - val_accuracy: 0.3516 - val_MSE: 0.2524 - val_precision_9: 0.3305 - val_recall_9: 0.1523\n",
      "Epoch 63/70\n",
      "3/3 [==============================] - 2s 552ms/step - loss: 7.6538 - accuracy: 0.4193 - MSE: 0.2514 - precision_9: 0.4229 - recall_9: 0.3320 - val_loss: 7.5693 - val_accuracy: 0.3516 - val_MSE: 0.2526 - val_precision_9: 0.3305 - val_recall_9: 0.1523\n",
      "Epoch 64/70\n",
      "3/3 [==============================] - 2s 545ms/step - loss: 7.7285 - accuracy: 0.3685 - MSE: 0.2689 - precision_9: 0.3746 - recall_9: 0.2956 - val_loss: 7.5552 - val_accuracy: 0.3398 - val_MSE: 0.2529 - val_precision_9: 0.3276 - val_recall_9: 0.1484\n",
      "Epoch 65/70\n",
      "3/3 [==============================] - 2s 545ms/step - loss: 7.6594 - accuracy: 0.4115 - MSE: 0.2561 - precision_9: 0.4309 - recall_9: 0.3372 - val_loss: 7.5411 - val_accuracy: 0.3398 - val_MSE: 0.2531 - val_precision_9: 0.3109 - val_recall_9: 0.1445\n",
      "Epoch 66/70\n",
      "3/3 [==============================] - 2s 547ms/step - loss: 7.6833 - accuracy: 0.3867 - MSE: 0.2628 - precision_9: 0.4098 - recall_9: 0.3164 - val_loss: 7.5272 - val_accuracy: 0.3398 - val_MSE: 0.2533 - val_precision_9: 0.3025 - val_recall_9: 0.1406\n",
      "Epoch 67/70\n",
      "3/3 [==============================] - 2s 639ms/step - loss: 7.5404 - accuracy: 0.4401 - MSE: 0.2418 - precision_9: 0.4614 - recall_9: 0.3503 - val_loss: 7.5133 - val_accuracy: 0.3359 - val_MSE: 0.2535 - val_precision_9: 0.3083 - val_recall_9: 0.1445\n",
      "Epoch 68/70\n",
      "3/3 [==============================] - 2s 545ms/step - loss: 7.6278 - accuracy: 0.4023 - MSE: 0.2585 - precision_9: 0.4295 - recall_9: 0.3294 - val_loss: 7.4992 - val_accuracy: 0.3359 - val_MSE: 0.2537 - val_precision_9: 0.3058 - val_recall_9: 0.1445\n",
      "Epoch 69/70\n",
      "3/3 [==============================] - 2s 559ms/step - loss: 7.6481 - accuracy: 0.3815 - MSE: 0.2636 - precision_9: 0.4025 - recall_9: 0.2982 - val_loss: 7.4851 - val_accuracy: 0.3320 - val_MSE: 0.2538 - val_precision_9: 0.3033 - val_recall_9: 0.1445\n",
      "Epoch 70/70\n",
      "3/3 [==============================] - 2s 546ms/step - loss: 7.5724 - accuracy: 0.4128 - MSE: 0.2566 - precision_9: 0.4171 - recall_9: 0.3177 - val_loss: 7.4712 - val_accuracy: 0.3320 - val_MSE: 0.2540 - val_precision_9: 0.3145 - val_recall_9: 0.1523\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_10 (LSTM)               (64, 2)                   48032     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (64, 2)                   0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (64, 2)                   8         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (64, 3)                   9         \n",
      "=================================================================\n",
      "Total params: 48,049\n",
      "Trainable params: 48,045\n",
      "Non-trainable params: 4\n",
      "_________________________________________________________________\n",
      "Starting: \n",
      "{'batch_size': 64, 'epochs': 75, 'learning_rate': 0.1, 'optimizer': 'adam'}\n",
      "---------------------------------------------------------------------------------\n",
      "{   'activation': 'softmax',\n",
      "    'dropout_rate': 0.3,\n",
      "    'filters': 15,\n",
      "    'kernel_size': 3,\n",
      "    'l1_r': 0.01,\n",
      "    'l2_r': 0.001,\n",
      "    'output_layer_activation': 'softmax',\n",
      "    'padding': 'valid',\n",
      "    'start_neurons': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      " 2/12 [====>.........................] - ETA: 9s - loss: 28.2358 - accuracy: 0.3125 - MSE: 0.2506 - precision_10: 0.3607 - recall_10: 0.1719WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0917s vs `on_train_batch_end` time: 1.8903s). Check your callbacks.\n",
      "12/12 [==============================] - 4s 342ms/step - loss: 46.4928 - accuracy: 0.3281 - MSE: 0.2292 - precision_10: 0.3737 - recall_10: 0.0482 - val_loss: 35.1015 - val_accuracy: 0.2344 - val_MSE: 0.2278 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 2/75\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 27.4644 - accuracy: 0.3177 - MSE: 0.2247 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 19.2490 - val_accuracy: 0.2344 - val_MSE: 0.2291 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00 accuracy: 0.3177 - MSE: 0.2247 - precision_10: 0.0000e+00 - recall_10: 0.0000e+\n",
      "Epoch 3/75\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 15.9442 - accuracy: 0.3294 - MSE: 0.2240 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 11.9631 - val_accuracy: 0.2344 - val_MSE: 0.2239 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 4/75\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 10.1866 - accuracy: 0.3034 - MSE: 0.2235 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 9.8476 - val_accuracy: 0.2656 - val_MSE: 0.2235 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 5/75\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 8.8654 - accuracy: 0.2943 - MSE: 0.2231 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 8.1518 - val_accuracy: 0.2656 - val_MSE: 0.2231 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 6/75\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 7.5163 - accuracy: 0.3073 - MSE: 0.2232 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 7.9773 - val_accuracy: 0.2812 - val_MSE: 0.2230 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 7/75\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 8.4358 - accuracy: 0.3034 - MSE: 0.2237 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 7.7040 - val_accuracy: 0.3594 - val_MSE: 0.2224 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 8/75\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 7.4597 - accuracy: 0.3008 - MSE: 0.2234 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 7.6003 - val_accuracy: 0.3594 - val_MSE: 0.2220 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 9/75\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 7.1800 - accuracy: 0.3138 - MSE: 0.2230 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 6.7548 - val_accuracy: 0.3594 - val_MSE: 0.2219 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 10/75\n",
      "12/12 [==============================] - 1s 118ms/step - loss: 6.7846 - accuracy: 0.3203 - MSE: 0.2228 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 6.8921 - val_accuracy: 0.3594 - val_MSE: 0.2218 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 11/75\n",
      "12/12 [==============================] - 2s 138ms/step - loss: 7.0761 - accuracy: 0.3242 - MSE: 0.2228 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 7.7298 - val_accuracy: 0.4062 - val_MSE: 0.2221 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 12/75\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 7.9082 - accuracy: 0.2839 - MSE: 0.2235 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 7.5546 - val_accuracy: 0.2344 - val_MSE: 0.2231 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 13/75\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 7.3196 - accuracy: 0.3190 - MSE: 0.2227 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 7.6109 - val_accuracy: 0.2344 - val_MSE: 0.2245 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 14/75\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 7.2462 - accuracy: 0.3125 - MSE: 0.2230 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 6.9460 - val_accuracy: 0.2344 - val_MSE: 0.2242 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 15/75\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 17.5078 - accuracy: 0.3125 - MSE: 0.2228 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 26.5799 - val_accuracy: 0.2344 - val_MSE: 0.2243 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 16/75\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 23.2693 - accuracy: 0.3099 - MSE: 0.2229 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 17.8268 - val_accuracy: 0.2344 - val_MSE: 0.2241 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 17/75\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 14.0352 - accuracy: 0.3073 - MSE: 0.2230 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 10.5629 - val_accuracy: 0.2344 - val_MSE: 0.2235 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 18/75\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 9.1432 - accuracy: 0.3086 - MSE: 0.2229 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 7.8713 - val_accuracy: 0.2344 - val_MSE: 0.2232 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 19/75\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 7.3033 - accuracy: 0.3047 - MSE: 0.2229 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 6.8024 - val_accuracy: 0.2344 - val_MSE: 0.2228 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 20/75\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 6.7047 - accuracy: 0.3099 - MSE: 0.2230 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 6.7102 - val_accuracy: 0.3594 - val_MSE: 0.2222 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 21/75\n",
      "12/12 [==============================] - 2s 134ms/step - loss: 6.6760 - accuracy: 0.3151 - MSE: 0.2228 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 6.5742 - val_accuracy: 0.3594 - val_MSE: 0.2218 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 22/75\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 7.0283 - accuracy: 0.3138 - MSE: 0.2230 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 7.1130 - val_accuracy: 0.3594 - val_MSE: 0.2213 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 23/75\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 6.9824 - accuracy: 0.3151 - MSE: 0.2230 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 7.0546 - val_accuracy: 0.3594 - val_MSE: 0.2219 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 24/75\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 7.2825 - accuracy: 0.2995 - MSE: 0.2230 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 8.1957 - val_accuracy: 0.3438 - val_MSE: 0.2217 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 25/75\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 7.6687 - accuracy: 0.3021 - MSE: 0.2235 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 7.2163 - val_accuracy: 0.2188 - val_MSE: 0.2236 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 26/75\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 7.1874 - accuracy: 0.3021 - MSE: 0.2231 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 7.0050 - val_accuracy: 0.2344 - val_MSE: 0.2242 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 27/75\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 7.1676 - accuracy: 0.3008 - MSE: 0.2231 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 7.8233 - val_accuracy: 0.2344 - val_MSE: 0.2245 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 28/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 115ms/step - loss: 8.6011 - accuracy: 0.3242 - MSE: 0.2228 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 12.0021 - val_accuracy: 0.2891 - val_MSE: 0.2240 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 29/75\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 11.1482 - accuracy: 0.3255 - MSE: 0.2230 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 9.4028 - val_accuracy: 0.2344 - val_MSE: 0.2228 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 30/75\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 9.5308 - accuracy: 0.3138 - MSE: 0.2235 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 9.6772 - val_accuracy: 0.1875 - val_MSE: 0.2254 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 31/75\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 8.8477 - accuracy: 0.2995 - MSE: 0.2237 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 7.9151 - val_accuracy: 0.3203 - val_MSE: 0.2227 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 32/75\n",
      "12/12 [==============================] - 2s 134ms/step - loss: 7.7726 - accuracy: 0.2943 - MSE: 0.2229 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 7.4923 - val_accuracy: 0.2422 - val_MSE: 0.2231 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 33/75\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 7.3303 - accuracy: 0.3099 - MSE: 0.2231 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 7.0517 - val_accuracy: 0.3828 - val_MSE: 0.2222 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 34/75\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 7.4679 - accuracy: 0.3125 - MSE: 0.2230 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 7.3253 - val_accuracy: 0.3594 - val_MSE: 0.2223 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 35/75\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 7.1705 - accuracy: 0.3138 - MSE: 0.2231 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 6.9233 - val_accuracy: 0.3594 - val_MSE: 0.2219 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00.1898 - accuracy: 0.3210 - MSE: 0.2231 - precision_10: 0.0000e+00 - recall_10: 0.0000e+\n",
      "Epoch 36/75\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 6.7943 - accuracy: 0.3190 - MSE: 0.2229 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 6.7098 - val_accuracy: 0.3594 - val_MSE: 0.2220 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 37/75\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 6.7166 - accuracy: 0.3151 - MSE: 0.2229 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 6.7399 - val_accuracy: 0.3828 - val_MSE: 0.2219 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 38/75\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 7.1863 - accuracy: 0.3021 - MSE: 0.2231 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 9.4837 - val_accuracy: 0.3125 - val_MSE: 0.2230 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 39/75\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 8.7285 - accuracy: 0.3307 - MSE: 0.2230 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 7.9148 - val_accuracy: 0.2344 - val_MSE: 0.2246 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 40/75\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 7.4337 - accuracy: 0.3021 - MSE: 0.2229 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 7.2187 - val_accuracy: 0.2344 - val_MSE: 0.2242 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 41/75\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 7.0307 - accuracy: 0.3138 - MSE: 0.2228 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 6.9141 - val_accuracy: 0.2344 - val_MSE: 0.2248 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 42/75\n",
      "12/12 [==============================] - 2s 125ms/step - loss: 7.2622 - accuracy: 0.3086 - MSE: 0.2231 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 7.1418 - val_accuracy: 0.2344 - val_MSE: 0.2245 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 43/75\n",
      "12/12 [==============================] - 1s 124ms/step - loss: 7.6117 - accuracy: 0.3138 - MSE: 0.2227 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 8.6436 - val_accuracy: 0.2578 - val_MSE: 0.2241 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 44/75\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 9.3408 - accuracy: 0.2969 - MSE: 0.2236 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 8.8759 - val_accuracy: 0.2344 - val_MSE: 0.2232 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 45/75\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 8.2255 - accuracy: 0.3138 - MSE: 0.2232 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 7.6938 - val_accuracy: 0.2344 - val_MSE: 0.2230 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 46/75\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 7.3512 - accuracy: 0.2956 - MSE: 0.2233 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 6.9759 - val_accuracy: 0.3594 - val_MSE: 0.2220 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00955 - accuracy: 0.3031 - MSE: 0.2233 - precision_10: 0.0000e+00 - recall_10: 0.0000e\n",
      "Epoch 47/75\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 6.8226 - accuracy: 0.3190 - MSE: 0.2229 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 6.6850 - val_accuracy: 0.3594 - val_MSE: 0.2216 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 48/75\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 7.2824 - accuracy: 0.3021 - MSE: 0.2227 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 11.4820 - val_accuracy: 0.4609 - val_MSE: 0.2200 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 49/75\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 12.5179 - accuracy: 0.3229 - MSE: 0.2232 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 10.6844 - val_accuracy: 0.3594 - val_MSE: 0.2221 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 50/75\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 9.2653 - accuracy: 0.3008 - MSE: 0.2233 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 8.1346 - val_accuracy: 0.3594 - val_MSE: 0.2233 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 51/75\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 7.7803 - accuracy: 0.3047 - MSE: 0.2231 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 7.6502 - val_accuracy: 0.2344 - val_MSE: 0.2233 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 52/75\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 7.2900 - accuracy: 0.3151 - MSE: 0.2228 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 7.1171 - val_accuracy: 0.2344 - val_MSE: 0.2243 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 53/75\n",
      "12/12 [==============================] - 2s 133ms/step - loss: 6.9681 - accuracy: 0.3060 - MSE: 0.2230 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 7.0156 - val_accuracy: 0.2344 - val_MSE: 0.2242 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 54/75\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 7.2322 - accuracy: 0.3125 - MSE: 0.2229 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 7.2410 - val_accuracy: 0.2344 - val_MSE: 0.2246 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 55/75\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 7.7976 - accuracy: 0.3164 - MSE: 0.2231 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 8.1928 - val_accuracy: 0.2188 - val_MSE: 0.2251 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 56/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 115ms/step - loss: 7.8894 - accuracy: 0.3216 - MSE: 0.2234 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 7.7455 - val_accuracy: 0.2812 - val_MSE: 0.2236 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 57/75\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 8.1856 - accuracy: 0.3268 - MSE: 0.2244 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 8.3893 - val_accuracy: 0.2344 - val_MSE: 0.2241 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 58/75\n",
      "12/12 [==============================] - 1s 118ms/step - loss: 9.3470 - accuracy: 0.3125 - MSE: 0.2248 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 11.4665 - val_accuracy: 0.2500 - val_MSE: 0.2288 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 59/75\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 15.5316 - accuracy: 0.3216 - MSE: 0.2261 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 19.9666 - val_accuracy: 0.3672 - val_MSE: 0.2210 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 60/75\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 17.5280 - accuracy: 0.3281 - MSE: 0.2251 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 13.7576 - val_accuracy: 0.2578 - val_MSE: 0.2255 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+006304 - accuracy: 0.3164 - MSE: 0.2260 - precision_10: 0.0000e+00 - recall_10: \n",
      "Epoch 61/75\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 11.6499 - accuracy: 0.3047 - MSE: 0.2252 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 9.8431 - val_accuracy: 0.3359 - val_MSE: 0.2176 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 62/75\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 9.1863 - accuracy: 0.3164 - MSE: 0.2248 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 8.4646 - val_accuracy: 0.3594 - val_MSE: 0.2208 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 63/75\n",
      "12/12 [==============================] - 1s 122ms/step - loss: 8.0980 - accuracy: 0.3125 - MSE: 0.2258 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 8.1814 - val_accuracy: 0.2812 - val_MSE: 0.2239 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 64/75\n",
      "12/12 [==============================] - 2s 132ms/step - loss: 8.4279 - accuracy: 0.3190 - MSE: 0.2239 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 8.3494 - val_accuracy: 0.3203 - val_MSE: 0.2224 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 65/75\n",
      "12/12 [==============================] - 1s 114ms/step - loss: 8.1316 - accuracy: 0.3138 - MSE: 0.2233 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 7.6817 - val_accuracy: 0.2344 - val_MSE: 0.2244 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 66/75\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 7.3121 - accuracy: 0.3086 - MSE: 0.2231 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 7.0577 - val_accuracy: 0.2344 - val_MSE: 0.2248 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 67/75\n",
      "12/12 [==============================] - 1s 113ms/step - loss: 7.0905 - accuracy: 0.3099 - MSE: 0.2228 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 7.4771 - val_accuracy: 0.2734 - val_MSE: 0.2243 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 68/75\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 9.7868 - accuracy: 0.3021 - MSE: 0.2231 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 8.8518 - val_accuracy: 0.2344 - val_MSE: 0.2240 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 69/75\n",
      "12/12 [==============================] - 1s 117ms/step - loss: 8.0608 - accuracy: 0.2995 - MSE: 0.2229 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 7.5806 - val_accuracy: 0.2344 - val_MSE: 0.2237 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 70/75\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 7.4273 - accuracy: 0.3034 - MSE: 0.2231 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 7.2480 - val_accuracy: 0.2344 - val_MSE: 0.2237 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 71/75\n",
      "12/12 [==============================] - 1s 113ms/step - loss: 7.3170 - accuracy: 0.2956 - MSE: 0.2232 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 7.4690 - val_accuracy: 0.3438 - val_MSE: 0.2222 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 72/75\n",
      "12/12 [==============================] - 1s 115ms/step - loss: 7.3450 - accuracy: 0.2852 - MSE: 0.2231 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 6.9698 - val_accuracy: 0.3594 - val_MSE: 0.2224 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 73/75\n",
      "12/12 [==============================] - 1s 112ms/step - loss: 6.7859 - accuracy: 0.3177 - MSE: 0.2228 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 6.5362 - val_accuracy: 0.3594 - val_MSE: 0.2219 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 74/75\n",
      "12/12 [==============================] - 2s 134ms/step - loss: 6.5810 - accuracy: 0.3164 - MSE: 0.2228 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 6.8148 - val_accuracy: 0.3359 - val_MSE: 0.2219 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Epoch 75/75\n",
      "12/12 [==============================] - 1s 116ms/step - loss: 7.2929 - accuracy: 0.3112 - MSE: 0.2231 - precision_10: 0.0000e+00 - recall_10: 0.0000e+00 - val_loss: 7.2155 - val_accuracy: 0.3594 - val_MSE: 0.2219 - val_precision_10: 0.0000e+00 - val_recall_10: 0.0000e+00\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_11 (LSTM)               (256, 4)                  96096     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (256, 4)                  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (256, 4)                  16        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (256, 3)                  15        \n",
      "=================================================================\n",
      "Total params: 96,127\n",
      "Trainable params: 96,119\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Starting: \n",
      "{'batch_size': 256, 'epochs': 80, 'learning_rate': 0.0001, 'optimizer': 'adam'}\n",
      "---------------------------------------------------------------------------------\n",
      "{   'activation': 'sigmoid',\n",
      "    'dropout_rate': 0.2,\n",
      "    'filters': 17,\n",
      "    'kernel_size': 3,\n",
      "    'l1_r': 0.2,\n",
      "    'l2_r': 0.0001,\n",
      "    'output_layer_activation': 'softmax',\n",
      "    'padding': 'same',\n",
      "    'start_neurons': 4}\n",
      "oof\n",
      "Epoch 1/80\n",
      "2/3 [===================>..........] - ETA: 1s - loss: 303.9608 - accuracy: 0.3379 - MSE: 0.2862 - precision_11: 0.3529 - recall_11: 0.2695WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.3574s vs `on_train_batch_end` time: 1.9558s). Check your callbacks.\n",
      "3/3 [==============================] - 4s 1s/step - loss: 303.0286 - accuracy: 0.3372 - MSE: 0.2868 - precision_11: 0.3462 - recall_11: 0.2682 - val_loss: 299.0618 - val_accuracy: 0.3086 - val_MSE: 0.2449 - val_precision_11: 0.3011 - val_recall_11: 0.1094\n",
      "Epoch 2/80\n",
      "3/3 [==============================] - 2s 670ms/step - loss: 297.4438 - accuracy: 0.3581 - MSE: 0.2817 - precision_11: 0.3545 - recall_11: 0.2760 - val_loss: 293.5335 - val_accuracy: 0.3164 - val_MSE: 0.2449 - val_precision_11: 0.2947 - val_recall_11: 0.1094\n",
      "Epoch 3/80\n",
      "3/3 [==============================] - 2s 574ms/step - loss: 291.9236 - accuracy: 0.3359 - MSE: 0.2799 - precision_11: 0.3521 - recall_11: 0.2773 - val_loss: 288.0471 - val_accuracy: 0.3203 - val_MSE: 0.2450 - val_precision_11: 0.2935 - val_recall_11: 0.1055\n",
      "Epoch 4/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 571ms/step - loss: 286.4100 - accuracy: 0.3594 - MSE: 0.2758 - precision_11: 0.3669 - recall_11: 0.2799 - val_loss: 282.6053 - val_accuracy: 0.3398 - val_MSE: 0.2450 - val_precision_11: 0.2889 - val_recall_11: 0.1016\n",
      "Epoch 5/80\n",
      "3/3 [==============================] - 2s 571ms/step - loss: 281.0312 - accuracy: 0.3503 - MSE: 0.2792 - precision_11: 0.3571 - recall_11: 0.2799 - val_loss: 277.2148 - val_accuracy: 0.3398 - val_MSE: 0.2449 - val_precision_11: 0.2955 - val_recall_11: 0.1016\n",
      "Epoch 6/80\n",
      "3/3 [==============================] - 2s 576ms/step - loss: 275.6788 - accuracy: 0.3294 - MSE: 0.2835 - precision_11: 0.3467 - recall_11: 0.2708 - val_loss: 271.8732 - val_accuracy: 0.3398 - val_MSE: 0.2449 - val_precision_11: 0.2989 - val_recall_11: 0.1016\n",
      "Epoch 7/80\n",
      "3/3 [==============================] - 2s 568ms/step - loss: 270.3088 - accuracy: 0.3555 - MSE: 0.2760 - precision_11: 0.3740 - recall_11: 0.2956 - val_loss: 266.5796 - val_accuracy: 0.3398 - val_MSE: 0.2448 - val_precision_11: 0.2955 - val_recall_11: 0.1016\n",
      "Epoch 8/80\n",
      "3/3 [==============================] - 2s 573ms/step - loss: 265.0179 - accuracy: 0.3633 - MSE: 0.2746 - precision_11: 0.3650 - recall_11: 0.2799 - val_loss: 261.3412 - val_accuracy: 0.3359 - val_MSE: 0.2448 - val_precision_11: 0.3034 - val_recall_11: 0.1055\n",
      "Epoch 9/80\n",
      "3/3 [==============================] - 2s 564ms/step - loss: 259.8084 - accuracy: 0.3633 - MSE: 0.2734 - precision_11: 0.3761 - recall_11: 0.2904 - val_loss: 256.1548 - val_accuracy: 0.3359 - val_MSE: 0.2448 - val_precision_11: 0.3023 - val_recall_11: 0.1016\n",
      "Epoch 10/80\n",
      "3/3 [==============================] - 2s 564ms/step - loss: 254.6760 - accuracy: 0.3581 - MSE: 0.2798 - precision_11: 0.3605 - recall_11: 0.2878 - val_loss: 251.0198 - val_accuracy: 0.3320 - val_MSE: 0.2450 - val_precision_11: 0.2941 - val_recall_11: 0.0977\n",
      "Epoch 11/80\n",
      "3/3 [==============================] - 2s 685ms/step - loss: 249.4965 - accuracy: 0.3607 - MSE: 0.2716 - precision_11: 0.3719 - recall_11: 0.2969 - val_loss: 245.9373 - val_accuracy: 0.3398 - val_MSE: 0.2452 - val_precision_11: 0.2841 - val_recall_11: 0.0977\n",
      "Epoch 12/80\n",
      "3/3 [==============================] - 2s 566ms/step - loss: 244.4036 - accuracy: 0.3698 - MSE: 0.2712 - precision_11: 0.3918 - recall_11: 0.2995 - val_loss: 240.8947 - val_accuracy: 0.3438 - val_MSE: 0.2454 - val_precision_11: 0.2778 - val_recall_11: 0.0977\n",
      "Epoch 13/80\n",
      "3/3 [==============================] - 2s 570ms/step - loss: 239.3730 - accuracy: 0.3776 - MSE: 0.2667 - precision_11: 0.4000 - recall_11: 0.3047 - val_loss: 235.9073 - val_accuracy: 0.3438 - val_MSE: 0.2455 - val_precision_11: 0.2809 - val_recall_11: 0.0977\n",
      "Epoch 14/80\n",
      "3/3 [==============================] - 2s 575ms/step - loss: 234.4216 - accuracy: 0.3698 - MSE: 0.2691 - precision_11: 0.3836 - recall_11: 0.2982 - val_loss: 230.9841 - val_accuracy: 0.3398 - val_MSE: 0.2459 - val_precision_11: 0.2935 - val_recall_11: 0.1055\n",
      "Epoch 15/80\n",
      "3/3 [==============================] - 2s 568ms/step - loss: 229.5377 - accuracy: 0.3672 - MSE: 0.2713 - precision_11: 0.3798 - recall_11: 0.2982 - val_loss: 226.1132 - val_accuracy: 0.3398 - val_MSE: 0.2460 - val_precision_11: 0.2967 - val_recall_11: 0.1055\n",
      "Epoch 16/80\n",
      "3/3 [==============================] - 2s 579ms/step - loss: 224.6303 - accuracy: 0.3724 - MSE: 0.2672 - precision_11: 0.3880 - recall_11: 0.3021 - val_loss: 221.2935 - val_accuracy: 0.3398 - val_MSE: 0.2461 - val_precision_11: 0.2941 - val_recall_11: 0.0977\n",
      "Epoch 17/80\n",
      "3/3 [==============================] - 2s 578ms/step - loss: 219.8527 - accuracy: 0.3763 - MSE: 0.2689 - precision_11: 0.3892 - recall_11: 0.2995 - val_loss: 216.5275 - val_accuracy: 0.3438 - val_MSE: 0.2463 - val_precision_11: 0.2941 - val_recall_11: 0.0977\n",
      "Epoch 18/80\n",
      "3/3 [==============================] - 2s 577ms/step - loss: 215.1196 - accuracy: 0.3659 - MSE: 0.2689 - precision_11: 0.3771 - recall_11: 0.2917 - val_loss: 211.8163 - val_accuracy: 0.3398 - val_MSE: 0.2465 - val_precision_11: 0.2857 - val_recall_11: 0.0938\n",
      "Epoch 19/80\n",
      "3/3 [==============================] - 2s 656ms/step - loss: 210.4255 - accuracy: 0.3646 - MSE: 0.2732 - precision_11: 0.3679 - recall_11: 0.2865 - val_loss: 207.1580 - val_accuracy: 0.3359 - val_MSE: 0.2468 - val_precision_11: 0.2824 - val_recall_11: 0.0938\n",
      "Epoch 20/80\n",
      "3/3 [==============================] - 2s 575ms/step - loss: 205.7526 - accuracy: 0.3711 - MSE: 0.2684 - precision_11: 0.3711 - recall_11: 0.2812 - val_loss: 202.5485 - val_accuracy: 0.3281 - val_MSE: 0.2470 - val_precision_11: 0.2791 - val_recall_11: 0.0938\n",
      "Epoch 21/80\n",
      "3/3 [==============================] - 2s 574ms/step - loss: 201.1104 - accuracy: 0.4089 - MSE: 0.2571 - precision_11: 0.4239 - recall_11: 0.3372 - val_loss: 197.9895 - val_accuracy: 0.3281 - val_MSE: 0.2472 - val_precision_11: 0.2857 - val_recall_11: 0.0938\n",
      "Epoch 22/80\n",
      "3/3 [==============================] - 2s 574ms/step - loss: 196.6370 - accuracy: 0.3737 - MSE: 0.2683 - precision_11: 0.3938 - recall_11: 0.3138 - val_loss: 193.4833 - val_accuracy: 0.3242 - val_MSE: 0.2474 - val_precision_11: 0.2727 - val_recall_11: 0.0938\n",
      "Epoch 23/80\n",
      "3/3 [==============================] - 2s 569ms/step - loss: 192.1076 - accuracy: 0.3958 - MSE: 0.2611 - precision_11: 0.4087 - recall_11: 0.3177 - val_loss: 189.0280 - val_accuracy: 0.3164 - val_MSE: 0.2477 - val_precision_11: 0.2614 - val_recall_11: 0.0898\n",
      "Epoch 24/80\n",
      "3/3 [==============================] - 2s 568ms/step - loss: 187.6727 - accuracy: 0.3802 - MSE: 0.2645 - precision_11: 0.3845 - recall_11: 0.2904 - val_loss: 184.6258 - val_accuracy: 0.3203 - val_MSE: 0.2481 - val_precision_11: 0.2584 - val_recall_11: 0.0898\n",
      "Epoch 25/80\n",
      "3/3 [==============================] - 2s 629ms/step - loss: 183.2708 - accuracy: 0.3932 - MSE: 0.2602 - precision_11: 0.3990 - recall_11: 0.3138 - val_loss: 180.2713 - val_accuracy: 0.3203 - val_MSE: 0.2483 - val_precision_11: 0.2667 - val_recall_11: 0.0938\n",
      "Epoch 26/80\n",
      "3/3 [==============================] - 2s 578ms/step - loss: 178.9392 - accuracy: 0.3802 - MSE: 0.2644 - precision_11: 0.3980 - recall_11: 0.3047 - val_loss: 175.9690 - val_accuracy: 0.3164 - val_MSE: 0.2483 - val_precision_11: 0.2614 - val_recall_11: 0.0898\n",
      "Epoch 27/80\n",
      "3/3 [==============================] - 2s 636ms/step - loss: 174.6940 - accuracy: 0.3906 - MSE: 0.2675 - precision_11: 0.3947 - recall_11: 0.3125 - val_loss: 171.7247 - val_accuracy: 0.3164 - val_MSE: 0.2486 - val_precision_11: 0.2529 - val_recall_11: 0.0859\n",
      "Epoch 28/80\n",
      "3/3 [==============================] - 2s 607ms/step - loss: 170.4198 - accuracy: 0.3984 - MSE: 0.2617 - precision_11: 0.4144 - recall_11: 0.3216 - val_loss: 167.5382 - val_accuracy: 0.3203 - val_MSE: 0.2487 - val_precision_11: 0.2619 - val_recall_11: 0.0859\n",
      "Epoch 29/80\n",
      "3/3 [==============================] - 2s 595ms/step - loss: 166.2645 - accuracy: 0.3828 - MSE: 0.2656 - precision_11: 0.3937 - recall_11: 0.3086 - val_loss: 163.3995 - val_accuracy: 0.3203 - val_MSE: 0.2489 - val_precision_11: 0.2771 - val_recall_11: 0.0898\n",
      "Epoch 30/80\n",
      "3/3 [==============================] - 2s 599ms/step - loss: 162.1398 - accuracy: 0.3854 - MSE: 0.2635 - precision_11: 0.3966 - recall_11: 0.2995 - val_loss: 159.3129 - val_accuracy: 0.3242 - val_MSE: 0.2490 - val_precision_11: 0.2718 - val_recall_11: 0.1094\n",
      "Epoch 31/80\n",
      "3/3 [==============================] - 2s 598ms/step - loss: 158.0564 - accuracy: 0.3685 - MSE: 0.2652 - precision_11: 0.3748 - recall_11: 0.2865 - val_loss: 155.2782 - val_accuracy: 0.3242 - val_MSE: 0.2491 - val_precision_11: 0.2736 - val_recall_11: 0.1133\n",
      "Epoch 32/80\n",
      "3/3 [==============================] - 2s 586ms/step - loss: 154.0173 - accuracy: 0.4128 - MSE: 0.2585 - precision_11: 0.4158 - recall_11: 0.3281 - val_loss: 151.2956 - val_accuracy: 0.3242 - val_MSE: 0.2492 - val_precision_11: 0.2804 - val_recall_11: 0.1172\n",
      "Epoch 33/80\n",
      "3/3 [==============================] - 2s 581ms/step - loss: 150.0465 - accuracy: 0.3906 - MSE: 0.2570 - precision_11: 0.4126 - recall_11: 0.3164 - val_loss: 147.3700 - val_accuracy: 0.3242 - val_MSE: 0.2495 - val_precision_11: 0.2897 - val_recall_11: 0.1211\n",
      "Epoch 34/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 571ms/step - loss: 146.1349 - accuracy: 0.3854 - MSE: 0.2576 - precision_11: 0.4053 - recall_11: 0.3008 - val_loss: 143.4956 - val_accuracy: 0.3203 - val_MSE: 0.2498 - val_precision_11: 0.2857 - val_recall_11: 0.1172\n",
      "Epoch 35/80\n",
      "3/3 [==============================] - 2s 574ms/step - loss: 142.3036 - accuracy: 0.3867 - MSE: 0.2602 - precision_11: 0.3980 - recall_11: 0.3073 - val_loss: 139.6718 - val_accuracy: 0.3242 - val_MSE: 0.2500 - val_precision_11: 0.2857 - val_recall_11: 0.1172\n",
      "Epoch 36/80\n",
      "3/3 [==============================] - 2s 676ms/step - loss: 138.4623 - accuracy: 0.4062 - MSE: 0.2525 - precision_11: 0.4319 - recall_11: 0.3385 - val_loss: 135.8982 - val_accuracy: 0.3242 - val_MSE: 0.2502 - val_precision_11: 0.2857 - val_recall_11: 0.1172\n",
      "Epoch 37/80\n",
      "3/3 [==============================] - 2s 577ms/step - loss: 134.6701 - accuracy: 0.4206 - MSE: 0.2465 - precision_11: 0.4486 - recall_11: 0.3464 - val_loss: 132.1775 - val_accuracy: 0.3203 - val_MSE: 0.2502 - val_precision_11: 0.2804 - val_recall_11: 0.1172\n",
      "Epoch 38/80\n",
      "3/3 [==============================] - 2s 581ms/step - loss: 131.0078 - accuracy: 0.3841 - MSE: 0.2568 - precision_11: 0.4101 - recall_11: 0.3177 - val_loss: 128.5105 - val_accuracy: 0.3164 - val_MSE: 0.2506 - val_precision_11: 0.2909 - val_recall_11: 0.1250\n",
      "Epoch 39/80\n",
      "3/3 [==============================] - 2s 575ms/step - loss: 127.3444 - accuracy: 0.4193 - MSE: 0.2505 - precision_11: 0.4400 - recall_11: 0.3438 - val_loss: 124.9069 - val_accuracy: 0.3164 - val_MSE: 0.2510 - val_precision_11: 0.2973 - val_recall_11: 0.1289\n",
      "Epoch 40/80\n",
      "3/3 [==============================] - 2s 576ms/step - loss: 123.7675 - accuracy: 0.3906 - MSE: 0.2557 - precision_11: 0.4088 - recall_11: 0.3151 - val_loss: 121.3562 - val_accuracy: 0.3125 - val_MSE: 0.2512 - val_precision_11: 0.3097 - val_recall_11: 0.1367\n",
      "Epoch 41/80\n",
      "3/3 [==============================] - 2s 579ms/step - loss: 120.1512 - accuracy: 0.4232 - MSE: 0.2406 - precision_11: 0.4525 - recall_11: 0.3411 - val_loss: 117.8483 - val_accuracy: 0.3203 - val_MSE: 0.2513 - val_precision_11: 0.3070 - val_recall_11: 0.1367\n",
      "Epoch 42/80\n",
      "3/3 [==============================] - 2s 572ms/step - loss: 116.7165 - accuracy: 0.4076 - MSE: 0.2518 - precision_11: 0.4151 - recall_11: 0.3151 - val_loss: 114.3943 - val_accuracy: 0.3125 - val_MSE: 0.2512 - val_precision_11: 0.3070 - val_recall_11: 0.1367\n",
      "Epoch 43/80\n",
      "3/3 [==============================] - 2s 570ms/step - loss: 113.2892 - accuracy: 0.3932 - MSE: 0.2520 - precision_11: 0.4222 - recall_11: 0.3216 - val_loss: 110.9894 - val_accuracy: 0.3164 - val_MSE: 0.2509 - val_precision_11: 0.3017 - val_recall_11: 0.1367\n",
      "Epoch 44/80\n",
      "3/3 [==============================] - 2s 660ms/step - loss: 109.8753 - accuracy: 0.4245 - MSE: 0.2479 - precision_11: 0.4421 - recall_11: 0.3333 - val_loss: 107.6424 - val_accuracy: 0.3164 - val_MSE: 0.2505 - val_precision_11: 0.3017 - val_recall_11: 0.1367\n",
      "Epoch 45/80\n",
      "3/3 [==============================] - 2s 570ms/step - loss: 106.5181 - accuracy: 0.4401 - MSE: 0.2388 - precision_11: 0.4745 - recall_11: 0.3633 - val_loss: 104.3473 - val_accuracy: 0.3320 - val_MSE: 0.2500 - val_precision_11: 0.3070 - val_recall_11: 0.1367\n",
      "Epoch 46/80\n",
      "3/3 [==============================] - 2s 575ms/step - loss: 103.2810 - accuracy: 0.4245 - MSE: 0.2475 - precision_11: 0.4486 - recall_11: 0.3411 - val_loss: 101.1092 - val_accuracy: 0.3281 - val_MSE: 0.2498 - val_precision_11: 0.3167 - val_recall_11: 0.1484\n",
      "Epoch 47/80\n",
      "3/3 [==============================] - 2s 568ms/step - loss: 100.0656 - accuracy: 0.4089 - MSE: 0.2501 - precision_11: 0.4320 - recall_11: 0.3307 - val_loss: 97.9296 - val_accuracy: 0.3164 - val_MSE: 0.2499 - val_precision_11: 0.2984 - val_recall_11: 0.1445\n",
      "Epoch 48/80\n",
      "3/3 [==============================] - 2s 576ms/step - loss: 96.8879 - accuracy: 0.4271 - MSE: 0.2477 - precision_11: 0.4530 - recall_11: 0.3451 - val_loss: 94.7992 - val_accuracy: 0.3242 - val_MSE: 0.2501 - val_precision_11: 0.2903 - val_recall_11: 0.1406\n",
      "Epoch 49/80\n",
      "3/3 [==============================] - 2s 580ms/step - loss: 93.7777 - accuracy: 0.4258 - MSE: 0.2442 - precision_11: 0.4566 - recall_11: 0.3490 - val_loss: 91.7150 - val_accuracy: 0.3242 - val_MSE: 0.2502 - val_precision_11: 0.3000 - val_recall_11: 0.1523\n",
      "Epoch 50/80\n",
      "3/3 [==============================] - 2s 582ms/step - loss: 90.6893 - accuracy: 0.4167 - MSE: 0.2463 - precision_11: 0.4379 - recall_11: 0.3398 - val_loss: 88.6848 - val_accuracy: 0.3281 - val_MSE: 0.2500 - val_precision_11: 0.3106 - val_recall_11: 0.1602\n",
      "Epoch 51/80\n",
      "3/3 [==============================] - 2s 571ms/step - loss: 87.6886 - accuracy: 0.4271 - MSE: 0.2449 - precision_11: 0.4388 - recall_11: 0.3359 - val_loss: 85.7044 - val_accuracy: 0.3203 - val_MSE: 0.2495 - val_precision_11: 0.3077 - val_recall_11: 0.1562\n",
      "Epoch 52/80\n",
      "3/3 [==============================] - 2s 584ms/step - loss: 84.7035 - accuracy: 0.4349 - MSE: 0.2419 - precision_11: 0.4532 - recall_11: 0.3464 - val_loss: 82.7760 - val_accuracy: 0.3203 - val_MSE: 0.2494 - val_precision_11: 0.3209 - val_recall_11: 0.1680\n",
      "Epoch 53/80\n",
      "3/3 [==============================] - 2s 669ms/step - loss: 81.7989 - accuracy: 0.4206 - MSE: 0.2426 - precision_11: 0.4523 - recall_11: 0.3581 - val_loss: 79.8983 - val_accuracy: 0.3320 - val_MSE: 0.2492 - val_precision_11: 0.3309 - val_recall_11: 0.1758\n",
      "Epoch 54/80\n",
      "3/3 [==============================] - 2s 571ms/step - loss: 78.9458 - accuracy: 0.4349 - MSE: 0.2403 - precision_11: 0.4518 - recall_11: 0.3359 - val_loss: 77.1055 - val_accuracy: 0.3359 - val_MSE: 0.2491 - val_precision_11: 0.3381 - val_recall_11: 0.1836\n",
      "Epoch 55/80\n",
      "3/3 [==============================] - 2s 578ms/step - loss: 76.1627 - accuracy: 0.4284 - MSE: 0.2401 - precision_11: 0.4566 - recall_11: 0.3490 - val_loss: 74.3503 - val_accuracy: 0.3359 - val_MSE: 0.2488 - val_precision_11: 0.3453 - val_recall_11: 0.1875\n",
      "Epoch 56/80\n",
      "3/3 [==============================] - 2s 578ms/step - loss: 73.3758 - accuracy: 0.4596 - MSE: 0.2322 - precision_11: 0.4807 - recall_11: 0.3724 - val_loss: 71.6465 - val_accuracy: 0.3281 - val_MSE: 0.2489 - val_precision_11: 0.3427 - val_recall_11: 0.1914\n",
      "Epoch 57/80\n",
      "3/3 [==============================] - 2s 573ms/step - loss: 70.7262 - accuracy: 0.4375 - MSE: 0.2373 - precision_11: 0.4745 - recall_11: 0.3633 - val_loss: 68.9942 - val_accuracy: 0.3242 - val_MSE: 0.2487 - val_precision_11: 0.3521 - val_recall_11: 0.1953\n",
      "Epoch 58/80\n",
      "3/3 [==============================] - 2s 574ms/step - loss: 68.0665 - accuracy: 0.4440 - MSE: 0.2343 - precision_11: 0.4727 - recall_11: 0.3607 - val_loss: 66.3877 - val_accuracy: 0.3242 - val_MSE: 0.2489 - val_precision_11: 0.3521 - val_recall_11: 0.1953\n",
      "Epoch 59/80\n",
      "3/3 [==============================] - 2s 572ms/step - loss: 65.4886 - accuracy: 0.4466 - MSE: 0.2355 - precision_11: 0.4545 - recall_11: 0.3320 - val_loss: 63.8392 - val_accuracy: 0.3242 - val_MSE: 0.2493 - val_precision_11: 0.3521 - val_recall_11: 0.1953\n",
      "Epoch 60/80\n",
      "3/3 [==============================] - 2s 578ms/step - loss: 62.9628 - accuracy: 0.4362 - MSE: 0.2385 - precision_11: 0.4583 - recall_11: 0.3438 - val_loss: 61.3453 - val_accuracy: 0.3203 - val_MSE: 0.2501 - val_precision_11: 0.3425 - val_recall_11: 0.1953\n",
      "Epoch 61/80\n",
      "3/3 [==============================] - 2s 674ms/step - loss: 60.4911 - accuracy: 0.4349 - MSE: 0.2390 - precision_11: 0.4626 - recall_11: 0.3620 - val_loss: 58.8990 - val_accuracy: 0.3164 - val_MSE: 0.2508 - val_precision_11: 0.3333 - val_recall_11: 0.1914\n",
      "Epoch 62/80\n",
      "3/3 [==============================] - 2s 570ms/step - loss: 58.0049 - accuracy: 0.4622 - MSE: 0.2300 - precision_11: 0.4759 - recall_11: 0.3477 - val_loss: 56.5013 - val_accuracy: 0.3086 - val_MSE: 0.2518 - val_precision_11: 0.3403 - val_recall_11: 0.1914\n",
      "Epoch 63/80\n",
      "3/3 [==============================] - 2s 581ms/step - loss: 55.6583 - accuracy: 0.4401 - MSE: 0.2349 - precision_11: 0.4648 - recall_11: 0.3438 - val_loss: 54.1570 - val_accuracy: 0.3047 - val_MSE: 0.2524 - val_precision_11: 0.3356 - val_recall_11: 0.1914\n",
      "Epoch 64/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 570ms/step - loss: 53.2889 - accuracy: 0.4674 - MSE: 0.2253 - precision_11: 0.4974 - recall_11: 0.3685 - val_loss: 51.8634 - val_accuracy: 0.3086 - val_MSE: 0.2522 - val_precision_11: 0.3310 - val_recall_11: 0.1875\n",
      "Epoch 65/80\n",
      "3/3 [==============================] - 2s 569ms/step - loss: 50.9968 - accuracy: 0.4727 - MSE: 0.2244 - precision_11: 0.5212 - recall_11: 0.3997 - val_loss: 49.6210 - val_accuracy: 0.3164 - val_MSE: 0.2526 - val_precision_11: 0.3221 - val_recall_11: 0.1875\n",
      "Epoch 66/80\n",
      "3/3 [==============================] - 2s 592ms/step - loss: 48.8047 - accuracy: 0.4349 - MSE: 0.2346 - precision_11: 0.4629 - recall_11: 0.3490 - val_loss: 47.4293 - val_accuracy: 0.3164 - val_MSE: 0.2526 - val_precision_11: 0.3311 - val_recall_11: 0.1914\n",
      "Epoch 67/80\n",
      "3/3 [==============================] - 2s 577ms/step - loss: 46.6183 - accuracy: 0.4479 - MSE: 0.2301 - precision_11: 0.4859 - recall_11: 0.3594 - val_loss: 45.2945 - val_accuracy: 0.3164 - val_MSE: 0.2526 - val_precision_11: 0.3219 - val_recall_11: 0.1836\n",
      "Epoch 68/80\n",
      "3/3 [==============================] - 2s 579ms/step - loss: 44.4960 - accuracy: 0.4635 - MSE: 0.2311 - precision_11: 0.4704 - recall_11: 0.3620 - val_loss: 43.2053 - val_accuracy: 0.3281 - val_MSE: 0.2524 - val_precision_11: 0.3288 - val_recall_11: 0.1875\n",
      "Epoch 69/80\n",
      "3/3 [==============================] - 2s 652ms/step - loss: 42.4048 - accuracy: 0.4674 - MSE: 0.2249 - precision_11: 0.5096 - recall_11: 0.3802 - val_loss: 41.1696 - val_accuracy: 0.3320 - val_MSE: 0.2523 - val_precision_11: 0.3401 - val_recall_11: 0.1953\n",
      "Epoch 70/80\n",
      "3/3 [==============================] - 2s 602ms/step - loss: 40.4248 - accuracy: 0.4362 - MSE: 0.2344 - precision_11: 0.4618 - recall_11: 0.3464 - val_loss: 39.1905 - val_accuracy: 0.3242 - val_MSE: 0.2521 - val_precision_11: 0.3356 - val_recall_11: 0.1953\n",
      "Epoch 71/80\n",
      "3/3 [==============================] - 2s 570ms/step - loss: 38.4417 - accuracy: 0.4596 - MSE: 0.2267 - precision_11: 0.4974 - recall_11: 0.3802 - val_loss: 37.2604 - val_accuracy: 0.3281 - val_MSE: 0.2522 - val_precision_11: 0.3288 - val_recall_11: 0.1875\n",
      "Epoch 72/80\n",
      "3/3 [==============================] - 2s 567ms/step - loss: 36.5289 - accuracy: 0.4648 - MSE: 0.2252 - precision_11: 0.4974 - recall_11: 0.3763 - val_loss: 35.4376 - val_accuracy: 0.3164 - val_MSE: 0.2526 - val_precision_11: 0.3310 - val_recall_11: 0.1875\n",
      "Epoch 73/80\n",
      "3/3 [==============================] - 2s 577ms/step - loss: 34.7179 - accuracy: 0.4766 - MSE: 0.2236 - precision_11: 0.5054 - recall_11: 0.3685 - val_loss: 33.6383 - val_accuracy: 0.3125 - val_MSE: 0.2531 - val_precision_11: 0.3197 - val_recall_11: 0.1836\n",
      "Epoch 74/80\n",
      "3/3 [==============================] - 2s 572ms/step - loss: 32.8946 - accuracy: 0.4661 - MSE: 0.2215 - precision_11: 0.4949 - recall_11: 0.3763 - val_loss: 31.8684 - val_accuracy: 0.3125 - val_MSE: 0.2536 - val_precision_11: 0.3154 - val_recall_11: 0.1836\n",
      "Epoch 75/80\n",
      "3/3 [==============================] - 2s 576ms/step - loss: 31.1171 - accuracy: 0.4779 - MSE: 0.2173 - precision_11: 0.5078 - recall_11: 0.3815 - val_loss: 30.1367 - val_accuracy: 0.3242 - val_MSE: 0.2540 - val_precision_11: 0.3154 - val_recall_11: 0.1836\n",
      "Epoch 76/80\n",
      "3/3 [==============================] - 2s 584ms/step - loss: 29.4035 - accuracy: 0.5065 - MSE: 0.2158 - precision_11: 0.5313 - recall_11: 0.4089 - val_loss: 28.4545 - val_accuracy: 0.3281 - val_MSE: 0.2536 - val_precision_11: 0.3243 - val_recall_11: 0.1875\n",
      "Epoch 77/80\n",
      "3/3 [==============================] - 2s 573ms/step - loss: 27.7857 - accuracy: 0.4727 - MSE: 0.2256 - precision_11: 0.5146 - recall_11: 0.3893 - val_loss: 26.8278 - val_accuracy: 0.3359 - val_MSE: 0.2532 - val_precision_11: 0.3245 - val_recall_11: 0.1914\n",
      "Epoch 78/80\n",
      "3/3 [==============================] - 2s 673ms/step - loss: 26.1252 - accuracy: 0.4844 - MSE: 0.2165 - precision_11: 0.5150 - recall_11: 0.3802 - val_loss: 25.2558 - val_accuracy: 0.3203 - val_MSE: 0.2533 - val_precision_11: 0.3245 - val_recall_11: 0.1914\n",
      "Epoch 79/80\n",
      "3/3 [==============================] - 2s 573ms/step - loss: 24.5786 - accuracy: 0.4961 - MSE: 0.2162 - precision_11: 0.5177 - recall_11: 0.3997 - val_loss: 23.7384 - val_accuracy: 0.3203 - val_MSE: 0.2529 - val_precision_11: 0.3113 - val_recall_11: 0.1836\n",
      "Epoch 80/80\n",
      "3/3 [==============================] - 2s 572ms/step - loss: 23.0637 - accuracy: 0.5208 - MSE: 0.2088 - precision_11: 0.5573 - recall_11: 0.4245 - val_loss: 22.2759 - val_accuracy: 0.3203 - val_MSE: 0.2523 - val_precision_11: 0.3158 - val_recall_11: 0.1875\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_12 (LSTM)               (16, 2)                   48032     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (16, 2)                   0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (16, 2)                   8         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (16, 3)                   9         \n",
      "=================================================================\n",
      "Total params: 48,049\n",
      "Trainable params: 48,045\n",
      "Non-trainable params: 4\n",
      "_________________________________________________________________\n",
      "Starting: \n",
      "{'batch_size': 16, 'epochs': 80, 'learning_rate': 0.0001, 'optimizer': 'adam'}\n",
      "---------------------------------------------------------------------------------\n",
      "{   'activation': 'tanh',\n",
      "    'dropout_rate': 0.1,\n",
      "    'filters': 9,\n",
      "    'kernel_size': 3,\n",
      "    'l1_r': 0.2,\n",
      "    'l2_r': 0.01,\n",
      "    'output_layer_activation': 'softmax',\n",
      "    'padding': 'valid',\n",
      "    'start_neurons': 2}\n",
      "Epoch 1/80\n",
      " 2/51 [>.............................] - ETA: 47s - loss: 152.1573 - accuracy: 0.3438 - MSE: 0.2663 - precision_12: 0.2353 - recall_12: 0.1250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0060s vs `on_train_batch_end` time: 1.9339s). Check your callbacks.\n",
      "51/51 [==============================] - 4s 88ms/step - loss: 136.4921 - accuracy: 0.3346 - MSE: 0.2541 - precision_12: 0.3385 - recall_12: 0.1593 - val_loss: 123.0722 - val_accuracy: 0.3906 - val_MSE: 0.2298 - val_precision_12: 0.3333 - val_recall_12: 0.0547\n",
      "Epoch 2/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 112.4142 - accuracy: 0.3480 - MSE: 0.2463 - precision_12: 0.3605 - recall_12: 0.1520 - val_loss: 101.2981 - val_accuracy: 0.3438 - val_MSE: 0.2342 - val_precision_12: 0.3077 - val_recall_12: 0.0625\n",
      "Epoch 3/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 92.0639 - accuracy: 0.3885 - MSE: 0.2356 - precision_12: 0.4085 - recall_12: 0.1642 - val_loss: 82.8276 - val_accuracy: 0.3594 - val_MSE: 0.2326 - val_precision_12: 0.3684 - val_recall_12: 0.1094\n",
      "Epoch 4/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 74.7916 - accuracy: 0.4044 - MSE: 0.2292 - precision_12: 0.4527 - recall_12: 0.1936 - val_loss: 67.1658 - val_accuracy: 0.3203 - val_MSE: 0.2308 - val_precision_12: 0.4444 - val_recall_12: 0.1562\n",
      "Epoch 5/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 61.4292 - accuracy: 0.3860 - MSE: 0.2307 - precision_12: 0.4206 - recall_12: 0.1752 - val_loss: 55.7011 - val_accuracy: 0.3125 - val_MSE: 0.2379 - val_precision_12: 0.4000 - val_recall_12: 0.1562\n",
      "Epoch 6/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 50.5331 - accuracy: 0.4069 - MSE: 0.2245 - precision_12: 0.4766 - recall_12: 0.1998 - val_loss: 45.6281 - val_accuracy: 0.3750 - val_MSE: 0.2323 - val_precision_12: 0.4255 - val_recall_12: 0.1562\n",
      "Epoch 7/80\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 41.5134 - accuracy: 0.4167 - MSE: 0.2159 - precision_12: 0.5100 - recall_12: 0.2194 - val_loss: 37.8990 - val_accuracy: 0.3516 - val_MSE: 0.2341 - val_precision_12: 0.3774 - val_recall_12: 0.1562\n",
      "Epoch 8/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 2s 31ms/step - loss: 34.9532 - accuracy: 0.4032 - MSE: 0.2205 - precision_12: 0.4912 - recall_12: 0.2047 - val_loss: 32.4395 - val_accuracy: 0.3516 - val_MSE: 0.2348 - val_precision_12: 0.4231 - val_recall_12: 0.1719\n",
      "Epoch 9/80\n",
      "51/51 [==============================] - 2s 37ms/step - loss: 30.1713 - accuracy: 0.4314 - MSE: 0.2140 - precision_12: 0.5241 - recall_12: 0.2132 - val_loss: 28.9874 - val_accuracy: 0.3750 - val_MSE: 0.2481 - val_precision_12: 0.3000 - val_recall_12: 0.1172\n",
      "Epoch 10/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 27.0265 - accuracy: 0.4203 - MSE: 0.2138 - precision_12: 0.5404 - recall_12: 0.2377 - val_loss: 25.4041 - val_accuracy: 0.3984 - val_MSE: 0.2453 - val_precision_12: 0.1860 - val_recall_12: 0.0625\n",
      "Epoch 11/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 23.9457 - accuracy: 0.4277 - MSE: 0.2190 - precision_12: 0.4971 - recall_12: 0.2132 - val_loss: 22.5972 - val_accuracy: 0.3906 - val_MSE: 0.2333 - val_precision_12: 0.3958 - val_recall_12: 0.1484\n",
      "Epoch 12/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 21.1170 - accuracy: 0.4326 - MSE: 0.2112 - precision_12: 0.5331 - recall_12: 0.2267 - val_loss: 20.0220 - val_accuracy: 0.3047 - val_MSE: 0.2448 - val_precision_12: 0.3261 - val_recall_12: 0.1172\n",
      "Epoch 13/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 19.0975 - accuracy: 0.4338 - MSE: 0.2127 - precision_12: 0.5281 - recall_12: 0.2071 - val_loss: 18.6947 - val_accuracy: 0.3359 - val_MSE: 0.2461 - val_precision_12: 0.3750 - val_recall_12: 0.1641\n",
      "Epoch 14/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 17.6278 - accuracy: 0.4522 - MSE: 0.2158 - precision_12: 0.5131 - recall_12: 0.2157 - val_loss: 16.6314 - val_accuracy: 0.3828 - val_MSE: 0.2396 - val_precision_12: 0.4118 - val_recall_12: 0.1641\n",
      "Epoch 15/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 15.7505 - accuracy: 0.4645 - MSE: 0.2078 - precision_12: 0.5460 - recall_12: 0.2181 - val_loss: 15.2626 - val_accuracy: 0.3828 - val_MSE: 0.2469 - val_precision_12: 0.4062 - val_recall_12: 0.2031\n",
      "Epoch 16/80\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 14.8513 - accuracy: 0.4130 - MSE: 0.2162 - precision_12: 0.5180 - recall_12: 0.2120 - val_loss: 14.4204 - val_accuracy: 0.3438 - val_MSE: 0.2503 - val_precision_12: 0.3684 - val_recall_12: 0.1641\n",
      "Epoch 17/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 13.3587 - accuracy: 0.4730 - MSE: 0.2070 - precision_12: 0.5736 - recall_12: 0.2341 - val_loss: 12.9465 - val_accuracy: 0.3203 - val_MSE: 0.2429 - val_precision_12: 0.4000 - val_recall_12: 0.1719\n",
      "Epoch 18/80\n",
      "51/51 [==============================] - 2s 35ms/step - loss: 12.5177 - accuracy: 0.4424 - MSE: 0.2114 - precision_12: 0.5360 - recall_12: 0.2279 - val_loss: 12.1562 - val_accuracy: 0.3281 - val_MSE: 0.2397 - val_precision_12: 0.3529 - val_recall_12: 0.1406\n",
      "Epoch 19/80\n",
      "51/51 [==============================] - 2s 32ms/step - loss: 12.0704 - accuracy: 0.4277 - MSE: 0.2161 - precision_12: 0.5074 - recall_12: 0.2108 - val_loss: 12.0189 - val_accuracy: 0.3984 - val_MSE: 0.2284 - val_precision_12: 0.4643 - val_recall_12: 0.2031\n",
      "Epoch 20/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 11.4781 - accuracy: 0.4240 - MSE: 0.2160 - precision_12: 0.5159 - recall_12: 0.2194 - val_loss: 10.5014 - val_accuracy: 0.4141 - val_MSE: 0.2282 - val_precision_12: 0.4200 - val_recall_12: 0.1641\n",
      "Epoch 21/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 9.9172 - accuracy: 0.4363 - MSE: 0.2099 - precision_12: 0.5490 - recall_12: 0.2267 - val_loss: 10.2373 - val_accuracy: 0.4062 - val_MSE: 0.2393 - val_precision_12: 0.3750 - val_recall_12: 0.1641\n",
      "Epoch 22/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 9.7993 - accuracy: 0.4277 - MSE: 0.2133 - precision_12: 0.5364 - recall_12: 0.2169 - val_loss: 9.6117 - val_accuracy: 0.3281 - val_MSE: 0.2545 - val_precision_12: 0.3667 - val_recall_12: 0.1719\n",
      "Epoch 23/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 9.2110 - accuracy: 0.4718 - MSE: 0.2085 - precision_12: 0.5415 - recall_12: 0.2157 - val_loss: 8.8484 - val_accuracy: 0.3594 - val_MSE: 0.2493 - val_precision_12: 0.2982 - val_recall_12: 0.1328\n",
      "Epoch 24/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 8.5364 - accuracy: 0.4743 - MSE: 0.2029 - precision_12: 0.5859 - recall_12: 0.2341 - val_loss: 8.4075 - val_accuracy: 0.3594 - val_MSE: 0.2415 - val_precision_12: 0.3519 - val_recall_12: 0.1484\n",
      "Epoch 25/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 8.3059 - accuracy: 0.4240 - MSE: 0.2161 - precision_12: 0.4940 - recall_12: 0.2010 - val_loss: 7.9551 - val_accuracy: 0.2969 - val_MSE: 0.2590 - val_precision_12: 0.2449 - val_recall_12: 0.0938\n",
      "Epoch 26/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 8.2236 - accuracy: 0.4093 - MSE: 0.2182 - precision_12: 0.4816 - recall_12: 0.1924 - val_loss: 8.0715 - val_accuracy: 0.3125 - val_MSE: 0.2406 - val_precision_12: 0.3488 - val_recall_12: 0.1172\n",
      "Epoch 27/80\n",
      "51/51 [==============================] - 2s 32ms/step - loss: 7.5642 - accuracy: 0.4424 - MSE: 0.2098 - precision_12: 0.5123 - recall_12: 0.2034 - val_loss: 7.2303 - val_accuracy: 0.3594 - val_MSE: 0.2336 - val_precision_12: 0.3929 - val_recall_12: 0.1719\n",
      "Epoch 28/80\n",
      "51/51 [==============================] - 2s 37ms/step - loss: 7.0173 - accuracy: 0.4632 - MSE: 0.2075 - precision_12: 0.5623 - recall_12: 0.2157 - val_loss: 6.5981 - val_accuracy: 0.3359 - val_MSE: 0.2361 - val_precision_12: 0.4000 - val_recall_12: 0.1562\n",
      "Epoch 29/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 6.2590 - accuracy: 0.4853 - MSE: 0.2055 - precision_12: 0.5929 - recall_12: 0.2267 - val_loss: 6.2947 - val_accuracy: 0.4062 - val_MSE: 0.2287 - val_precision_12: 0.4468 - val_recall_12: 0.1641\n",
      "Epoch 30/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 6.0711 - accuracy: 0.4657 - MSE: 0.2037 - precision_12: 0.5928 - recall_12: 0.2426 - val_loss: 5.7934 - val_accuracy: 0.3984 - val_MSE: 0.2249 - val_precision_12: 0.4348 - val_recall_12: 0.1562\n",
      "Epoch 31/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 5.6434 - accuracy: 0.4645 - MSE: 0.2072 - precision_12: 0.5855 - recall_12: 0.2181 - val_loss: 5.4618 - val_accuracy: 0.3516 - val_MSE: 0.2327 - val_precision_12: 0.4348 - val_recall_12: 0.1562\n",
      "Epoch 32/80\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 5.1593 - accuracy: 0.4485 - MSE: 0.2058 - precision_12: 0.5623 - recall_12: 0.2157 - val_loss: 5.1015 - val_accuracy: 0.3906 - val_MSE: 0.2273 - val_precision_12: 0.4359 - val_recall_12: 0.1328\n",
      "Epoch 33/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 5.6084 - accuracy: 0.4130 - MSE: 0.2198 - precision_12: 0.4737 - recall_12: 0.1875 - val_loss: 5.7709 - val_accuracy: 0.2812 - val_MSE: 0.2472 - val_precision_12: 0.2653 - val_recall_12: 0.1016\n",
      "Epoch 34/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 5.4797 - accuracy: 0.4203 - MSE: 0.2144 - precision_12: 0.4868 - recall_12: 0.1814 - val_loss: 5.0513 - val_accuracy: 0.3125 - val_MSE: 0.2452 - val_precision_12: 0.3265 - val_recall_12: 0.1250\n",
      "Epoch 35/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 5.3071 - accuracy: 0.4608 - MSE: 0.2078 - precision_12: 0.5497 - recall_12: 0.2034 - val_loss: 6.0081 - val_accuracy: 0.2891 - val_MSE: 0.2419 - val_precision_12: 0.2857 - val_recall_12: 0.0938\n",
      "Epoch 36/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 5.4113 - accuracy: 0.4473 - MSE: 0.2100 - precision_12: 0.5387 - recall_12: 0.2218 - val_loss: 5.0053 - val_accuracy: 0.3281 - val_MSE: 0.2541 - val_precision_12: 0.2642 - val_recall_12: 0.1094\n",
      "Epoch 37/80\n",
      "51/51 [==============================] - 2s 37ms/step - loss: 5.1428 - accuracy: 0.4301 - MSE: 0.2087 - precision_12: 0.5479 - recall_12: 0.2034 - val_loss: 5.2918 - val_accuracy: 0.2500 - val_MSE: 0.2597 - val_precision_12: 0.2041 - val_recall_12: 0.0781\n",
      "Epoch 38/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 2s 31ms/step - loss: 5.0480 - accuracy: 0.4400 - MSE: 0.2109 - precision_12: 0.5344 - recall_12: 0.1998 - val_loss: 4.8322 - val_accuracy: 0.3828 - val_MSE: 0.2404 - val_precision_12: 0.3415 - val_recall_12: 0.1094\n",
      "Epoch 39/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 4.7010 - accuracy: 0.4363 - MSE: 0.2100 - precision_12: 0.5531 - recall_12: 0.2169 - val_loss: 5.1815 - val_accuracy: 0.3750 - val_MSE: 0.2312 - val_precision_12: 0.4048 - val_recall_12: 0.1328\n",
      "Epoch 40/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 5.0044 - accuracy: 0.4473 - MSE: 0.2118 - precision_12: 0.5227 - recall_12: 0.2120 - val_loss: 4.7983 - val_accuracy: 0.3516 - val_MSE: 0.2370 - val_precision_12: 0.3889 - val_recall_12: 0.1641\n",
      "Epoch 41/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 5.1646 - accuracy: 0.4326 - MSE: 0.2131 - precision_12: 0.5097 - recall_12: 0.1924 - val_loss: 5.2914 - val_accuracy: 0.3203 - val_MSE: 0.2515 - val_precision_12: 0.2826 - val_recall_12: 0.1016\n",
      "Epoch 42/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 4.9297 - accuracy: 0.4314 - MSE: 0.2115 - precision_12: 0.5183 - recall_12: 0.1912 - val_loss: 5.0445 - val_accuracy: 0.2891 - val_MSE: 0.2416 - val_precision_12: 0.3261 - val_recall_12: 0.1172\n",
      "Epoch 43/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 4.6311 - accuracy: 0.4510 - MSE: 0.2098 - precision_12: 0.5451 - recall_12: 0.1924 - val_loss: 4.6384 - val_accuracy: 0.3750 - val_MSE: 0.2380 - val_precision_12: 0.3636 - val_recall_12: 0.1250\n",
      "Epoch 44/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 4.4424 - accuracy: 0.4363 - MSE: 0.2122 - precision_12: 0.5458 - recall_12: 0.2047 - val_loss: 4.4295 - val_accuracy: 0.3672 - val_MSE: 0.2377 - val_precision_12: 0.3409 - val_recall_12: 0.1172\n",
      "Epoch 45/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 4.1906 - accuracy: 0.4498 - MSE: 0.2094 - precision_12: 0.5559 - recall_12: 0.2071 - val_loss: 4.3020 - val_accuracy: 0.3594 - val_MSE: 0.2343 - val_precision_12: 0.4255 - val_recall_12: 0.1562\n",
      "Epoch 46/80\n",
      "51/51 [==============================] - 2s 34ms/step - loss: 4.8240 - accuracy: 0.4461 - MSE: 0.2098 - precision_12: 0.5514 - recall_12: 0.1973 - val_loss: 5.2736 - val_accuracy: 0.3281 - val_MSE: 0.2440 - val_precision_12: 0.2609 - val_recall_12: 0.0938\n",
      "Epoch 47/80\n",
      "51/51 [==============================] - 2s 32ms/step - loss: 5.0516 - accuracy: 0.4767 - MSE: 0.2060 - precision_12: 0.5666 - recall_12: 0.2034 - val_loss: 4.6723 - val_accuracy: 0.3516 - val_MSE: 0.2377 - val_precision_12: 0.3636 - val_recall_12: 0.1250\n",
      "Epoch 48/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 4.9576 - accuracy: 0.4522 - MSE: 0.2113 - precision_12: 0.5213 - recall_12: 0.1949 - val_loss: 5.0127 - val_accuracy: 0.3750 - val_MSE: 0.2256 - val_precision_12: 0.4286 - val_recall_12: 0.1406\n",
      "Epoch 49/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 4.6732 - accuracy: 0.4498 - MSE: 0.2109 - precision_12: 0.5570 - recall_12: 0.2034 - val_loss: 4.4291 - val_accuracy: 0.2891 - val_MSE: 0.2453 - val_precision_12: 0.2632 - val_recall_12: 0.0781\n",
      "Epoch 50/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 4.0596 - accuracy: 0.4706 - MSE: 0.2054 - precision_12: 0.5629 - recall_12: 0.2083 - val_loss: 4.8395 - val_accuracy: 0.3203 - val_MSE: 0.2517 - val_precision_12: 0.2273 - val_recall_12: 0.0781\n",
      "Epoch 51/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 4.5149 - accuracy: 0.4596 - MSE: 0.2084 - precision_12: 0.5476 - recall_12: 0.1973 - val_loss: 4.5228 - val_accuracy: 0.2734 - val_MSE: 0.2498 - val_precision_12: 0.2326 - val_recall_12: 0.0781\n",
      "Epoch 52/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 4.4192 - accuracy: 0.4534 - MSE: 0.2130 - precision_12: 0.5324 - recall_12: 0.1912 - val_loss: 4.6241 - val_accuracy: 0.3438 - val_MSE: 0.2323 - val_precision_12: 0.3846 - val_recall_12: 0.1172\n",
      "Epoch 53/80\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 3.9638 - accuracy: 0.4596 - MSE: 0.2044 - precision_12: 0.5839 - recall_12: 0.2132 - val_loss: 3.7763 - val_accuracy: 0.4062 - val_MSE: 0.2271 - val_precision_12: 0.3784 - val_recall_12: 0.1094\n",
      "Epoch 54/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 3.5503 - accuracy: 0.4669 - MSE: 0.2015 - precision_12: 0.6321 - recall_12: 0.2316 - val_loss: 3.7201 - val_accuracy: 0.3750 - val_MSE: 0.2333 - val_precision_12: 0.3889 - val_recall_12: 0.1094\n",
      "Epoch 55/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 3.7529 - accuracy: 0.4620 - MSE: 0.2071 - precision_12: 0.5559 - recall_12: 0.2010 - val_loss: 4.7055 - val_accuracy: 0.3672 - val_MSE: 0.2278 - val_precision_12: 0.3684 - val_recall_12: 0.1094\n",
      "Epoch 56/80\n",
      "51/51 [==============================] - 2s 36ms/step - loss: 4.7055 - accuracy: 0.4130 - MSE: 0.2161 - precision_12: 0.5102 - recall_12: 0.1838 - val_loss: 5.0302 - val_accuracy: 0.3594 - val_MSE: 0.2319 - val_precision_12: 0.4348 - val_recall_12: 0.1562\n",
      "Epoch 57/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 4.7741 - accuracy: 0.4436 - MSE: 0.2098 - precision_12: 0.5424 - recall_12: 0.1961 - val_loss: 5.3922 - val_accuracy: 0.2812 - val_MSE: 0.2476 - val_precision_12: 0.2791 - val_recall_12: 0.0938\n",
      "Epoch 58/80\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 5.0138 - accuracy: 0.4583 - MSE: 0.2090 - precision_12: 0.5338 - recall_12: 0.1838 - val_loss: 4.8986 - val_accuracy: 0.3359 - val_MSE: 0.2355 - val_precision_12: 0.3947 - val_recall_12: 0.1172\n",
      "Epoch 59/80\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 4.6365 - accuracy: 0.4277 - MSE: 0.2139 - precision_12: 0.5201 - recall_12: 0.1740 - val_loss: 4.8443 - val_accuracy: 0.3906 - val_MSE: 0.2319 - val_precision_12: 0.4000 - val_recall_12: 0.1719\n",
      "Epoch 60/80\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 4.7207 - accuracy: 0.4559 - MSE: 0.2098 - precision_12: 0.5190 - recall_12: 0.1838 - val_loss: 4.5640 - val_accuracy: 0.3516 - val_MSE: 0.2359 - val_precision_12: 0.3922 - val_recall_12: 0.1562\n",
      "Epoch 61/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 4.7970 - accuracy: 0.4461 - MSE: 0.2038 - precision_12: 0.6107 - recall_12: 0.2096 - val_loss: 5.2457 - val_accuracy: 0.3125 - val_MSE: 0.2344 - val_precision_12: 0.3778 - val_recall_12: 0.1328\n",
      "Epoch 62/80\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 4.4686 - accuracy: 0.4571 - MSE: 0.2013 - precision_12: 0.6115 - recall_12: 0.2083 - val_loss: 4.3691 - val_accuracy: 0.3125 - val_MSE: 0.2361 - val_precision_12: 0.2821 - val_recall_12: 0.0859\n",
      "Epoch 63/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 4.1026 - accuracy: 0.4596 - MSE: 0.2095 - precision_12: 0.5571 - recall_12: 0.1912 - val_loss: 3.8636 - val_accuracy: 0.3203 - val_MSE: 0.2290 - val_precision_12: 0.4250 - val_recall_12: 0.1328\n",
      "Epoch 64/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 3.7349 - accuracy: 0.4461 - MSE: 0.2058 - precision_12: 0.5957 - recall_12: 0.2059 - val_loss: 4.0402 - val_accuracy: 0.4062 - val_MSE: 0.2229 - val_precision_12: 0.4359 - val_recall_12: 0.1328\n",
      "Epoch 65/80\n",
      "51/51 [==============================] - 2s 36ms/step - loss: 4.1304 - accuracy: 0.4363 - MSE: 0.2125 - precision_12: 0.5448 - recall_12: 0.1789 - val_loss: 4.7499 - val_accuracy: 0.4297 - val_MSE: 0.2352 - val_precision_12: 0.3469 - val_recall_12: 0.1328 4.0928 - accuracy: 0.4375 - MSE: 0.2126 - precision_12: 0.5425 - recall_12: 0.17 - ETA: 0s - loss: 4.1304 - accuracy: 0.4363 - MSE: 0.2125 - precision_12: 0.5448 - recall_12: 0.178\n",
      "Epoch 66/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 4.4363 - accuracy: 0.4289 - MSE: 0.2124 - precision_12: 0.5219 - recall_12: 0.1752 - val_loss: 4.0852 - val_accuracy: 0.4141 - val_MSE: 0.2258 - val_precision_12: 0.3902 - val_recall_12: 0.1250\n",
      "Epoch 67/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 3.6989 - accuracy: 0.4571 - MSE: 0.2025 - precision_12: 0.5912 - recall_12: 0.1985 - val_loss: 3.8832 - val_accuracy: 0.3516 - val_MSE: 0.2305 - val_precision_12: 0.4130 - val_recall_12: 0.1484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/80\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 5.1588 - accuracy: 0.4301 - MSE: 0.2113 - precision_12: 0.5182 - recall_12: 0.1740 - val_loss: 5.9076 - val_accuracy: 0.3906 - val_MSE: 0.2172 - val_precision_12: 0.5854 - val_recall_12: 0.1875\n",
      "Epoch 69/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 5.6864 - accuracy: 0.4314 - MSE: 0.2136 - precision_12: 0.5326 - recall_12: 0.1801 - val_loss: 5.6487 - val_accuracy: 0.3750 - val_MSE: 0.2352 - val_precision_12: 0.4468 - val_recall_12: 0.1641\n",
      "Epoch 70/80\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 4.8156 - accuracy: 0.4510 - MSE: 0.2104 - precision_12: 0.5441 - recall_12: 0.1740 - val_loss: 4.5905 - val_accuracy: 0.3984 - val_MSE: 0.2287 - val_precision_12: 0.3810 - val_recall_12: 0.1250\n",
      "Epoch 71/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 4.2698 - accuracy: 0.4767 - MSE: 0.2035 - precision_12: 0.6049 - recall_12: 0.2120 - val_loss: 4.6469 - val_accuracy: 0.3516 - val_MSE: 0.2369 - val_precision_12: 0.3261 - val_recall_12: 0.1172\n",
      "Epoch 72/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 4.8394 - accuracy: 0.4314 - MSE: 0.2150 - precision_12: 0.5296 - recall_12: 0.1752 - val_loss: 4.8732 - val_accuracy: 0.2578 - val_MSE: 0.2413 - val_precision_12: 0.3500 - val_recall_12: 0.1094\n",
      "Epoch 73/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 4.2967 - accuracy: 0.4534 - MSE: 0.2043 - precision_12: 0.6169 - recall_12: 0.1973 - val_loss: 4.3885 - val_accuracy: 0.3438 - val_MSE: 0.2374 - val_precision_12: 0.3030 - val_recall_12: 0.0781\n",
      "Epoch 74/80\n",
      "51/51 [==============================] - 2s 33ms/step - loss: 4.6185 - accuracy: 0.4412 - MSE: 0.2096 - precision_12: 0.5560 - recall_12: 0.1703 - val_loss: 5.0149 - val_accuracy: 0.3672 - val_MSE: 0.2360 - val_precision_12: 0.3243 - val_recall_12: 0.0938\n",
      "Epoch 75/80\n",
      "51/51 [==============================] - 2s 33ms/step - loss: 5.1427 - accuracy: 0.4583 - MSE: 0.2066 - precision_12: 0.5736 - recall_12: 0.1863 - val_loss: 5.9939 - val_accuracy: 0.4297 - val_MSE: 0.2273 - val_precision_12: 0.4074 - val_recall_12: 0.1719\n",
      "Epoch 76/80\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 5.3123 - accuracy: 0.4424 - MSE: 0.2099 - precision_12: 0.5799 - recall_12: 0.1912 - val_loss: 4.9132 - val_accuracy: 0.4531 - val_MSE: 0.2315 - val_precision_12: 0.4043 - val_recall_12: 0.1484\n",
      "Epoch 77/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 4.6222 - accuracy: 0.4596 - MSE: 0.2046 - precision_12: 0.5674 - recall_12: 0.1961 - val_loss: 4.4613 - val_accuracy: 0.3984 - val_MSE: 0.2262 - val_precision_12: 0.3684 - val_recall_12: 0.1094\n",
      "Epoch 78/80\n",
      "51/51 [==============================] - 2s 30ms/step - loss: 4.2398 - accuracy: 0.4914 - MSE: 0.2018 - precision_12: 0.6007 - recall_12: 0.2083 - val_loss: 4.5223 - val_accuracy: 0.4531 - val_MSE: 0.2321 - val_precision_12: 0.2941 - val_recall_12: 0.0781\n",
      "Epoch 79/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 4.0464 - accuracy: 0.4877 - MSE: 0.2002 - precision_12: 0.6140 - recall_12: 0.2047 - val_loss: 3.9676 - val_accuracy: 0.3672 - val_MSE: 0.2317 - val_precision_12: 0.3529 - val_recall_12: 0.0938\n",
      "Epoch 80/80\n",
      "51/51 [==============================] - 2s 31ms/step - loss: 3.6072 - accuracy: 0.4877 - MSE: 0.1994 - precision_12: 0.6176 - recall_12: 0.2059 - val_loss: 3.6125 - val_accuracy: 0.3203 - val_MSE: 0.2337 - val_precision_12: 0.3448 - val_recall_12: 0.0781\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_13 (LSTM)               (64, 32)                  772352    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (64, 32)                  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (64, 32)                  128       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (64, 3)                   99        \n",
      "=================================================================\n",
      "Total params: 772,579\n",
      "Trainable params: 772,515\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "Starting: \n",
      "{'batch_size': 64, 'epochs': 65, 'learning_rate': 1e-05, 'optimizer': 'sgd'}\n",
      "---------------------------------------------------------------------------------\n",
      "{   'activation': 'sigmoid',\n",
      "    'dropout_rate': 0.5,\n",
      "    'filters': 9,\n",
      "    'kernel_size': 3,\n",
      "    'l1_r': 0.1,\n",
      "    'l2_r': 0.1,\n",
      "    'output_layer_activation': 'softmax',\n",
      "    'padding': 'valid',\n",
      "    'start_neurons': 32}\n",
      "Epoch 1/65\n",
      " 2/12 [====>.........................] - ETA: 9s - loss: 1232.3745 - accuracy: 0.3438 - MSE: 0.3122 - precision_13: 0.3423 - recall_13: 0.2969WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0925s vs `on_train_batch_end` time: 1.8286s). Check your callbacks.\n",
      "12/12 [==============================] - 4s 334ms/step - loss: 1231.9067 - accuracy: 0.3294 - MSE: 0.3006 - precision_13: 0.3275 - recall_13: 0.2669 - val_loss: 1230.9299 - val_accuracy: 0.3125 - val_MSE: 0.2393 - val_precision_13: 0.3390 - val_recall_13: 0.1562\n",
      "Epoch 2/65\n",
      "12/12 [==============================] - 2s 126ms/step - loss: 1230.8617 - accuracy: 0.3490 - MSE: 0.2874 - precision_13: 0.3534 - recall_13: 0.2826 - val_loss: 1229.9441 - val_accuracy: 0.3125 - val_MSE: 0.2386 - val_precision_13: 0.3390 - val_recall_13: 0.1562\n",
      "Epoch 3/65\n",
      "12/12 [==============================] - 2s 127ms/step - loss: 1229.8673 - accuracy: 0.3451 - MSE: 0.2884 - precision_13: 0.3575 - recall_13: 0.2826 - val_loss: 1228.9594 - val_accuracy: 0.3203 - val_MSE: 0.2379 - val_precision_13: 0.3448 - val_recall_13: 0.1562\n",
      "Epoch 4/65\n",
      "12/12 [==============================] - 1s 124ms/step - loss: 1228.8533 - accuracy: 0.3372 - MSE: 0.2857 - precision_13: 0.3328 - recall_13: 0.2669 - val_loss: 1227.9768 - val_accuracy: 0.3359 - val_MSE: 0.2375 - val_precision_13: 0.3684 - val_recall_13: 0.1641\n",
      "Epoch 5/65\n",
      "12/12 [==============================] - 2s 126ms/step - loss: 1227.9608 - accuracy: 0.3464 - MSE: 0.2982 - precision_13: 0.3418 - recall_13: 0.2812 - val_loss: 1226.9958 - val_accuracy: 0.3359 - val_MSE: 0.2373 - val_precision_13: 0.3621 - val_recall_13: 0.1641\n",
      "Epoch 6/65\n",
      "12/12 [==============================] - 2s 127ms/step - loss: 1226.9192 - accuracy: 0.3307 - MSE: 0.2879 - precision_13: 0.3291 - recall_13: 0.2669 - val_loss: 1226.0161 - val_accuracy: 0.3359 - val_MSE: 0.2372 - val_precision_13: 0.3729 - val_recall_13: 0.1719\n",
      "Epoch 7/65\n",
      "12/12 [==============================] - 2s 154ms/step - loss: 1225.9594 - accuracy: 0.3464 - MSE: 0.2886 - precision_13: 0.3484 - recall_13: 0.2904 - val_loss: 1225.0370 - val_accuracy: 0.3516 - val_MSE: 0.2372 - val_precision_13: 0.3710 - val_recall_13: 0.1797\n",
      "Epoch 8/65\n",
      "12/12 [==============================] - 2s 128ms/step - loss: 1224.9995 - accuracy: 0.3385 - MSE: 0.2941 - precision_13: 0.3402 - recall_13: 0.2786 - val_loss: 1224.0596 - val_accuracy: 0.3438 - val_MSE: 0.2373 - val_precision_13: 0.3770 - val_recall_13: 0.1797\n",
      "Epoch 9/65\n",
      "12/12 [==============================] - 2s 127ms/step - loss: 1223.9612 - accuracy: 0.3490 - MSE: 0.2830 - precision_13: 0.3581 - recall_13: 0.2891 - val_loss: 1223.0828 - val_accuracy: 0.3594 - val_MSE: 0.2374 - val_precision_13: 0.3607 - val_recall_13: 0.1719\n",
      "Epoch 10/65\n",
      "12/12 [==============================] - 2s 127ms/step - loss: 1223.0078 - accuracy: 0.3411 - MSE: 0.2882 - precision_13: 0.3576 - recall_13: 0.2878 - val_loss: 1222.1074 - val_accuracy: 0.3672 - val_MSE: 0.2378 - val_precision_13: 0.3667 - val_recall_13: 0.1719\n",
      "Epoch 11/65\n",
      "12/12 [==============================] - 2s 128ms/step - loss: 1221.9882 - accuracy: 0.3633 - MSE: 0.2804 - precision_13: 0.3657 - recall_13: 0.2943 - val_loss: 1221.1328 - val_accuracy: 0.3594 - val_MSE: 0.2381 - val_precision_13: 0.3607 - val_recall_13: 0.1719\n",
      "Epoch 12/65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 2s 126ms/step - loss: 1221.0863 - accuracy: 0.3281 - MSE: 0.2936 - precision_13: 0.3312 - recall_13: 0.2643 - val_loss: 1220.1584 - val_accuracy: 0.3594 - val_MSE: 0.2385 - val_precision_13: 0.3810 - val_recall_13: 0.1875\n",
      "Epoch 13/65\n",
      "12/12 [==============================] - 2s 128ms/step - loss: 1220.0613 - accuracy: 0.3438 - MSE: 0.2862 - precision_13: 0.3495 - recall_13: 0.2812 - val_loss: 1219.1848 - val_accuracy: 0.3594 - val_MSE: 0.2389 - val_precision_13: 0.3810 - val_recall_13: 0.1875\n",
      "Epoch 14/65\n",
      "12/12 [==============================] - 2s 130ms/step - loss: 1219.1077 - accuracy: 0.3568 - MSE: 0.2850 - precision_13: 0.3728 - recall_13: 0.3073 - val_loss: 1218.2115 - val_accuracy: 0.3594 - val_MSE: 0.2393 - val_precision_13: 0.4000 - val_recall_13: 0.2031\n",
      "Epoch 15/65\n",
      "12/12 [==============================] - 2s 127ms/step - loss: 1218.1969 - accuracy: 0.3294 - MSE: 0.2962 - precision_13: 0.3241 - recall_13: 0.2604 - val_loss: 1217.2390 - val_accuracy: 0.3672 - val_MSE: 0.2397 - val_precision_13: 0.3939 - val_recall_13: 0.2031\n",
      "Epoch 16/65\n",
      "12/12 [==============================] - 2s 142ms/step - loss: 1217.1117 - accuracy: 0.3529 - MSE: 0.2823 - precision_13: 0.3419 - recall_13: 0.2773 - val_loss: 1216.2675 - val_accuracy: 0.3594 - val_MSE: 0.2402 - val_precision_13: 0.3939 - val_recall_13: 0.2031\n",
      "Epoch 17/65\n",
      "12/12 [==============================] - 2s 133ms/step - loss: 1216.1754 - accuracy: 0.3359 - MSE: 0.2875 - precision_13: 0.3393 - recall_13: 0.2695 - val_loss: 1215.2959 - val_accuracy: 0.3594 - val_MSE: 0.2407 - val_precision_13: 0.3939 - val_recall_13: 0.2031\n",
      "Epoch 18/65\n",
      "12/12 [==============================] - 2s 127ms/step - loss: 1215.2511 - accuracy: 0.3268 - MSE: 0.2968 - precision_13: 0.3208 - recall_13: 0.2552 - val_loss: 1214.3241 - val_accuracy: 0.3594 - val_MSE: 0.2411 - val_precision_13: 0.3662 - val_recall_13: 0.2031\n",
      "Epoch 19/65\n",
      "12/12 [==============================] - 2s 126ms/step - loss: 1214.2118 - accuracy: 0.3607 - MSE: 0.2813 - precision_13: 0.3724 - recall_13: 0.2982 - val_loss: 1213.3523 - val_accuracy: 0.3594 - val_MSE: 0.2414 - val_precision_13: 0.3803 - val_recall_13: 0.2109\n",
      "Epoch 20/65\n",
      "12/12 [==============================] - 2s 127ms/step - loss: 1213.2174 - accuracy: 0.3529 - MSE: 0.2822 - precision_13: 0.3555 - recall_13: 0.2852 - val_loss: 1212.3820 - val_accuracy: 0.3594 - val_MSE: 0.2418 - val_precision_13: 0.3836 - val_recall_13: 0.2188\n",
      "Epoch 21/65\n",
      "12/12 [==============================] - 2s 128ms/step - loss: 1212.2960 - accuracy: 0.3529 - MSE: 0.2896 - precision_13: 0.3575 - recall_13: 0.2826 - val_loss: 1211.4116 - val_accuracy: 0.3516 - val_MSE: 0.2422 - val_precision_13: 0.3919 - val_recall_13: 0.2266\n",
      "Epoch 22/65\n",
      "12/12 [==============================] - 2s 125ms/step - loss: 1211.2755 - accuracy: 0.3529 - MSE: 0.2819 - precision_13: 0.3507 - recall_13: 0.2799 - val_loss: 1210.4417 - val_accuracy: 0.3516 - val_MSE: 0.2426 - val_precision_13: 0.4079 - val_recall_13: 0.2422\n",
      "Epoch 23/65\n",
      "12/12 [==============================] - 2s 127ms/step - loss: 1210.3656 - accuracy: 0.3516 - MSE: 0.2927 - precision_13: 0.3402 - recall_13: 0.2786 - val_loss: 1209.4714 - val_accuracy: 0.3516 - val_MSE: 0.2429 - val_precision_13: 0.4026 - val_recall_13: 0.2422\n",
      "Epoch 24/65\n",
      "12/12 [==============================] - 2s 127ms/step - loss: 1209.3199 - accuracy: 0.3763 - MSE: 0.2778 - precision_13: 0.3814 - recall_13: 0.3099 - val_loss: 1208.5020 - val_accuracy: 0.3516 - val_MSE: 0.2432 - val_precision_13: 0.4051 - val_recall_13: 0.2500\n",
      "Epoch 25/65\n",
      "12/12 [==============================] - 2s 128ms/step - loss: 1208.4196 - accuracy: 0.3411 - MSE: 0.2883 - precision_13: 0.3544 - recall_13: 0.2852 - val_loss: 1207.5325 - val_accuracy: 0.3516 - val_MSE: 0.2434 - val_precision_13: 0.4051 - val_recall_13: 0.2500\n",
      "Epoch 26/65\n",
      "12/12 [==============================] - 2s 155ms/step - loss: 1207.4128 - accuracy: 0.3555 - MSE: 0.2852 - precision_13: 0.3500 - recall_13: 0.2826 - val_loss: 1206.5635 - val_accuracy: 0.3672 - val_MSE: 0.2437 - val_precision_13: 0.4074 - val_recall_13: 0.2578\n",
      "Epoch 27/65\n",
      "12/12 [==============================] - 2s 127ms/step - loss: 1206.4237 - accuracy: 0.3893 - MSE: 0.2794 - precision_13: 0.3894 - recall_13: 0.3164 - val_loss: 1205.5947 - val_accuracy: 0.3672 - val_MSE: 0.2439 - val_precision_13: 0.4024 - val_recall_13: 0.2578\n",
      "Epoch 28/65\n",
      "12/12 [==============================] - 2s 133ms/step - loss: 1205.4889 - accuracy: 0.3333 - MSE: 0.2899 - precision_13: 0.3402 - recall_13: 0.2799 - val_loss: 1204.6260 - val_accuracy: 0.3672 - val_MSE: 0.2441 - val_precision_13: 0.4024 - val_recall_13: 0.2578\n",
      "Epoch 29/65\n",
      "12/12 [==============================] - 2s 133ms/step - loss: 1204.4532 - accuracy: 0.3581 - MSE: 0.2789 - precision_13: 0.3544 - recall_13: 0.2917 - val_loss: 1203.6576 - val_accuracy: 0.3672 - val_MSE: 0.2442 - val_precision_13: 0.4024 - val_recall_13: 0.2578\n",
      "Epoch 30/65\n",
      "12/12 [==============================] - 2s 129ms/step - loss: 1203.5187 - accuracy: 0.3633 - MSE: 0.2840 - precision_13: 0.3670 - recall_13: 0.2930 - val_loss: 1202.6898 - val_accuracy: 0.3672 - val_MSE: 0.2444 - val_precision_13: 0.4024 - val_recall_13: 0.2578\n",
      "Epoch 31/65\n",
      "12/12 [==============================] - 2s 131ms/step - loss: 1202.5999 - accuracy: 0.3516 - MSE: 0.2915 - precision_13: 0.3460 - recall_13: 0.2734 - val_loss: 1201.7217 - val_accuracy: 0.3672 - val_MSE: 0.2445 - val_precision_13: 0.4096 - val_recall_13: 0.2656\n",
      "Epoch 32/65\n",
      "12/12 [==============================] - 2s 126ms/step - loss: 1201.5958 - accuracy: 0.3320 - MSE: 0.2897 - precision_13: 0.3452 - recall_13: 0.2786 - val_loss: 1200.7542 - val_accuracy: 0.3672 - val_MSE: 0.2446 - val_precision_13: 0.4048 - val_recall_13: 0.2656\n",
      "Epoch 33/65\n",
      "12/12 [==============================] - 2s 127ms/step - loss: 1200.6083 - accuracy: 0.3737 - MSE: 0.2828 - precision_13: 0.3777 - recall_13: 0.2956 - val_loss: 1199.7872 - val_accuracy: 0.3672 - val_MSE: 0.2447 - val_precision_13: 0.4048 - val_recall_13: 0.2656\n",
      "Epoch 34/65\n",
      "12/12 [==============================] - 1s 123ms/step - loss: 1199.6417 - accuracy: 0.3633 - MSE: 0.2841 - precision_13: 0.3555 - recall_13: 0.2930 - val_loss: 1198.8208 - val_accuracy: 0.3672 - val_MSE: 0.2448 - val_precision_13: 0.4048 - val_recall_13: 0.2656\n",
      "Epoch 35/65\n",
      "12/12 [==============================] - 2s 150ms/step - loss: 1198.6937 - accuracy: 0.3672 - MSE: 0.2841 - precision_13: 0.3601 - recall_13: 0.2865 - val_loss: 1197.8540 - val_accuracy: 0.3672 - val_MSE: 0.2449 - val_precision_13: 0.4048 - val_recall_13: 0.2656\n",
      "Epoch 36/65\n",
      "12/12 [==============================] - 2s 135ms/step - loss: 1197.7500 - accuracy: 0.3542 - MSE: 0.2880 - precision_13: 0.3567 - recall_13: 0.2917 - val_loss: 1196.8879 - val_accuracy: 0.3672 - val_MSE: 0.2450 - val_precision_13: 0.4000 - val_recall_13: 0.2656\n",
      "Epoch 37/65\n",
      "12/12 [==============================] - 1s 124ms/step - loss: 1196.7510 - accuracy: 0.3555 - MSE: 0.2821 - precision_13: 0.3629 - recall_13: 0.2878 - val_loss: 1195.9224 - val_accuracy: 0.3594 - val_MSE: 0.2451 - val_precision_13: 0.4048 - val_recall_13: 0.2656\n",
      "Epoch 38/65\n",
      "12/12 [==============================] - 2s 127ms/step - loss: 1195.7429 - accuracy: 0.3672 - MSE: 0.2773 - precision_13: 0.3712 - recall_13: 0.3021 - val_loss: 1194.9568 - val_accuracy: 0.3594 - val_MSE: 0.2451 - val_precision_13: 0.4048 - val_recall_13: 0.2656\n",
      "Epoch 39/65\n",
      "12/12 [==============================] - 2s 126ms/step - loss: 1194.7909 - accuracy: 0.3542 - MSE: 0.2806 - precision_13: 0.3560 - recall_13: 0.2865 - val_loss: 1193.9917 - val_accuracy: 0.3594 - val_MSE: 0.2451 - val_precision_13: 0.4048 - val_recall_13: 0.2656\n",
      "Epoch 40/65\n",
      "12/12 [==============================] - 2s 126ms/step - loss: 1193.8348 - accuracy: 0.3607 - MSE: 0.2832 - precision_13: 0.3578 - recall_13: 0.2917 - val_loss: 1193.0264 - val_accuracy: 0.3594 - val_MSE: 0.2451 - val_precision_13: 0.4048 - val_recall_13: 0.2656\n",
      "Epoch 41/65\n",
      "12/12 [==============================] - 2s 130ms/step - loss: 1192.8971 - accuracy: 0.3451 - MSE: 0.2871 - precision_13: 0.3503 - recall_13: 0.2865 - val_loss: 1192.0619 - val_accuracy: 0.3594 - val_MSE: 0.2451 - val_precision_13: 0.4048 - val_recall_13: 0.2656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/65\n",
      "12/12 [==============================] - 2s 128ms/step - loss: 1191.8981 - accuracy: 0.3516 - MSE: 0.2828 - precision_13: 0.3590 - recall_13: 0.2852 - val_loss: 1191.0974 - val_accuracy: 0.3516 - val_MSE: 0.2451 - val_precision_13: 0.4000 - val_recall_13: 0.2656\n",
      "Epoch 43/65\n",
      "12/12 [==============================] - 2s 129ms/step - loss: 1190.9403 - accuracy: 0.3789 - MSE: 0.2769 - precision_13: 0.3855 - recall_13: 0.3047 - val_loss: 1190.1338 - val_accuracy: 0.3594 - val_MSE: 0.2451 - val_precision_13: 0.4000 - val_recall_13: 0.2656\n",
      "Epoch 44/65\n",
      "12/12 [==============================] - 2s 131ms/step - loss: 1189.9825 - accuracy: 0.3477 - MSE: 0.2831 - precision_13: 0.3613 - recall_13: 0.2917 - val_loss: 1189.1709 - val_accuracy: 0.3672 - val_MSE: 0.2451 - val_precision_13: 0.4000 - val_recall_13: 0.2656\n",
      "Epoch 45/65\n",
      "12/12 [==============================] - 2s 172ms/step - loss: 1189.1014 - accuracy: 0.3268 - MSE: 0.2937 - precision_13: 0.3339 - recall_13: 0.2786 - val_loss: 1188.2079 - val_accuracy: 0.3594 - val_MSE: 0.2452 - val_precision_13: 0.4000 - val_recall_13: 0.2656\n",
      "Epoch 46/65\n",
      "12/12 [==============================] - 2s 127ms/step - loss: 1188.0582 - accuracy: 0.3516 - MSE: 0.2867 - precision_13: 0.3350 - recall_13: 0.2604 - val_loss: 1187.2451 - val_accuracy: 0.3594 - val_MSE: 0.2451 - val_precision_13: 0.4000 - val_recall_13: 0.2656\n",
      "Epoch 47/65\n",
      "12/12 [==============================] - 1s 125ms/step - loss: 1187.0587 - accuracy: 0.3685 - MSE: 0.2767 - precision_13: 0.3687 - recall_13: 0.3034 - val_loss: 1186.2837 - val_accuracy: 0.3594 - val_MSE: 0.2452 - val_precision_13: 0.4048 - val_recall_13: 0.2656\n",
      "Epoch 48/65\n",
      "12/12 [==============================] - 2s 130ms/step - loss: 1186.1044 - accuracy: 0.3359 - MSE: 0.2829 - precision_13: 0.3279 - recall_13: 0.2630 - val_loss: 1185.3235 - val_accuracy: 0.3594 - val_MSE: 0.2456 - val_precision_13: 0.4000 - val_recall_13: 0.2656\n",
      "Epoch 49/65\n",
      "12/12 [==============================] - 2s 127ms/step - loss: 1185.2341 - accuracy: 0.3398 - MSE: 0.2915 - precision_13: 0.3274 - recall_13: 0.2617 - val_loss: 1184.3628 - val_accuracy: 0.3594 - val_MSE: 0.2457 - val_precision_13: 0.4000 - val_recall_13: 0.2656\n",
      "Epoch 50/65\n",
      "12/12 [==============================] - 2s 127ms/step - loss: 1184.1980 - accuracy: 0.3398 - MSE: 0.2862 - precision_13: 0.3431 - recall_13: 0.2734 - val_loss: 1183.4021 - val_accuracy: 0.3594 - val_MSE: 0.2458 - val_precision_13: 0.3953 - val_recall_13: 0.2656\n",
      "Epoch 51/65\n",
      "12/12 [==============================] - 2s 127ms/step - loss: 1183.2003 - accuracy: 0.3763 - MSE: 0.2731 - precision_13: 0.3965 - recall_13: 0.3268 - val_loss: 1182.4414 - val_accuracy: 0.3672 - val_MSE: 0.2459 - val_precision_13: 0.4000 - val_recall_13: 0.2656\n",
      "Epoch 52/65\n",
      "12/12 [==============================] - 2s 130ms/step - loss: 1182.2926 - accuracy: 0.3503 - MSE: 0.2812 - precision_13: 0.3695 - recall_13: 0.2930 - val_loss: 1181.4812 - val_accuracy: 0.3672 - val_MSE: 0.2458 - val_precision_13: 0.4000 - val_recall_13: 0.2656\n",
      "Epoch 53/65\n",
      "12/12 [==============================] - 2s 127ms/step - loss: 1181.3588 - accuracy: 0.3542 - MSE: 0.2888 - precision_13: 0.3484 - recall_13: 0.2904 - val_loss: 1180.5211 - val_accuracy: 0.3672 - val_MSE: 0.2458 - val_precision_13: 0.3953 - val_recall_13: 0.2656\n",
      "Epoch 54/65\n",
      "12/12 [==============================] - 2s 152ms/step - loss: 1180.3328 - accuracy: 0.3594 - MSE: 0.2762 - precision_13: 0.3760 - recall_13: 0.3021 - val_loss: 1179.5620 - val_accuracy: 0.3672 - val_MSE: 0.2459 - val_precision_13: 0.3953 - val_recall_13: 0.2656\n",
      "Epoch 55/65\n",
      "12/12 [==============================] - 2s 128ms/step - loss: 1179.4011 - accuracy: 0.3711 - MSE: 0.2791 - precision_13: 0.3825 - recall_13: 0.3138 - val_loss: 1178.6033 - val_accuracy: 0.3672 - val_MSE: 0.2459 - val_precision_13: 0.3882 - val_recall_13: 0.2578\n",
      "Epoch 56/65\n",
      "12/12 [==============================] - 2s 128ms/step - loss: 1178.4005 - accuracy: 0.3711 - MSE: 0.2727 - precision_13: 0.3790 - recall_13: 0.2956 - val_loss: 1177.6443 - val_accuracy: 0.3672 - val_MSE: 0.2459 - val_precision_13: 0.3882 - val_recall_13: 0.2578\n",
      "Epoch 57/65\n",
      "12/12 [==============================] - 2s 126ms/step - loss: 1177.4375 - accuracy: 0.3854 - MSE: 0.2731 - precision_13: 0.3874 - recall_13: 0.3112 - val_loss: 1176.6858 - val_accuracy: 0.3672 - val_MSE: 0.2459 - val_precision_13: 0.3882 - val_recall_13: 0.2578\n",
      "Epoch 58/65\n",
      "12/12 [==============================] - 2s 127ms/step - loss: 1176.4800 - accuracy: 0.3737 - MSE: 0.2721 - precision_13: 0.3754 - recall_13: 0.3099 - val_loss: 1175.7279 - val_accuracy: 0.3672 - val_MSE: 0.2459 - val_precision_13: 0.3882 - val_recall_13: 0.2578\n",
      "Epoch 59/65\n",
      "12/12 [==============================] - 2s 126ms/step - loss: 1175.5253 - accuracy: 0.3802 - MSE: 0.2719 - precision_13: 0.3939 - recall_13: 0.3190 - val_loss: 1174.7705 - val_accuracy: 0.3672 - val_MSE: 0.2459 - val_precision_13: 0.3882 - val_recall_13: 0.2578\n",
      "Epoch 60/65\n",
      "12/12 [==============================] - 2s 126ms/step - loss: 1174.6364 - accuracy: 0.3424 - MSE: 0.2866 - precision_13: 0.3478 - recall_13: 0.2721 - val_loss: 1173.8138 - val_accuracy: 0.3672 - val_MSE: 0.2460 - val_precision_13: 0.3882 - val_recall_13: 0.2578\n",
      "Epoch 61/65\n",
      "12/12 [==============================] - 2s 126ms/step - loss: 1173.6735 - accuracy: 0.3464 - MSE: 0.2870 - precision_13: 0.3508 - recall_13: 0.2695 - val_loss: 1172.8571 - val_accuracy: 0.3672 - val_MSE: 0.2460 - val_precision_13: 0.3882 - val_recall_13: 0.2578\n",
      "Epoch 62/65\n",
      "12/12 [==============================] - 2s 128ms/step - loss: 1172.6814 - accuracy: 0.3542 - MSE: 0.2781 - precision_13: 0.3679 - recall_13: 0.2956 - val_loss: 1171.9006 - val_accuracy: 0.3672 - val_MSE: 0.2460 - val_precision_13: 0.3882 - val_recall_13: 0.2578172.6814 - accuracy: 0.3542 - MSE: 0.2781 - precision_13: 0.3679 - recall_13: 0.29\n",
      "Epoch 63/65\n",
      "12/12 [==============================] - 2s 142ms/step - loss: 1171.7208 - accuracy: 0.3724 - MSE: 0.2756 - precision_13: 0.3746 - recall_13: 0.3073 - val_loss: 1170.9441 - val_accuracy: 0.3594 - val_MSE: 0.2459 - val_precision_13: 0.3882 - val_recall_13: 0.2578\n",
      "Epoch 64/65\n",
      "12/12 [==============================] - 2s 139ms/step - loss: 1170.7539 - accuracy: 0.3802 - MSE: 0.2706 - precision_13: 0.3762 - recall_13: 0.2969 - val_loss: 1169.9888 - val_accuracy: 0.3672 - val_MSE: 0.2459 - val_precision_13: 0.3837 - val_recall_13: 0.2578\n",
      "Epoch 65/65\n",
      "12/12 [==============================] - 1s 124ms/step - loss: 1169.8737 - accuracy: 0.3411 - MSE: 0.2885 - precision_13: 0.3534 - recall_13: 0.2904 - val_loss: 1169.0339 - val_accuracy: 0.3672 - val_MSE: 0.2459 - val_precision_13: 0.3837 - val_recall_13: 0.2578\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_14 (LSTM)               (32, 16)                  385152    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (32, 16)                  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (32, 16)                  64        \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (32, 3)                   51        \n",
      "=================================================================\n",
      "Total params: 385,267\n",
      "Trainable params: 385,235\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n",
      "Starting: \n",
      "{'batch_size': 32, 'epochs': 65, 'learning_rate': 0.001, 'optimizer': 'rmsprop'}\n",
      "---------------------------------------------------------------------------------\n",
      "{   'activation': 'relu',\n",
      "    'dropout_rate': 0,\n",
      "    'filters': 15,\n",
      "    'kernel_size': 3,\n",
      "    'l1_r': 0.1,\n",
      "    'l2_r': 0.001,\n",
      "    'output_layer_activation': 'softmax',\n",
      "    'padding': 'valid',\n",
      "    'start_neurons': 16}\n",
      "Epoch 1/65\n",
      " 2/25 [=>............................] - ETA: 21s - loss: 625.9591 - accuracy: 0.3125 - MSE: 0.2939 - precision_14: 0.2683 - recall_14: 0.1719WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0440s vs `on_train_batch_end` time: 1.8043s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 4s 175ms/step - loss: 481.5145 - accuracy: 0.3650 - MSE: 0.2609 - precision_14: 0.3525 - recall_14: 0.2225 - val_loss: 568.5548 - val_accuracy: 0.3125 - val_MSE: 0.2724 - val_precision_14: 0.2105 - val_recall_14: 0.093881.5145 - accuracy: 0.3650 - MSE: 0.2609 - precision_14: 0.3525 - recall_14: 0.222\n",
      "Epoch 2/65\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 604.8978 - accuracy: 0.3650 - MSE: 0.2540 - precision_14: 0.3594 - recall_14: 0.2300 - val_loss: 245.3727 - val_accuracy: 0.4297 - val_MSE: 0.2317 - val_precision_14: 0.3684 - val_recall_14: 0.10944151 - accuracy: 0.3688 - MSE: 0.2560 - precision_14: 0.3428 - recall_1\n",
      "Epoch 3/65\n",
      "25/25 [==============================] - 2s 66ms/step - loss: 350.0264 - accuracy: 0.3762 - MSE: 0.2495 - precision_14: 0.3924 - recall_14: 0.2463 - val_loss: 330.4926 - val_accuracy: 0.3828 - val_MSE: 0.2423 - val_precision_14: 0.3478 - val_recall_14: 0.0625\n",
      "Epoch 4/65\n",
      "25/25 [==============================] - 2s 65ms/step - loss: 355.8079 - accuracy: 0.3750 - MSE: 0.2497 - precision_14: 0.3836 - recall_14: 0.2225 - val_loss: 262.2870 - val_accuracy: 0.3984 - val_MSE: 0.2246 - val_precision_14: 0.4286 - val_recall_14: 0.0703\n",
      "Epoch 5/65\n",
      "25/25 [==============================] - 2s 65ms/step - loss: 295.2758 - accuracy: 0.4075 - MSE: 0.2391 - precision_14: 0.4361 - recall_14: 0.2475 - val_loss: 237.8557 - val_accuracy: 0.4453 - val_MSE: 0.2174 - val_precision_14: 0.5833 - val_recall_14: 0.0547\n",
      "Epoch 6/65\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 162.5031 - accuracy: 0.3638 - MSE: 0.2441 - precision_14: 0.3902 - recall_14: 0.2200 - val_loss: 184.8295 - val_accuracy: 0.4688 - val_MSE: 0.2176 - val_precision_14: 0.5000 - val_recall_14: 0.0391\n",
      "Epoch 7/65\n",
      "25/25 [==============================] - 2s 66ms/step - loss: 162.1306 - accuracy: 0.4100 - MSE: 0.2354 - precision_14: 0.4455 - recall_14: 0.2300 - val_loss: 155.3474 - val_accuracy: 0.3906 - val_MSE: 0.2182 - val_precision_14: 0.6000 - val_recall_14: 0.0469\n",
      "Epoch 8/65\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 134.2463 - accuracy: 0.4175 - MSE: 0.2316 - precision_14: 0.4612 - recall_14: 0.2375 - val_loss: 224.8398 - val_accuracy: 0.3828 - val_MSE: 0.2278 - val_precision_14: 0.4286 - val_recall_14: 0.0234\n",
      "Epoch 9/65\n",
      "25/25 [==============================] - 2s 65ms/step - loss: 132.9428 - accuracy: 0.4013 - MSE: 0.2315 - precision_14: 0.4672 - recall_14: 0.2313 - val_loss: 254.6649 - val_accuracy: 0.3828 - val_MSE: 0.2224 - val_precision_14: 0.4000 - val_recall_14: 0.0156\n",
      "Epoch 10/65\n",
      "25/25 [==============================] - 2s 78ms/step - loss: 130.1944 - accuracy: 0.4162 - MSE: 0.2288 - precision_14: 0.4538 - recall_14: 0.2087 - val_loss: 126.3076 - val_accuracy: 0.4375 - val_MSE: 0.2195 - val_precision_14: 0.3333 - val_recall_14: 0.0078\n",
      "Epoch 11/65\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 177.7024 - accuracy: 0.3850 - MSE: 0.2352 - precision_14: 0.3824 - recall_14: 0.1625 - val_loss: 91.2402 - val_accuracy: 0.3984 - val_MSE: 0.2176 - val_precision_14: 0.5000 - val_recall_14: 0.0156\n",
      "Epoch 12/65\n",
      "25/25 [==============================] - 2s 65ms/step - loss: 106.5866 - accuracy: 0.4137 - MSE: 0.2293 - precision_14: 0.4290 - recall_14: 0.1737 - val_loss: 82.0396 - val_accuracy: 0.4531 - val_MSE: 0.2208 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 13/65\n",
      "25/25 [==============================] - 2s 65ms/step - loss: 78.9382 - accuracy: 0.3900 - MSE: 0.2297 - precision_14: 0.4379 - recall_14: 0.1675 - val_loss: 80.9077 - val_accuracy: 0.4375 - val_MSE: 0.2192 - val_precision_14: 0.5000 - val_recall_14: 0.0156\n",
      "Epoch 14/65\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 78.3819 - accuracy: 0.4050 - MSE: 0.2327 - precision_14: 0.4241 - recall_14: 0.1713 - val_loss: 79.9429 - val_accuracy: 0.3516 - val_MSE: 0.2269 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 15/65\n",
      "25/25 [==============================] - 2s 65ms/step - loss: 91.1643 - accuracy: 0.3812 - MSE: 0.2323 - precision_14: 0.4074 - recall_14: 0.1375 - val_loss: 116.5255 - val_accuracy: 0.4219 - val_MSE: 0.2160 - val_precision_14: 1.0000 - val_recall_14: 0.0312\n",
      "Epoch 16/65\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 123.0885 - accuracy: 0.4000 - MSE: 0.2227 - precision_14: 0.4484 - recall_14: 0.1412 - val_loss: 76.0325 - val_accuracy: 0.4297 - val_MSE: 0.2275 - val_precision_14: 0.4000 - val_recall_14: 0.0156\n",
      "Epoch 17/65\n",
      "25/25 [==============================] - 2s 66ms/step - loss: 60.1283 - accuracy: 0.3825 - MSE: 0.2280 - precision_14: 0.4369 - recall_14: 0.1213 - val_loss: 60.0151 - val_accuracy: 0.4375 - val_MSE: 0.2169 - val_precision_14: 0.5000 - val_recall_14: 0.0078\n",
      "Epoch 18/65\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 56.8091 - accuracy: 0.3750 - MSE: 0.2265 - precision_14: 0.4336 - recall_14: 0.1225 - val_loss: 60.9178 - val_accuracy: 0.3750 - val_MSE: 0.2205 - val_precision_14: 0.2500 - val_recall_14: 0.0078\n",
      "Epoch 19/65\n",
      "25/25 [==============================] - 2s 79ms/step - loss: 58.2419 - accuracy: 0.3750 - MSE: 0.2283 - precision_14: 0.4272 - recall_14: 0.1138 - val_loss: 53.0223 - val_accuracy: 0.3984 - val_MSE: 0.2249 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 20/65\n",
      "25/25 [==============================] - 2s 65ms/step - loss: 69.7662 - accuracy: 0.3725 - MSE: 0.2265 - precision_14: 0.3736 - recall_14: 0.0850 - val_loss: 52.9926 - val_accuracy: 0.3828 - val_MSE: 0.2187 - val_precision_14: 0.5000 - val_recall_14: 0.0078\n",
      "Epoch 21/65\n",
      "25/25 [==============================] - 2s 65ms/step - loss: 56.8573 - accuracy: 0.3963 - MSE: 0.2261 - precision_14: 0.4271 - recall_14: 0.1063 - val_loss: 56.3055 - val_accuracy: 0.4297 - val_MSE: 0.2209 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 22/65\n",
      "25/25 [==============================] - 2s 65ms/step - loss: 52.6205 - accuracy: 0.3775 - MSE: 0.2289 - precision_14: 0.3520 - recall_14: 0.0787 - val_loss: 56.5309 - val_accuracy: 0.4219 - val_MSE: 0.2172 - val_precision_14: 1.0000 - val_recall_14: 0.0156\n",
      "Epoch 23/65\n",
      "25/25 [==============================] - 2s 66ms/step - loss: 60.1659 - accuracy: 0.3900 - MSE: 0.2236 - precision_14: 0.4304 - recall_14: 0.0850 - val_loss: 68.4403 - val_accuracy: 0.3828 - val_MSE: 0.2210 - val_precision_14: 0.8000 - val_recall_14: 0.0312\n",
      "Epoch 24/65\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 275.9749 - accuracy: 0.3762 - MSE: 0.2241 - precision_14: 0.3889 - recall_14: 0.0613 - val_loss: 63.6608 - val_accuracy: 0.3906 - val_MSE: 0.2182 - val_precision_14: 1.0000 - val_recall_14: 0.0078\n",
      "Epoch 25/65\n",
      "25/25 [==============================] - 2s 65ms/step - loss: 132.4757 - accuracy: 0.3938 - MSE: 0.2218 - precision_14: 0.4508 - recall_14: 0.0688 - val_loss: 57.2444 - val_accuracy: 0.3906 - val_MSE: 0.2195 - val_precision_14: 0.6667 - val_recall_14: 0.0156\n",
      "Epoch 26/65\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 61.4730 - accuracy: 0.3988 - MSE: 0.2225 - precision_14: 0.4537 - recall_14: 0.0613 - val_loss: 58.1086 - val_accuracy: 0.3984 - val_MSE: 0.2214 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00- accuracy: 0.4013 - MSE: 0.2228 - precision_14: 0.4512 - recal\n",
      "Epoch 27/65\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 64.1506 - accuracy: 0.3725 - MSE: 0.2262 - precision_14: 0.4565 - recall_14: 0.0525 - val_loss: 57.3805 - val_accuracy: 0.4062 - val_MSE: 0.2197 - val_precision_14: 0.5000 - val_recall_14: 0.0078\n",
      "Epoch 28/65\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 83.7232 - accuracy: 0.3925 - MSE: 0.2217 - precision_14: 0.4607 - recall_14: 0.0512 - val_loss: 76.3037 - val_accuracy: 0.3984 - val_MSE: 0.2167 - val_precision_14: 1.0000 - val_recall_14: 0.0156uracy: 0.3995 - MSE: 0.2210 - precision_14: 0.4750 - recall_14: \n",
      "Epoch 29/65\n",
      "25/25 [==============================] - 2s 66ms/step - loss: 93.2506 - accuracy: 0.3775 - MSE: 0.2223 - precision_14: 0.3855 - recall_14: 0.0400 - val_loss: 58.9820 - val_accuracy: 0.3906 - val_MSE: 0.2183 - val_precision_14: 1.0000 - val_recall_14: 0.0078\n",
      "Epoch 30/65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 2s 65ms/step - loss: 130.0204 - accuracy: 0.3700 - MSE: 0.2246 - precision_14: 0.3951 - recall_14: 0.0400 - val_loss: 55.9880 - val_accuracy: 0.4062 - val_MSE: 0.2176 - val_precision_14: 1.0000 - val_recall_14: 0.0156\n",
      "Epoch 31/65\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 56.6426 - accuracy: 0.3887 - MSE: 0.2224 - precision_14: 0.4444 - recall_14: 0.0350 - val_loss: 57.9795 - val_accuracy: 0.4141 - val_MSE: 0.2182 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 32/65\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 62.9451 - accuracy: 0.3688 - MSE: 0.2235 - precision_14: 0.3396 - recall_14: 0.0225 - val_loss: 75.5267 - val_accuracy: 0.4062 - val_MSE: 0.2169 - val_precision_14: 1.0000 - val_recall_14: 0.0156\n",
      "Epoch 33/65\n",
      "25/25 [==============================] - 2s 62ms/step - loss: 67.4552 - accuracy: 0.3850 - MSE: 0.2220 - precision_14: 0.3793 - recall_14: 0.0275 - val_loss: 63.7852 - val_accuracy: 0.4219 - val_MSE: 0.2184 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 34/65\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 60.8079 - accuracy: 0.3688 - MSE: 0.2223 - precision_14: 0.4815 - recall_14: 0.0325 - val_loss: 61.7104 - val_accuracy: 0.3828 - val_MSE: 0.2211 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 35/65\n",
      "25/25 [==============================] - 2s 65ms/step - loss: 58.1792 - accuracy: 0.3988 - MSE: 0.2198 - precision_14: 0.5283 - recall_14: 0.0350 - val_loss: 62.9518 - val_accuracy: 0.4219 - val_MSE: 0.2201 - val_precision_14: 0.5000 - val_recall_14: 0.0078\n",
      "Epoch 36/65\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 118.6109 - accuracy: 0.3675 - MSE: 0.2227 - precision_14: 0.4894 - recall_14: 0.0288 - val_loss: 68.6929 - val_accuracy: 0.4219 - val_MSE: 0.2177 - val_precision_14: 1.0000 - val_recall_14: 0.0156\n",
      "Epoch 37/65\n",
      "25/25 [==============================] - 2s 77ms/step - loss: 62.8572 - accuracy: 0.3850 - MSE: 0.2208 - precision_14: 0.4444 - recall_14: 0.0250 - val_loss: 49.2084 - val_accuracy: 0.3906 - val_MSE: 0.2214 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 38/65\n",
      "25/25 [==============================] - 2s 65ms/step - loss: 50.3694 - accuracy: 0.3688 - MSE: 0.2228 - precision_14: 0.4444 - recall_14: 0.0200 - val_loss: 57.5806 - val_accuracy: 0.4062 - val_MSE: 0.2164 - val_precision_14: 1.0000 - val_recall_14: 0.0234\n",
      "Epoch 39/65\n",
      "25/25 [==============================] - 2s 66ms/step - loss: 49.3465 - accuracy: 0.3600 - MSE: 0.2205 - precision_14: 0.5385 - recall_14: 0.0175 - val_loss: 52.8849 - val_accuracy: 0.4375 - val_MSE: 0.2167 - val_precision_14: 1.0000 - val_recall_14: 0.0078\n",
      "Epoch 40/65\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 48.7621 - accuracy: 0.3887 - MSE: 0.2201 - precision_14: 0.4118 - recall_14: 0.0175 - val_loss: 54.5041 - val_accuracy: 0.4375 - val_MSE: 0.2172 - val_precision_14: 1.0000 - val_recall_14: 0.0078\n",
      "Epoch 41/65\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 47.1325 - accuracy: 0.3438 - MSE: 0.2235 - precision_14: 0.3750 - recall_14: 0.0113 - val_loss: 39.5873 - val_accuracy: 0.4141 - val_MSE: 0.2188 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 42/65\n",
      "25/25 [==============================] - 2s 66ms/step - loss: 55.3118 - accuracy: 0.3587 - MSE: 0.2219 - precision_14: 0.5455 - recall_14: 0.0150 - val_loss: 49.1093 - val_accuracy: 0.3984 - val_MSE: 0.2223 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 43/65\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 48.2596 - accuracy: 0.3913 - MSE: 0.2204 - precision_14: 0.4737 - recall_14: 0.0113 - val_loss: 48.0407 - val_accuracy: 0.3906 - val_MSE: 0.2181 - val_precision_14: 1.0000 - val_recall_14: 0.0156\n",
      "Epoch 44/65\n",
      "25/25 [==============================] - 2s 65ms/step - loss: 52.9034 - accuracy: 0.3750 - MSE: 0.2221 - precision_14: 0.4167 - recall_14: 0.0125 - val_loss: 59.3811 - val_accuracy: 0.3906 - val_MSE: 0.2183 - val_precision_14: 1.0000 - val_recall_14: 0.0234\n",
      "Epoch 45/65\n",
      "25/25 [==============================] - 2s 65ms/step - loss: 331.3849 - accuracy: 0.3700 - MSE: 0.2222 - precision_14: 0.2400 - recall_14: 0.0075 - val_loss: 64.0810 - val_accuracy: 0.3906 - val_MSE: 0.2200 - val_precision_14: 1.0000 - val_recall_14: 0.0078\n",
      "Epoch 46/65\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 54.2714 - accuracy: 0.3613 - MSE: 0.2226 - precision_14: 0.5625 - recall_14: 0.0113 - val_loss: 68.8754 - val_accuracy: 0.3672 - val_MSE: 0.2203 - val_precision_14: 1.0000 - val_recall_14: 0.0078\n",
      "Epoch 47/65\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 67.8606 - accuracy: 0.3787 - MSE: 0.2218 - precision_14: 0.4286 - recall_14: 0.0075 - val_loss: 57.4622 - val_accuracy: 0.3750 - val_MSE: 0.2203 - val_precision_14: 1.0000 - val_recall_14: 0.0156\n",
      "Epoch 48/65\n",
      "25/25 [==============================] - 2s 66ms/step - loss: 55.7587 - accuracy: 0.3462 - MSE: 0.2231 - precision_14: 0.4615 - recall_14: 0.0075 - val_loss: 58.0077 - val_accuracy: 0.4297 - val_MSE: 0.2177 - val_precision_14: 1.0000 - val_recall_14: 0.0156\n",
      "Epoch 49/65\n",
      "25/25 [==============================] - 2s 66ms/step - loss: 49.2961 - accuracy: 0.3688 - MSE: 0.2209 - precision_14: 0.7333 - recall_14: 0.0137 - val_loss: 46.7668 - val_accuracy: 0.3828 - val_MSE: 0.2155 - val_precision_14: 1.0000 - val_recall_14: 0.0234\n",
      "Epoch 50/65\n",
      "25/25 [==============================] - 2s 65ms/step - loss: 42.9838 - accuracy: 0.3775 - MSE: 0.2214 - precision_14: 0.4444 - recall_14: 0.0100 - val_loss: 53.2892 - val_accuracy: 0.4219 - val_MSE: 0.2175 - val_precision_14: 1.0000 - val_recall_14: 0.0078\n",
      "Epoch 51/65\n",
      "25/25 [==============================] - 2s 65ms/step - loss: 76.5347 - accuracy: 0.3963 - MSE: 0.2197 - precision_14: 0.5714 - recall_14: 0.0100 - val_loss: 89.9855 - val_accuracy: 0.4141 - val_MSE: 0.2185 - val_precision_14: 0.5000 - val_recall_14: 0.0156\n",
      "Epoch 52/65\n",
      "25/25 [==============================] - 2s 66ms/step - loss: 70.3710 - accuracy: 0.4225 - MSE: 0.2174 - precision_14: 0.5714 - recall_14: 0.0100 - val_loss: 49.7206 - val_accuracy: 0.3906 - val_MSE: 0.2201 - val_precision_14: 1.0000 - val_recall_14: 0.0078\n",
      "Epoch 53/65\n",
      "25/25 [==============================] - 2s 65ms/step - loss: 49.4656 - accuracy: 0.3738 - MSE: 0.2198 - precision_14: 0.6471 - recall_14: 0.0137 - val_loss: 46.6978 - val_accuracy: 0.4219 - val_MSE: 0.2170 - val_precision_14: 1.0000 - val_recall_14: 0.0078\n",
      "Epoch 54/65\n",
      "25/25 [==============================] - 2s 65ms/step - loss: 53.3334 - accuracy: 0.3825 - MSE: 0.2211 - precision_14: 0.5625 - recall_14: 0.0113 - val_loss: 57.1974 - val_accuracy: 0.3984 - val_MSE: 0.2196 - val_precision_14: 1.0000 - val_recall_14: 0.0078\n",
      "Epoch 55/65\n",
      "25/25 [==============================] - 2s 78ms/step - loss: 80.7320 - accuracy: 0.3688 - MSE: 0.2222 - precision_14: 0.5333 - recall_14: 0.0100 - val_loss: 62.3270 - val_accuracy: 0.3828 - val_MSE: 0.2193 - val_precision_14: 1.0000 - val_recall_14: 0.0156\n",
      "Epoch 56/65\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 361.9192 - accuracy: 0.3375 - MSE: 0.2224 - precision_14: 0.6250 - recall_14: 0.0063 - val_loss: 72.5001 - val_accuracy: 0.3984 - val_MSE: 0.2223 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 57/65\n",
      "25/25 [==============================] - 2s 65ms/step - loss: 59.9790 - accuracy: 0.3450 - MSE: 0.2219 - precision_14: 0.4545 - recall_14: 0.0063 - val_loss: 62.0874 - val_accuracy: 0.3906 - val_MSE: 0.2204 - val_precision_14: 1.0000 - val_recall_14: 0.0078\n",
      "Epoch 58/65\n",
      "25/25 [==============================] - 2s 66ms/step - loss: 91.4825 - accuracy: 0.3613 - MSE: 0.2217 - precision_14: 0.4000 - recall_14: 0.0050 - val_loss: 56.3295 - val_accuracy: 0.3750 - val_MSE: 0.2218 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 59/65\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 57.9925 - accuracy: 0.3750 - MSE: 0.2198 - precision_14: 0.6250 - recall_14: 0.0125 - val_loss: 54.1959 - val_accuracy: 0.4062 - val_MSE: 0.2199 - val_precision_14: 1.0000 - val_recall_14: 0.0078\n",
      "Epoch 60/65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 2s 64ms/step - loss: 140.7363 - accuracy: 0.3762 - MSE: 0.2211 - precision_14: 0.9091 - recall_14: 0.0125 - val_loss: 54.0459 - val_accuracy: 0.3984 - val_MSE: 0.2187 - val_precision_14: 1.0000 - val_recall_14: 0.0078\n",
      "Epoch 61/65\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 54.7536 - accuracy: 0.3837 - MSE: 0.2209 - precision_14: 0.4615 - recall_14: 0.0075 - val_loss: 46.9380 - val_accuracy: 0.4141 - val_MSE: 0.2202 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 62/65\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 45.6566 - accuracy: 0.3688 - MSE: 0.2213 - precision_14: 0.5000 - recall_14: 0.0075 - val_loss: 48.0081 - val_accuracy: 0.3672 - val_MSE: 0.2220 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 63/65\n",
      "25/25 [==============================] - 2s 65ms/step - loss: 46.8569 - accuracy: 0.4000 - MSE: 0.2203 - precision_14: 0.3846 - recall_14: 0.0063 - val_loss: 75.8546 - val_accuracy: 0.3906 - val_MSE: 0.2248 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 64/65\n",
      "25/25 [==============================] - 2s 78ms/step - loss: 45.4698 - accuracy: 0.3625 - MSE: 0.2222 - precision_14: 0.3333 - recall_14: 0.0050 - val_loss: 45.0189 - val_accuracy: 0.3750 - val_MSE: 0.2209 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 65/65\n",
      "25/25 [==============================] - 2s 66ms/step - loss: 47.5609 - accuracy: 0.3688 - MSE: 0.2222 - precision_14: 0.3000 - recall_14: 0.0037 - val_loss: 52.5228 - val_accuracy: 0.3672 - val_MSE: 0.2194 - val_precision_14: 1.0000 - val_recall_14: 0.0156\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_15 (LSTM)               (128, 4)                  96096     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (128, 4)                  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (128, 4)                  16        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (128, 3)                  15        \n",
      "=================================================================\n",
      "Total params: 96,127\n",
      "Trainable params: 96,119\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n",
      "Starting: \n",
      "{'batch_size': 128, 'epochs': 70, 'learning_rate': 0.1, 'optimizer': 'sgd'}\n",
      "---------------------------------------------------------------------------------\n",
      "{   'activation': 'relu',\n",
      "    'dropout_rate': 0.4,\n",
      "    'filters': 3,\n",
      "    'kernel_size': 3,\n",
      "    'l1_r': 0.01,\n",
      "    'l2_r': 0.0001,\n",
      "    'output_layer_activation': 'softmax',\n",
      "    'padding': 'same',\n",
      "    'start_neurons': 4}\n",
      "Epoch 1/70\n",
      "2/6 [=========>....................] - ETA: 4s - loss: 19.9246 - accuracy: 0.3398 - MSE: 0.2448 - precision_15: 0.3810 - recall_15: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1686s vs `on_train_batch_end` time: 1.9042s). Check your callbacks.\n",
      "6/6 [==============================] - 4s 653ms/step - loss: 26.1725 - accuracy: 0.3307 - MSE: 0.2423 - precision_15: 0.3692 - recall_15: 0.0625 - val_loss: 170.7958 - val_accuracy: 0.3203 - val_MSE: 0.2631 - val_precision_15: 0.3542 - val_recall_15: 0.1328\n",
      "Epoch 2/70\n",
      "6/6 [==============================] - 2s 303ms/step - loss: 131.4035 - accuracy: 0.3411 - MSE: 0.2304 - precision_15: 0.4600 - recall_15: 0.0599 - val_loss: 1257.4175 - val_accuracy: 0.2734 - val_MSE: 0.2822 - val_precision_15: 0.2500 - val_recall_15: 0.0781\n",
      "Epoch 3/70\n",
      "6/6 [==============================] - 1s 235ms/step - loss: 499.3863 - accuracy: 0.3307 - MSE: 0.2314 - precision_15: 0.3913 - recall_15: 0.0469 - val_loss: 1083.1565 - val_accuracy: 0.2656 - val_MSE: 0.2902 - val_precision_15: 0.1429 - val_recall_15: 0.0547\n",
      "Epoch 4/70\n",
      "6/6 [==============================] - 1s 232ms/step - loss: 5621.1909 - accuracy: 0.3320 - MSE: 0.2304 - precision_15: 0.3766 - recall_15: 0.0378 - val_loss: 12547.9307 - val_accuracy: 0.3516 - val_MSE: 0.2710 - val_precision_15: 0.2683 - val_recall_15: 0.0859\n",
      "Epoch 5/70\n",
      "6/6 [==============================] - 1s 235ms/step - loss: 20878.8809 - accuracy: 0.3385 - MSE: 0.2315 - precision_15: 0.3731 - recall_15: 0.0326 - val_loss: 39858.6875 - val_accuracy: 0.3828 - val_MSE: 0.2571 - val_precision_15: 0.3500 - val_recall_15: 0.1094\n",
      "Epoch 6/70\n",
      "6/6 [==============================] - 1s 233ms/step - loss: 1453096.8750 - accuracy: 0.3255 - MSE: 0.2316 - precision_15: 0.3103 - recall_15: 0.0234 - val_loss: 56396976.0000 - val_accuracy: 0.3750 - val_MSE: 0.2414 - val_precision_15: 0.4800 - val_recall_15: 0.0938\n",
      "Epoch 7/70\n",
      "6/6 [==============================] - 1s 241ms/step - loss: 3061379.7500 - accuracy: 0.3125 - MSE: 0.2280 - precision_15: 0.4306 - recall_15: 0.0404 - val_loss: 98840272.0000 - val_accuracy: 0.3125 - val_MSE: 0.2620 - val_precision_15: 0.2903 - val_recall_15: 0.0703\n",
      "Epoch 8/70\n",
      "6/6 [==============================] - 1s 232ms/step - loss: 2511035.2500 - accuracy: 0.3411 - MSE: 0.2275 - precision_15: 0.3611 - recall_15: 0.0339 - val_loss: 101125824.0000 - val_accuracy: 0.3281 - val_MSE: 0.2506 - val_precision_15: 0.2609 - val_recall_15: 0.0469\n",
      "Epoch 9/70\n",
      "6/6 [==============================] - 1s 232ms/step - loss: 17707562.0000 - accuracy: 0.3281 - MSE: 0.2312 - precision_15: 0.2909 - recall_15: 0.0208 - val_loss: 88208568.0000 - val_accuracy: 0.2969 - val_MSE: 0.2434 - val_precision_15: 0.2963 - val_recall_15: 0.0625\n",
      "Epoch 10/70\n",
      "6/6 [==============================] - 1s 234ms/step - loss: 43249836.0000 - accuracy: 0.3320 - MSE: 0.2278 - precision_15: 0.3676 - recall_15: 0.0326 - val_loss: 831716800.0000 - val_accuracy: 0.3359 - val_MSE: 0.2627 - val_precision_15: 0.2414 - val_recall_15: 0.0547\n",
      "Epoch 11/70\n",
      "6/6 [==============================] - 1s 237ms/step - loss: 70974136.0000 - accuracy: 0.2773 - MSE: 0.2305 - precision_15: 0.2745 - recall_15: 0.0182 - val_loss: 468558752.0000 - val_accuracy: 0.3438 - val_MSE: 0.2398 - val_precision_15: 0.1579 - val_recall_15: 0.0234\n",
      "Epoch 12/70\n",
      "6/6 [==============================] - 2s 299ms/step - loss: 3887802624.0000 - accuracy: 0.3542 - MSE: 0.2269 - precision_15: 0.2800 - recall_15: 0.0182 - val_loss: 10570664960.0000 - val_accuracy: 0.3516 - val_MSE: 0.2359 - val_precision_15: 0.3750 - val_recall_15: 0.0703\n",
      "Epoch 13/70\n",
      "6/6 [==============================] - 1s 243ms/step - loss: 1733984256.0000 - accuracy: 0.3490 - MSE: 0.2254 - precision_15: 0.3913 - recall_15: 0.0234 - val_loss: 5364483584.0000 - val_accuracy: 0.3438 - val_MSE: 0.2318 - val_precision_15: 0.4000 - val_recall_15: 0.0469\n",
      "Epoch 14/70\n",
      "6/6 [==============================] - 1s 238ms/step - loss: 1029952484933632.0000 - accuracy: 0.3333 - MSE: 0.2266 - precision_15: 0.2444 - recall_15: 0.0143 - val_loss: 1544775584972800.0000 - val_accuracy: 0.3516 - val_MSE: 0.2270 - val_precision_15: 0.3333 - val_recall_15: 0.0156\n",
      "Epoch 15/70\n",
      "6/6 [==============================] - 1s 233ms/step - loss: 1544620966150144.0000 - accuracy: 0.3411 - MSE: 0.2267 - precision_15: 0.2340 - recall_15: 0.0143 - val_loss: 1544404204519424.0000 - val_accuracy: 0.3438 - val_MSE: 0.2310 - val_precision_15: 0.1667 - val_recall_15: 0.0078\n",
      "Epoch 16/70\n",
      "6/6 [==============================] - 1s 234ms/step - loss: 1544247840866304.0000 - accuracy: 0.3516 - MSE: 0.2253 - precision_15: 0.2581 - recall_15: 0.0104 - val_loss: 1544033629372416.0000 - val_accuracy: 0.3438 - val_MSE: 0.2300 - val_precision_15: 0.0000e+00 - val_recall_15: 0.0000e+00\n",
      "Epoch 17/70\n",
      "6/6 [==============================] - 1s 232ms/step - loss: 1543876997283840.0000 - accuracy: 0.3503 - MSE: 0.2239 - precision_15: 0.3043 - recall_15: 0.0091 - val_loss: 1543661712048128.0000 - val_accuracy: 0.3359 - val_MSE: 0.2333 - val_precision_15: 0.1429 - val_recall_15: 0.0078\n",
      "Epoch 18/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 235ms/step - loss: 1543506422136832.0000 - accuracy: 0.3320 - MSE: 0.2244 - precision_15: 0.3158 - recall_15: 0.0078 - val_loss: 1543292479078400.0000 - val_accuracy: 0.3281 - val_MSE: 0.2345 - val_precision_15: 0.0000e+00 - val_recall_15: 0.0000e+00\n",
      "Epoch 19/70\n",
      "6/6 [==============================] - 1s 231ms/step - loss: 1543136115425280.0000 - accuracy: 0.3607 - MSE: 0.2239 - precision_15: 0.1875 - recall_15: 0.0039 - val_loss: 1542924454068224.0000 - val_accuracy: 0.3281 - val_MSE: 0.2389 - val_precision_15: 0.3750 - val_recall_15: 0.0469\n",
      "Epoch 20/70\n",
      "6/6 [==============================] - 1s 230ms/step - loss: 1542774801301504.0000 - accuracy: 0.3490 - MSE: 0.2244 - precision_15: 0.1667 - recall_15: 0.0026 - val_loss: 1542770774769664.0000 - val_accuracy: 0.3359 - val_MSE: 0.2346 - val_precision_15: 0.1111 - val_recall_15: 0.0078\n",
      "Epoch 21/70\n",
      "6/6 [==============================] - 1s 230ms/step - loss: 1542528914423808.0000 - accuracy: 0.3555 - MSE: 0.2225 - precision_15: 0.6154 - recall_15: 0.0104 - val_loss: 1542519250747392.0000 - val_accuracy: 0.3281 - val_MSE: 0.2281 - val_precision_15: 0.4545 - val_recall_15: 0.0391\n",
      "Epoch 22/70\n",
      "6/6 [==============================] - 2s 280ms/step - loss: 1542145991245824.0000 - accuracy: 0.3346 - MSE: 0.2235 - precision_15: 0.3846 - recall_15: 0.0065 - val_loss: 1542151225737216.0000 - val_accuracy: 0.3203 - val_MSE: 0.2298 - val_precision_15: 0.3333 - val_recall_15: 0.0156\n",
      "Epoch 23/70\n",
      "6/6 [==============================] - 2s 254ms/step - loss: 1542035127402496.0000 - accuracy: 0.3477 - MSE: 0.2230 - precision_15: 0.4000 - recall_15: 0.0052 - val_loss: 1547845547065344.0000 - val_accuracy: 0.3672 - val_MSE: 0.2227 - val_precision_15: 0.4615 - val_recall_15: 0.0469\n",
      "Epoch 24/70\n",
      "6/6 [==============================] - 1s 233ms/step - loss: 1546440958541824.0000 - accuracy: 0.3685 - MSE: 0.2215 - precision_15: 0.6154 - recall_15: 0.0104 - val_loss: 1578088693497856.0000 - val_accuracy: 0.3359 - val_MSE: 0.2250 - val_precision_15: 0.5000 - val_recall_15: 0.0234\n",
      "Epoch 25/70\n",
      "6/6 [==============================] - 1s 230ms/step - loss: 1560134522241024.0000 - accuracy: 0.3581 - MSE: 0.2223 - precision_15: 0.1111 - recall_15: 0.0013 - val_loss: 1569154490433536.0000 - val_accuracy: 0.3516 - val_MSE: 0.2260 - val_precision_15: 0.4000 - val_recall_15: 0.0156\n",
      "Epoch 26/70\n",
      "6/6 [==============================] - 1s 232ms/step - loss: 1542463281954816.0000 - accuracy: 0.3763 - MSE: 0.2217 - precision_15: 0.4000 - recall_15: 0.0052 - val_loss: 1573681654398976.0000 - val_accuracy: 0.3672 - val_MSE: 0.2260 - val_precision_15: 0.4000 - val_recall_15: 0.0156\n",
      "Epoch 27/70\n",
      "6/6 [==============================] - 1s 234ms/step - loss: 1548189144449024.0000 - accuracy: 0.3477 - MSE: 0.2222 - precision_15: 0.3333 - recall_15: 0.0026 - val_loss: 1573162634444800.0000 - val_accuracy: 0.3594 - val_MSE: 0.2260 - val_precision_15: 0.4000 - val_recall_15: 0.0156\n",
      "Epoch 28/70\n",
      "6/6 [==============================] - 1s 233ms/step - loss: 1544679753515008.0000 - accuracy: 0.3490 - MSE: 0.2223 - precision_15: 0.4286 - recall_15: 0.0039 - val_loss: 1572915271172096.0000 - val_accuracy: 0.3516 - val_MSE: 0.2259 - val_precision_15: 0.4000 - val_recall_15: 0.0156\n",
      "Epoch 29/70\n",
      "6/6 [==============================] - 1s 236ms/step - loss: 1542554147356672.0000 - accuracy: 0.3555 - MSE: 0.2219 - precision_15: 0.5000 - recall_15: 0.0052 - val_loss: 1572695422533632.0000 - val_accuracy: 0.3594 - val_MSE: 0.2261 - val_precision_15: 0.4000 - val_recall_15: 0.0156\n",
      "Epoch 30/70\n",
      "6/6 [==============================] - 1s 234ms/step - loss: 1541093455822848.0000 - accuracy: 0.3594 - MSE: 0.2219 - precision_15: 0.3333 - recall_15: 0.0039 - val_loss: 1572386721759232.0000 - val_accuracy: 0.3750 - val_MSE: 0.2261 - val_precision_15: 0.4000 - val_recall_15: 0.0156\n",
      "Epoch 31/70\n",
      "6/6 [==============================] - 1s 235ms/step - loss: 1540369753833472.0000 - accuracy: 0.3802 - MSE: 0.2211 - precision_15: 0.5000 - recall_15: 0.0065 - val_loss: 1571884881674240.0000 - val_accuracy: 0.3672 - val_MSE: 0.2265 - val_precision_15: 0.4000 - val_recall_15: 0.0156\n",
      "Epoch 32/70\n",
      "6/6 [==============================] - 1s 243ms/step - loss: 1539255209820160.0000 - accuracy: 0.3620 - MSE: 0.2211 - precision_15: 0.6364 - recall_15: 0.0091 - val_loss: 1571765830549504.0000 - val_accuracy: 0.3594 - val_MSE: 0.2265 - val_precision_15: 0.4000 - val_recall_15: 0.0156\n",
      "Epoch 33/70\n",
      "6/6 [==============================] - 2s 296ms/step - loss: 1538219854266368.0000 - accuracy: 0.3711 - MSE: 0.2215 - precision_15: 0.5833 - recall_15: 0.0091 - val_loss: 1571456592904192.0000 - val_accuracy: 0.3672 - val_MSE: 0.2267 - val_precision_15: 0.5000 - val_recall_15: 0.0156\n",
      "Epoch 34/70\n",
      "6/6 [==============================] - 1s 229ms/step - loss: 1621671203045376.0000 - accuracy: 0.3529 - MSE: 0.2213 - precision_15: 0.6000 - recall_15: 0.0078 - val_loss: 1623479250059264.0000 - val_accuracy: 0.3750 - val_MSE: 0.2245 - val_precision_15: 0.4000 - val_recall_15: 0.0156\n",
      "Epoch 35/70\n",
      "6/6 [==============================] - 1s 234ms/step - loss: 134562771791226339328.0000 - accuracy: 0.3581 - MSE: 0.2220 - precision_15: 0.5833 - recall_15: 0.0091 - val_loss: 68322764775672294777290752.0000 - val_accuracy: 0.3203 - val_MSE: 0.2524 - val_precision_15: 0.3636 - val_recall_15: 0.0625\n",
      "Epoch 36/70\n",
      "6/6 [==============================] - 1s 229ms/step - loss: 356130369223330726418579456.0000 - accuracy: 0.3346 - MSE: 0.2233 - precision_15: 0.2727 - recall_15: 0.0039 - val_loss: 79716691400704178685739008.0000 - val_accuracy: 0.3281 - val_MSE: 0.2271 - val_precision_15: 0.5000 - val_recall_15: 0.0234\n",
      "Epoch 37/70\n",
      "6/6 [==============================] - 1s 235ms/step - loss: 1096666240092686032553639936.0000 - accuracy: 0.3529 - MSE: 0.2226 - precision_15: 0.2857 - recall_15: 0.0026 - val_loss: inf - val_accuracy: 0.3516 - val_MSE: 0.2721 - val_precision_15: 0.3214 - val_recall_15: 0.0703call_15: 0.0\n",
      "Epoch 38/70\n",
      "1/6 [====>.........................] - ETA: 0s - loss: inf - accuracy: 0.3750 - MSE: 0.2220 - precision_15: 1.0000 - recall_15: 0.0078"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " assertion failed: [predictions must be >= 0] [Condition x >= y did not hold element-wise:] [x (sequential_15/dense_15/Softmax:0) = ] [[-nan(ind) -nan(ind) -nan(ind)]...] [y (Cast_8/x:0) = ] [0]\n\t [[{{node assert_greater_equal/Assert/AssertGuard/else/_209/assert_greater_equal/Assert/AssertGuard/Assert}}]] [Op:__inference_train_function_431582]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-b6bc2388562f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhighest_test_accuracy_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhighest_train_accuracy_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhighest_test_precision_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhighest_test_recall_index\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mrandomGridSearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Documents\\Thesis_ssd\\Master Thesis\\Thesis\\RandomGridSearch.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    162\u001b[0m                                                      epoch, val_gen, use_tensorboard = self.use_tensorboard)\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m             \u001b[0mmodel_fit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhelper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_steps_per_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m             current_picks.append({\"test_loss\" : loss,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  assertion failed: [predictions must be >= 0] [Condition x >= y did not hold element-wise:] [x (sequential_15/dense_15/Softmax:0) = ] [[-nan(ind) -nan(ind) -nan(ind)]...] [y (Cast_8/x:0) = ] [0]\n\t [[{{node assert_greater_equal/Assert/AssertGuard/else/_209/assert_greater_equal/Assert/AssertGuard/Assert}}]] [Op:__inference_train_function_431582]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "results, highest_test_accuracy_index, highest_train_accuracy_index, highest_test_precision_index, highest_test_recall_index= randomGridSearch.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionaries = randomGridSearch.read_results()\n",
    "print(dictionaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Highest test accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test_accuracy = randomGridSearch.fit_from_result(dictionaries, highest_test_accuracy_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Highest train accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_accuracy = randomGridSearch.fit_from_result(dictionaries, highest_train_accuracy_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Highest precision**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test_precision = randomGridSearch.fit_from_result(dictionaries, highest_test_precision_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Highest recall**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test_recall = randomGridSearch.fit_from_result(dictionaries, highest_test_recall_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
