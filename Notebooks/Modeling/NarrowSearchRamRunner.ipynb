{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "australian-version",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "import pylab as pl\n",
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"0\" \n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import re\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "classes_dir = '/media/tord/T7/Thesis_ssd/MasterThesis3.0'\n",
    "os.chdir(classes_dir)\n",
    "from Classes.DataProcessing.LoadData import LoadData\n",
    "from Classes.DataProcessing.HelperFunctions import HelperFunctions\n",
    "from Classes.DataProcessing.DataHandler import DataHandler\n",
    "from Classes.DataProcessing.TimeAugmentor import TimeAugmentor\n",
    "from Classes.Modeling.DynamicModels import DynamicModels\n",
    "from Classes.Modeling.StaticModels import StaticModels\n",
    "from Classes.Modeling.NarrowSearchRam import NarrowSearchRam\n",
    "from Classes.Modeling.CustomCallback import CustomCallback\n",
    "from Classes.Modeling.ResultFitter import ResultFitter\n",
    "from Classes.Scaling.ScalerFitter import ScalerFitter\n",
    "from Classes.Scaling.MinMaxScalerFitter import MinMaxScalerFitter\n",
    "from Classes.Scaling.StandardScalerFitter import StandardScalerFitter\n",
    "import json\n",
    "#from Classes import Tf_shutup\n",
    "#Tf_shutup.Tf_shutup()\n",
    "\n",
    "from livelossplot import PlotLossesKeras\n",
    "\n",
    "\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"]= (15,15)\n",
    "helper = HelperFunctions()\n",
    "\n",
    "import sys\n",
    "ISCOLAB = 'google.colab' in sys.modules\n",
    "\n",
    "import random\n",
    "import pprint\n",
    "\n",
    "base_dir = '/media/tord/T7/Thesis_ssd/MasterThesis3.0'\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "according-surname",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "premier-dominican",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping redundancy: [--------------------------------------->] 100 %\r"
     ]
    }
   ],
   "source": [
    "load_args = {\n",
    "    'earth_explo_only' : False,\n",
    "    'noise_earth_only' : False,\n",
    "    'noise_not_noise' : True,\n",
    "    'downsample' : True,\n",
    "    'upsample' : True,\n",
    "    'frac_diff' : 0.3,\n",
    "    'seed' : 1,\n",
    "    'subsample_size' : 0.4,\n",
    "    'balance_non_train_set' : True,\n",
    "    'use_true_test_set' : False\n",
    "}\n",
    "loadData = LoadData(**load_args)\n",
    "full_ds, train_ds, val_ds, test_ds = loadData.get_datasets()\n",
    "noise_ds = loadData.noise_ds\n",
    "handler = DataHandler(loadData)\n",
    "\n",
    "if load_args['earth_explo_only']:\n",
    "    full_and_noise_ds = np.concatenate((full_ds, noise_ds))\n",
    "    timeAug = TimeAugmentor(handler, full_and_noise_ds, seed = load_args['seed'])\n",
    "else:\n",
    "    timeAug = TimeAugmentor(handler, full_ds, seed = load_args['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "realistic-sample",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33854 6771 4514\n",
      "All data:\n",
      "Total: 45139, earthquake: 15036, explosion: 14787, noise: 15316\n",
      "Train set:\n",
      "Total: 33854, earthquake: 11291, explosion: 11127, noise: 11436\n",
      "Validation set:\n",
      "Total: 6771, earthquake: 2230, explosion: 2210, noise: 2331\n",
      "Test set:\n",
      "Total: 4514, earthquake: 1515, explosion: 1450, noise: 1549\n",
      "Nr noise samples 11436\n"
     ]
    }
   ],
   "source": [
    "# Printing data stats:\n",
    "print(len(train_ds), len(val_ds), len(test_ds))\n",
    "print(\"All data:\")\n",
    "classes, counts = handler.get_class_distribution_from_ds(full_ds)\n",
    "print(\"Train set:\")\n",
    "classes, counts = handler.get_class_distribution_from_ds(train_ds)\n",
    "print(\"Validation set:\")\n",
    "classes, counts = handler.get_class_distribution_from_ds(val_ds)\n",
    "print(\"Test set:\")\n",
    "classes, counts = handler.get_class_distribution_from_ds(test_ds)\n",
    "print(\"Nr noise samples \" + str(len(loadData.noise_ds)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "gentle-buddy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detrend and highpass filters are not implemented in this class yet.\n"
     ]
    }
   ],
   "source": [
    "main_grid = {\n",
    "            \"num_layers\" : [2],\n",
    "            \"batch_size\" : [256],\n",
    "            \"epochs\" : [30],\n",
    "            \"learning_rate\" : [0.01],\n",
    "            \"optimizer\" : [\"sgd\"],\n",
    "            \"start_neurons\" : [4],\n",
    "            \"decay_sequence\" : [[1,2,4,6,8,10]],\n",
    "            \"dropout_rate\" : [0.3],\n",
    "            \"filters\" : [17],\n",
    "            \"kernel_size\" : [5],\n",
    "            \"padding\" : [\"same\"],\n",
    "            \"use_layerwise_dropout_batchnorm\" : [True],\n",
    "            \"l2_r\" : [0.001],\n",
    "            \"l1_r\" : [0.0001],\n",
    "            \"activation\" : [\"tanh\"],\n",
    "            \"output_layer_activation\" : [\"sigmoid\"]\n",
    "           }\n",
    "\n",
    "hyper_grid = {\n",
    "        \"num_layers\" : [3,4,5,6],\n",
    "        \"batch_size\" : [128, 512, 1028],\n",
    "        \"epochs\" : [40],\n",
    "        \"learning_rate\" : [0.05, 0.025, .005],\n",
    "        \"optimizer\" : [\"sgd\"]\n",
    "    }\n",
    "model_grid = {\n",
    "    \"start_neurons\" : [2,3,5],\n",
    "    \"use_layerwise_dropout_batchnorm\" : [False, True],\n",
    "    \"decay_sequence\" : [[1,2,4,4,2,1], [1,4,8,8,4,1], [1,0.5,0.25,0.25,0.5,1], [1,1,1,1,1,1]],\n",
    "    \"dropout_rate\" : [0.3, 0.25, 0.2, 0.15, 0.1],\n",
    "    \"filters\" : [11],\n",
    "    \"kernel_size\" : [5],\n",
    "    \"padding\" : [\"same\"],\n",
    "    \"l2_r\" : [0.005, 0.001, 0.0005, 0.0001, 0],\n",
    "    \"l1_r\" : [0.0005, 0.0001, 0.00005],\n",
    "    \"activation\" : [\"tanh\"],\n",
    "    \"output_layer_activation\" : [\"sigmoid\"]\n",
    "}\n",
    "\n",
    "\n",
    "model_nr = \"LSTM\"\n",
    "is_lstm = True\n",
    "num_channels = 3\n",
    "\n",
    "use_time_augmentor = True\n",
    "use_scaler = True\n",
    "use_noise_augmentor = True\n",
    "detrend = False\n",
    "use_minmax = False\n",
    "use_highpass = False\n",
    "highpass_freq = 0.1\n",
    "\n",
    "use_tensorboard = False\n",
    "use_liveplots = True\n",
    "use_custom_callback = False\n",
    "use_early_stopping = True\n",
    "start_from_scratch = True\n",
    "\n",
    "narrowSearch = NarrowSearchRam(loadData, train_ds, val_ds, test_ds, model_nr, detrend, use_scaler, use_time_augmentor, \n",
    "                                    use_noise_augmentor, use_minmax, use_highpass, main_grid, hyper_grid, \n",
    "                                    model_grid, use_tensorboard = use_tensorboard,use_liveplots = use_liveplots, \n",
    "                                    use_custom_callback = use_custom_callback, use_early_stopping = use_early_stopping, \n",
    "                                    highpass_freq = highpass_freq, start_from_scratch = start_from_scratch, is_lstm = is_lstm,\n",
    "                                    num_channels = num_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "opposed-austin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_tensorboard_dir():\n",
    "    import os\n",
    "    import shutil\n",
    "    path = f\"{base_dir}/Tensorboard_dir/fit\"\n",
    "    files = os.listdir(path)\n",
    "    print(files)\n",
    "    for f in files:\n",
    "        shutil.rmtree(os.path.join(path,f))\n",
    "if use_tensorboard:\n",
    "    clear_tensorboard_dir()\n",
    "    %tensorboard --logdir tensorboard_dir/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "obvious-drawing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit process completed after 19.121706247329712 seconds. Total datapoints fitted: 45139.\n",
      "Average time per datapoint: 0.00042361829564965353\n",
      "[{'activation': 'tanh', [------------------> ] 99 %%\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 30,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.05,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 30,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.025,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 30,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.005,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 30,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0005,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 30,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 30,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 5e-05,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 4, 2, 1],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 30,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 4, 8, 8, 4, 1],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 30,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 0.5, 0.25, 0.25, 0.5, 1],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 30,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 1, 1, 1, 1, 1],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 30,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 128,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 30,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 512,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 30,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 1028,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 30,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 30,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.25,\n",
      "  'epochs': 30,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.2,\n",
      "  'epochs': 30,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.15,\n",
      "  'epochs': 30,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.1,\n",
      "  'epochs': 30,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 30,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.005,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 30,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 30,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.0005,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 30,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.0001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 30,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 30,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 2,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 30,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 3,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 30,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 5,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 30,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 3,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 30,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 4,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 30,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 5,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 30,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 6,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 30,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': False},\n",
      " {'activation': 'tanh',\n",
      "  'batch_size': 256,\n",
      "  'decay_sequence': [1, 2, 4, 6, 8, 10],\n",
      "  'dropout_rate': 0.3,\n",
      "  'epochs': 30,\n",
      "  'filters': 17,\n",
      "  'kernel_size': 5,\n",
      "  'l1_r': 0.0001,\n",
      "  'l2_r': 0.001,\n",
      "  'learning_rate': 0.01,\n",
      "  'num_channels': 3,\n",
      "  'num_layers': 2,\n",
      "  'optimizer': 'sgd',\n",
      "  'output_layer_activation': 'sigmoid',\n",
      "  'padding': 'same',\n",
      "  'start_neurons': 4,\n",
      "  'use_layerwise_dropout_batchnorm': True}]\n",
      "Starting loading\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loading\n",
      "Model nr 1 of 32\n",
      "[{'model_nr_type': 'LSTM', 'index': 0}, {'batch_size': 256, 'epochs': 30, 'learning_rate': 0.05, 'num_channels': 3, 'num_layers': 2, 'optimizer': 'sgd'}, {'activation': 'tanh', 'decay_sequence': [1, 2], 'dropout_rate': 0.3, 'filters': 17, 'kernel_size': 5, 'l1_r': 0.0001, 'l2_r': 0.001, 'output_layer_activation': 'sigmoid', 'padding': 'same', 'start_neurons': 4, 'use_layerwise_dropout_batchnorm': True}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/tord/T7/Thesis_ssd/MasterThesis3.0/Classes/Modeling/GridSearchResultProcessor.py:96: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  temp_df = pd.DataFrame(np.array(picks).reshape(1,len(results_df.columns)), columns = results_df.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 6000, 4)           128       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 6000, 4)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 6000, 4)           16        \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 6000, 2)           56        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6000, 2)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 6000, 2)           8         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12000)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 12001     \n",
      "=================================================================\n",
      "Total params: 12,209\n",
      "Trainable params: 12,197\n",
      "Non-trainable params: 12\n",
      "_________________________________________________________________\n",
      "Starting: \n",
      "{   'batch_size': 256,\n",
      "    'epochs': 30,\n",
      "    'learning_rate': 0.05,\n",
      "    'num_channels': 3,\n",
      "    'num_layers': 2,\n",
      "    'optimizer': 'sgd'}\n",
      "---------------------------------------------------------------------------------\n",
      "{   'activation': 'tanh',\n",
      "    'decay_sequence': [1, 2],\n",
      "    'dropout_rate': 0.3,\n",
      "    'filters': 17,\n",
      "    'kernel_size': 5,\n",
      "    'l1_r': 0.0001,\n",
      "    'l2_r': 0.001,\n",
      "    'output_layer_activation': 'sigmoid',\n",
      "    'padding': 'same',\n",
      "    'start_neurons': 4,\n",
      "    'use_layerwise_dropout_batchnorm': True}\n",
      "Epoch 1/30\n",
      " 29/132 [=====>........................] - ETA: 7:50 - loss: 0.7173 - precision: 0.7277 - binary_accuracy: 0.6496 - recall: 0.7584"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-479d9934dff2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_precision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_recall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnarrowSearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/tord/T7/Thesis_ssd/MasterThesis3.0/Classes/Modeling/NarrowSearchRam.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    171\u001b[0m                                                         use_early_stopping = self.use_early_stopping)\n\u001b[1;32m    172\u001b[0m             \u001b[0;31m# Fit the model using the generated args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0mmodel_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;31m# Evaluate the fitted model on the validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results_df, min_loss, max_accuracy, max_precision, max_recall = narrowSearch.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decent-thursday",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
