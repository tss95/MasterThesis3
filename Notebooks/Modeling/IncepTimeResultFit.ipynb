{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "import pylab as pl\n",
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"0\" \n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "base_dir = '/media/tord/T7/Thesis_ssd/MasterThesis3.0'\n",
    "os.chdir(base_dir)\n",
    "\n",
    "from Classes.DataProcessing.LoadData import LoadData\n",
    "from Classes.DataProcessing.HelperFunctions import HelperFunctions\n",
    "from Classes.DataProcessing.DataHandler import DataHandler\n",
    "from Classes.DataProcessing.TimeAugmentor import TimeAugmentor\n",
    "from Classes.DataProcessing.NoiseAugmentor import NoiseAugmentor\n",
    "from Classes.DataProcessing.RamLoader import RamLoader\n",
    "from Classes.DataProcessing.RamGenerator import RamGenerator\n",
    "from Classes.Modeling.InceptionTimeModel import InceptionTimeModel\n",
    "from Classes.Modeling.NarrowSearchRam import NarrowSearchRam\n",
    "from Classes.Modeling.CustomCallback import CustomCallback\n",
    "from Classes.Modeling.ResultFitter import ResultFitter\n",
    "from Classes.Scaling.ScalerFitter import ScalerFitter\n",
    "from Classes.Scaling.MinMaxScalerFitter import MinMaxScalerFitter\n",
    "from Classes.Scaling.StandardScalerFitter import StandardScalerFitter\n",
    "from Classes.Modeling.GridSearchResultProcessor import GridSearchResultProcessor\n",
    "import json\n",
    "#from Classes import Tf_shutup\n",
    "#Tf_shutup.Tf_shutup()\n",
    "\n",
    "from livelossplot import PlotLossesKeras\n",
    "\n",
    "\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"]= (15,15)\n",
    "helper = HelperFunctions()\n",
    "\n",
    "import sys\n",
    "ISCOLAB = 'google.colab' in sys.modules\n",
    "\n",
    "import random\n",
    "import pprint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3\n",
      "{'noise': 105999, 'earthquake': 105999, 'explosion': 102808}\n",
      "Mapping redundancy: [--------------------------------------->] 100 %\r"
     ]
    }
   ],
   "source": [
    "load_args = {\n",
    "    'earth_explo_only' : False,\n",
    "    'noise_earth_only' : False,\n",
    "    'noise_not_noise' : True,\n",
    "    'downsample' : True,\n",
    "    'upsample' : True,\n",
    "    'frac_diff' : 1,\n",
    "    'seed' : 1,\n",
    "    'subsample_size' : 0.4,\n",
    "    'balance_non_train_set' : True,\n",
    "    'use_true_test_set' : False,\n",
    "    'even_balance' : True\n",
    "}\n",
    "loadData = LoadData(**load_args)\n",
    "full_ds, train_ds, val_ds, test_ds = loadData.get_datasets()\n",
    "noise_ds = loadData.noise_ds\n",
    "handler = DataHandler(loadData)\n",
    "\n",
    "if load_args['earth_explo_only']:\n",
    "    full_and_noise_ds = np.concatenate((full_ds, noise_ds))\n",
    "    timeAug = TimeAugmentor(handler, full_and_noise_ds, seed = load_args['seed'])\n",
    "else:\n",
    "    timeAug = TimeAugmentor(handler, full_ds, seed = load_args['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Preprocessing ###########\n",
    "use_noise_augmentor = True\n",
    "use_time_augmentor = True\n",
    "detrend = False\n",
    "use_scaler = True\n",
    "use_highpass = False\n",
    "highpass_freq = 0.2\n",
    "\n",
    "use_tensorboard = True\n",
    "use_livelossplot = False\n",
    "use_custom = False\n",
    "use_reduce_lr = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ResultModelGetter:\n",
    "\n",
    "    def __init__(self, loadData, handler, helper, timeAug = None, scaler = None, noiseAug = None):\n",
    "        self.loadData = loadData\n",
    "        self.handler = handler\n",
    "        self.helper = helper\n",
    "        self.timeAug = timeAug\n",
    "        self.scaler = scaler\n",
    "        self.noiseAug = noiseAug\n",
    "\n",
    "    def model_from_result(self, result_name, input_shape, num_classes = 2, by_index = False, index = 0, top_index = 0, sort_by = ['val_f1', 'train_f1'], early_stop = False):\n",
    "        df = self.load_df(result_name, num_classes)\n",
    "        df_f1 = df.copy()\n",
    "        df_f1 = self.add_f1(df_f1)\n",
    "        df_f1.convert_dtypes().dtypes\n",
    "\n",
    "        if by_index:\n",
    "            model_df = df_f1.iloc[index]\n",
    "        else:\n",
    "            ascending = False\n",
    "            if sort_by == ['val_loss', 'train_loss']:\n",
    "                ascending = True\n",
    "            df_f1 = df_f1.sort_values(by=sort_by, axis = 0, ascending = ascending).reset_index()\n",
    "            model_df = df_f1.iloc[top_index]\n",
    "\n",
    "        model_dict = self.row_to_dict(model_df)\n",
    "        batch_size = model_dict['batch_size']\n",
    "        epochs = model_dict['epochs']\n",
    "        learning_rate = model_dict['learning_rate']\n",
    "        num_channels = model_dict['num_channels']\n",
    "        fit_args = {\"batch_size\" : batch_size, \"epochs\" : epochs, \"learning_rate\" : learning_rate, \"num_channels\" : num_channels}\n",
    "\n",
    "        del model_dict['batch_size']\n",
    "        del model_dict['epochs']\n",
    "        del model_dict['learning_rate']\n",
    "        del model_dict['num_channels']\n",
    "        \n",
    "        return self.build_model_by_name(result_name, model_dict, input_shape, num_classes, fit_args)\n",
    "\n",
    "    def row_to_dict(self, model_df):\n",
    "        keys = list(model_df.keys())\n",
    "        # Assumes 10 columns dedicated to results and the rest to hyperparams\n",
    "        hyper_keys = keys[:len(keys) - 10]\n",
    "        model_dict = model_df[:len(hyper_keys)].to_dict()\n",
    "        del model_dict['index']\n",
    "        return model_dict\n",
    "\n",
    "    def build_model_by_name(self, result_name, model_dict, input_shape, num_classes, fit_args):\n",
    "        model_name = result_name.split('_')[1]\n",
    "        if model_name == 'InceptionTime':\n",
    "            return self.build_incep_model(model_dict, input_shape, num_classes, fit_args)\n",
    "        else:\n",
    "            raise Exception(f\"Not implemented {model_name} yet\")\n",
    "\n",
    "    def build_incep_model(self, model_dict, input_shape, num_classes, fit_args):\n",
    "        optimizer = self.helper.get_optimizer(model_dict['optimizer'], fit_args[\"learning_rate\"])\n",
    "        compile_args = self.helper.generate_model_compile_args(optimizer, num_classes)\n",
    "        input = {\"input_shape\" : input_shape, \"nr_classes\" : num_classes}\n",
    "        build_dict = {**input, **model_dict}\n",
    "        build_dict[\"optimizer\"] = optimizer\n",
    "\n",
    "        inceptionTime = InceptionTimeModel(**build_dict)\n",
    "        model = inceptionTime.build_model(input_shape, num_classes)\n",
    "        print(model.summary())\n",
    "        return model, fit_args\n",
    "\n",
    "        \n",
    "    def load_df(self, result_name, num_classes):\n",
    "        return GridSearchResultProcessor().get_results_df_by_name(result_name, num_classes)\n",
    "\n",
    "    def add_f1(self, df):\n",
    "        df_f1 = df\n",
    "        df_f1.columns=df_f1.columns.str.strip()\n",
    "        all_train_precision = df_f1['train_precision']\n",
    "        all_train_recall = df_f1['train_recall']\n",
    "        all_val_precision = df_f1['val_precision']\n",
    "        all_val_recall = df_f1['val_recall']\n",
    "        f1_train = self.create_f1_list(all_train_precision, all_train_recall)\n",
    "        f1_val = self.create_f1_list(all_val_precision, all_val_recall)\n",
    "        df_f1['train_f1'] = f1_train\n",
    "        df_f1['val_f1'] = f1_val\n",
    "        return df_f1\n",
    "\n",
    "    def f1_score(self, precision, recall):\n",
    "        f1 = 2*((precision*recall)/(precision + recall))\n",
    "        return f1\n",
    "\n",
    "    def create_f1_list(self, precision_df, recall_df):\n",
    "        f1 = []\n",
    "        for i in range(len(precision_df)):\n",
    "            f1.append(self.f1_score(precision_df.loc[i], recall_df.loc[i]))\n",
    "        return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 3, 6000)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 3, 6000)      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 3, 32)        7680000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 3, 32)        3840000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 3, 32)        1920000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 3, 32)        192000      max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 3, 128)       0           conv1d[0][0]                     \n",
      "                                                                 conv1d_1[0][0]                   \n",
      "                                                                 conv1d_2[0][0]                   \n",
      "                                                                 conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 3, 128)       512         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 3, 128)       0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 128)          0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            129         global_average_pooling1d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 13,632,641\n",
      "Trainable params: 13,632,385\n",
      "Non-trainable params: 256\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "resultModel = ResultModelGetter(loadData, handler, HelperFunctions(), None, None, None)\n",
    "model, fit_args = resultModel.model_from_result('results_InceptionTime_noiseNotNoise_timeAug_sscale_noiseAug_earlyS.csv', (3, 6000), by_index = False, index = 10, top_index = 0, sort_by = ['val_accuracy', 'train_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit process completed after 305.30140590667725 seconds. Total datapoints fitted: 84160.\n",
      "Average time per datapoint: 0.003627630773605956\n",
      "Fitting noise progress: [------------------> ] 99 %%\r"
     ]
    }
   ],
   "source": [
    "########### Preprocessing ###########\n",
    "use_noise_augmentor = True\n",
    "use_time_augmentor = True\n",
    "detrend = False\n",
    "use_scaler = True\n",
    "use_highpass = False\n",
    "highpass_freq = 0.2\n",
    "\n",
    "use_tensorboard = True\n",
    "use_livelossplot = False\n",
    "use_custom = False\n",
    "use_reduce_lr = True\n",
    "\n",
    "scaler = None\n",
    "noiseAug = None\n",
    "if use_time_augmentor:\n",
    "    timeAug.fit()\n",
    "if use_scaler:\n",
    "    scaler = StandardScalerFitter(train_ds, timeAug).fit_scaler(detrend = detrend)\n",
    "if use_noise_augmentor:\n",
    "    noiseAug = NoiseAugmentor(train_ds, use_scaler, scaler, loadData, timeAug)\n",
    "num_ds, channels, timesteps = handler.get_trace_shape_no_cast(train_ds, use_time_augmentor)\n",
    "input_shape = (channels, timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loading to RAM\n",
      "Completed loading to RAM\n",
      "Starting loading to RAM\n",
      "Completed loading to RAM\n"
     ]
    }
   ],
   "source": [
    "ramLoader = RamLoader(handler, timeAug, scaler)\n",
    "x_train, y_train = ramLoader.load_to_ram(train_ds, False)\n",
    "x_val, y_val = ramLoader.load_to_ram(val_ds, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20210210-020130', '20210210-020427', '20210210-025257', '20210210-025530', '20210210-025806', '20210210-030202', '20210210-031148', '20210210-031221', '20210210-031640', '20210210-032037', '20210210-032056', '20210210-032449', '20210210-032533', '20210210-032621', '20210210-041554', '20210210-042047', '20210210-042409', '20210210-044355', '20210210-044949', '20210210-045022', '20210210-045442', '20210210-045741', '20210210-050010', '20210210-050948', '20210210-051022', '20210210-051320', '20210210-051622', '20210210-051918', '20210210-052334', '20210210-052604', '20210210-052623', '20210210-053237', '20210210-053733', '20210210-054127', '20210210-054357', '20210210-054749', '20210210-055211', '20210210-055436', '20210210-064324', '20210210-064558', '20210210-064953', '20210210-071709', '20210210-071940', '20210210-072232', '20210210-072502', '20210210-072602', '20210210-072832', '20210210-080711']\n"
     ]
    }
   ],
   "source": [
    "callbacks = []\n",
    "\n",
    "def clear_tensorboard_dir():\n",
    "    import os\n",
    "    import shutil\n",
    "    path = f\"{base_dir}/Tensorboard_dir/fit\"\n",
    "    files = os.listdir(path)\n",
    "    print(files)\n",
    "    for f in files:\n",
    "        shutil.rmtree(os.path.join(path,f))\n",
    "\n",
    "if use_tensorboard:\n",
    "    import datetime\n",
    "    clear_tensorboard_dir()\n",
    "    #%tensorboard --logdir tensorboard_dir/fit\n",
    "    log_dir = f\"{base_dir}/tensorboard_dir/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    callbacks.append(tensorboard_callback)\n",
    "    # tensorboard --logdir='/media/tord/T7/Thesis_ssd/MasterThesis3.0/tensorboard_dir/fit'\n",
    "\n",
    "if use_custom:\n",
    "    custom_callback = CustomCallback(data_gen)\n",
    "    callbacks.append(custom_callback)\n",
    "elif use_livelossplot:\n",
    "    callbacks.append(PlotLossesKeras())\n",
    "elif use_reduce_lr:\n",
    "    callbacks.append(tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50,\n",
    "                                                          min_lr=0.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "123/123 [==============================] - 8s 34ms/step - loss: 0.6632 - precision_1: 0.5999 - binary_accuracy: 0.5892 - recall_1: 0.5030 - val_loss: 0.6711 - val_precision_1: 0.9882 - val_binary_accuracy: 0.5632 - val_recall_1: 0.1231\n",
      "Epoch 2/100\n",
      "123/123 [==============================] - 4s 30ms/step - loss: 0.5613 - precision_1: 0.8165 - binary_accuracy: 0.7263 - recall_1: 0.5816 - val_loss: 1.1909 - val_precision_1: 0.4966 - val_binary_accuracy: 0.4960 - val_recall_1: 0.9957\n",
      "Epoch 3/100\n",
      "123/123 [==============================] - 4s 30ms/step - loss: 0.5205 - precision_1: 0.8155 - binary_accuracy: 0.7534 - recall_1: 0.6524 - val_loss: 0.5569 - val_precision_1: 0.9825 - val_binary_accuracy: 0.7089 - val_recall_1: 0.4221\n",
      "Epoch 4/100\n",
      "123/123 [==============================] - 4s 31ms/step - loss: 0.4960 - precision_1: 0.8327 - binary_accuracy: 0.7708 - recall_1: 0.6762 - val_loss: 0.5069 - val_precision_1: 0.8552 - val_binary_accuracy: 0.8158 - val_recall_1: 0.7579\n",
      "Epoch 5/100\n",
      "123/123 [==============================] - 4s 31ms/step - loss: 0.4803 - precision_1: 0.8377 - binary_accuracy: 0.7816 - recall_1: 0.6926 - val_loss: 1.7243 - val_precision_1: 0.4974 - val_binary_accuracy: 0.4977 - val_recall_1: 0.9822\n",
      "Epoch 6/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.4713 - precision_1: 0.8353 - binary_accuracy: 0.7870 - recall_1: 0.7095 - val_loss: 1.6435 - val_precision_1: 0.9897 - val_binary_accuracy: 0.6111 - val_recall_1: 0.2201\n",
      "Epoch 7/100\n",
      "123/123 [==============================] - 4s 31ms/step - loss: 0.4607 - precision_1: 0.8442 - binary_accuracy: 0.7910 - recall_1: 0.7094 - val_loss: 0.8324 - val_precision_1: 0.5158 - val_binary_accuracy: 0.5316 - val_recall_1: 0.9476\n",
      "Epoch 8/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.4523 - precision_1: 0.8426 - binary_accuracy: 0.7950 - recall_1: 0.7211 - val_loss: 0.5481 - val_precision_1: 0.6123 - val_binary_accuracy: 0.6663 - val_recall_1: 0.8971\n",
      "Epoch 9/100\n",
      "123/123 [==============================] - 4s 33ms/step - loss: 0.4446 - precision_1: 0.8530 - binary_accuracy: 0.8026 - recall_1: 0.7274 - val_loss: 1.2279 - val_precision_1: 0.9897 - val_binary_accuracy: 0.6497 - val_recall_1: 0.2987\n",
      "Epoch 10/100\n",
      "123/123 [==============================] - 4s 33ms/step - loss: 0.4363 - precision_1: 0.8611 - binary_accuracy: 0.8070 - recall_1: 0.7292 - val_loss: 0.4737 - val_precision_1: 0.9781 - val_binary_accuracy: 0.7836 - val_recall_1: 0.5777\n",
      "Epoch 11/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.4308 - precision_1: 0.8605 - binary_accuracy: 0.8092 - recall_1: 0.7351 - val_loss: 2.1055 - val_precision_1: 0.9895 - val_binary_accuracy: 0.6170 - val_recall_1: 0.2322\n",
      "Epoch 12/100\n",
      "123/123 [==============================] - 4s 31ms/step - loss: 0.4224 - precision_1: 0.8708 - binary_accuracy: 0.8142 - recall_1: 0.7353 - val_loss: 1.6535 - val_precision_1: 0.9901 - val_binary_accuracy: 0.6319 - val_recall_1: 0.2624\n",
      "Epoch 13/100\n",
      "123/123 [==============================] - 4s 31ms/step - loss: 0.4143 - precision_1: 0.8735 - binary_accuracy: 0.8194 - recall_1: 0.7440 - val_loss: 1.2007 - val_precision_1: 0.9881 - val_binary_accuracy: 0.6702 - val_recall_1: 0.3409\n",
      "Epoch 14/100\n",
      "123/123 [==============================] - 4s 31ms/step - loss: 0.4111 - precision_1: 0.8741 - binary_accuracy: 0.8207 - recall_1: 0.7462 - val_loss: 0.9657 - val_precision_1: 0.9855 - val_binary_accuracy: 0.6822 - val_recall_1: 0.3663\n",
      "Epoch 15/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.4029 - precision_1: 0.8829 - binary_accuracy: 0.8269 - recall_1: 0.7505 - val_loss: 1.7049 - val_precision_1: 0.4987 - val_binary_accuracy: 0.5002 - val_recall_1: 0.9774\n",
      "Epoch 16/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.4018 - precision_1: 0.8752 - binary_accuracy: 0.8246 - recall_1: 0.7544 - val_loss: 0.5111 - val_precision_1: 0.9704 - val_binary_accuracy: 0.7740 - val_recall_1: 0.5627\n",
      "Epoch 17/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.4016 - precision_1: 0.8733 - binary_accuracy: 0.8235 - recall_1: 0.7548 - val_loss: 1.0718 - val_precision_1: 0.9851 - val_binary_accuracy: 0.6882 - val_recall_1: 0.3786\n",
      "Epoch 18/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.3894 - precision_1: 0.8879 - binary_accuracy: 0.8315 - recall_1: 0.7572 - val_loss: 1.4415 - val_precision_1: 0.4999 - val_binary_accuracy: 0.5025 - val_recall_1: 0.9769\n",
      "Epoch 19/100\n",
      "123/123 [==============================] - 4s 31ms/step - loss: 0.3827 - precision_1: 0.8904 - binary_accuracy: 0.8359 - recall_1: 0.7649 - val_loss: 0.9559 - val_precision_1: 0.9825 - val_binary_accuracy: 0.7091 - val_recall_1: 0.4226\n",
      "Epoch 20/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.3835 - precision_1: 0.8833 - binary_accuracy: 0.8326 - recall_1: 0.7654 - val_loss: 7.2083 - val_precision_1: 0.4970 - val_binary_accuracy: 0.4967 - val_recall_1: 0.9971\n",
      "Epoch 21/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.3798 - precision_1: 0.8845 - binary_accuracy: 0.8356 - recall_1: 0.7723 - val_loss: 1.4732 - val_precision_1: 0.4991 - val_binary_accuracy: 0.5011 - val_recall_1: 0.9833\n",
      "Epoch 22/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.3724 - precision_1: 0.8891 - binary_accuracy: 0.8384 - recall_1: 0.7733 - val_loss: 3.1248 - val_precision_1: 0.4970 - val_binary_accuracy: 0.4968 - val_recall_1: 0.9894\n",
      "Epoch 23/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.3722 - precision_1: 0.8893 - binary_accuracy: 0.8381 - recall_1: 0.7734 - val_loss: 1.0165 - val_precision_1: 0.9826 - val_binary_accuracy: 0.7061 - val_recall_1: 0.4164\n",
      "Epoch 24/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.3674 - precision_1: 0.8955 - binary_accuracy: 0.8428 - recall_1: 0.7757 - val_loss: 1.2589 - val_precision_1: 0.9884 - val_binary_accuracy: 0.6746 - val_recall_1: 0.3498\n",
      "Epoch 25/100\n",
      "123/123 [==============================] - 4s 31ms/step - loss: 0.3661 - precision_1: 0.8961 - binary_accuracy: 0.8441 - recall_1: 0.7771 - val_loss: 1.3878 - val_precision_1: 0.9869 - val_binary_accuracy: 0.6595 - val_recall_1: 0.3195\n",
      "Epoch 26/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.3615 - precision_1: 0.8988 - binary_accuracy: 0.8466 - recall_1: 0.7806 - val_loss: 2.5167 - val_precision_1: 0.4978 - val_binary_accuracy: 0.4985 - val_recall_1: 0.9856\n",
      "Epoch 27/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.3606 - precision_1: 0.8972 - binary_accuracy: 0.8464 - recall_1: 0.7819 - val_loss: 3.3213 - val_precision_1: 0.4969 - val_binary_accuracy: 0.4967 - val_recall_1: 0.9863\n",
      "Epoch 28/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.3545 - precision_1: 0.8969 - binary_accuracy: 0.8479 - recall_1: 0.7861 - val_loss: 2.5856 - val_precision_1: 0.9923 - val_binary_accuracy: 0.5968 - val_recall_1: 0.1905\n",
      "Epoch 29/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.3504 - precision_1: 0.9062 - binary_accuracy: 0.8528 - recall_1: 0.7863 - val_loss: 2.4200 - val_precision_1: 0.4989 - val_binary_accuracy: 0.5006 - val_recall_1: 0.9845\n",
      "Epoch 30/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.3508 - precision_1: 0.8981 - binary_accuracy: 0.8505 - recall_1: 0.7882 - val_loss: 4.7055 - val_precision_1: 0.4968 - val_binary_accuracy: 0.4963 - val_recall_1: 0.9926\n",
      "Epoch 31/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.3470 - precision_1: 0.9016 - binary_accuracy: 0.8530 - recall_1: 0.7897 - val_loss: 3.1339 - val_precision_1: 0.4971 - val_binary_accuracy: 0.4970 - val_recall_1: 0.9908\n",
      "Epoch 32/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.3427 - precision_1: 0.9031 - binary_accuracy: 0.8559 - recall_1: 0.7944 - val_loss: 0.3975 - val_precision_1: 0.9098 - val_binary_accuracy: 0.8402 - val_recall_1: 0.7532\n",
      "Epoch 33/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.3396 - precision_1: 0.9083 - binary_accuracy: 0.8564 - recall_1: 0.7910 - val_loss: 2.3162 - val_precision_1: 0.5004 - val_binary_accuracy: 0.5036 - val_recall_1: 0.9673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100\n",
      "123/123 [==============================] - 4s 31ms/step - loss: 0.3387 - precision_1: 0.9076 - binary_accuracy: 0.8582 - recall_1: 0.7956 - val_loss: 2.6690 - val_precision_1: 0.4978 - val_binary_accuracy: 0.4984 - val_recall_1: 0.9912\n",
      "Epoch 35/100\n",
      "123/123 [==============================] - 4s 31ms/step - loss: 0.3324 - precision_1: 0.9093 - binary_accuracy: 0.8594 - recall_1: 0.7961 - val_loss: 2.3869 - val_precision_1: 0.4983 - val_binary_accuracy: 0.4995 - val_recall_1: 0.9881\n",
      "Epoch 36/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.3270 - precision_1: 0.9181 - binary_accuracy: 0.8655 - recall_1: 0.8006 - val_loss: 7.8001 - val_precision_1: 0.4971 - val_binary_accuracy: 0.4971 - val_recall_1: 0.9971\n",
      "Epoch 37/100\n",
      "123/123 [==============================] - 4s 33ms/step - loss: 0.3262 - precision_1: 0.9123 - binary_accuracy: 0.8655 - recall_1: 0.8062 - val_loss: 3.6603 - val_precision_1: 0.4972 - val_binary_accuracy: 0.4972 - val_recall_1: 0.9979\n",
      "Epoch 38/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.3252 - precision_1: 0.9120 - binary_accuracy: 0.8636 - recall_1: 0.8035 - val_loss: 0.4883 - val_precision_1: 0.7573 - val_binary_accuracy: 0.7475 - val_recall_1: 0.7242\n",
      "Epoch 39/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.3229 - precision_1: 0.9143 - binary_accuracy: 0.8648 - recall_1: 0.8048 - val_loss: 1.2984 - val_precision_1: 0.4996 - val_binary_accuracy: 0.5020 - val_recall_1: 0.9854\n",
      "Epoch 40/100\n",
      "123/123 [==============================] - 4s 31ms/step - loss: 0.3182 - precision_1: 0.9206 - binary_accuracy: 0.8685 - recall_1: 0.8063 - val_loss: 0.5266 - val_precision_1: 0.9244 - val_binary_accuracy: 0.7505 - val_recall_1: 0.5426\n",
      "Epoch 41/100\n",
      "123/123 [==============================] - 4s 31ms/step - loss: 0.3131 - precision_1: 0.9230 - binary_accuracy: 0.8703 - recall_1: 0.8073 - val_loss: 3.7976 - val_precision_1: 0.4975 - val_binary_accuracy: 0.4978 - val_recall_1: 0.9943\n",
      "Epoch 42/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.3105 - precision_1: 0.9240 - binary_accuracy: 0.8722 - recall_1: 0.8114 - val_loss: 2.9498 - val_precision_1: 0.4972 - val_binary_accuracy: 0.4972 - val_recall_1: 0.9972\n",
      "Epoch 43/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.3128 - precision_1: 0.9189 - binary_accuracy: 0.8685 - recall_1: 0.8079 - val_loss: 4.1899 - val_precision_1: 0.9897 - val_binary_accuracy: 0.5492 - val_recall_1: 0.0943\n",
      "Epoch 44/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.3115 - precision_1: 0.9269 - binary_accuracy: 0.8718 - recall_1: 0.8061 - val_loss: 4.5897 - val_precision_1: 0.4969 - val_binary_accuracy: 0.4967 - val_recall_1: 0.9964\n",
      "Epoch 45/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.3091 - precision_1: 0.9190 - binary_accuracy: 0.8722 - recall_1: 0.8148 - val_loss: 7.3168 - val_precision_1: 0.4969 - val_binary_accuracy: 0.4967 - val_recall_1: 0.9967\n",
      "Epoch 46/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.3110 - precision_1: 0.9160 - binary_accuracy: 0.8707 - recall_1: 0.8145 - val_loss: 1.0272 - val_precision_1: 0.5043 - val_binary_accuracy: 0.5110 - val_recall_1: 0.9722\n",
      "Epoch 47/100\n",
      "123/123 [==============================] - 4s 33ms/step - loss: 0.3049 - precision_1: 0.9205 - binary_accuracy: 0.8745 - recall_1: 0.8182 - val_loss: 0.4436 - val_precision_1: 0.8061 - val_binary_accuracy: 0.8040 - val_recall_1: 0.7975\n",
      "Epoch 48/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.3019 - precision_1: 0.9216 - binary_accuracy: 0.8755 - recall_1: 0.8194 - val_loss: 2.4401 - val_precision_1: 0.4976 - val_binary_accuracy: 0.4980 - val_recall_1: 0.9925\n",
      "Epoch 49/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.3000 - precision_1: 0.9222 - binary_accuracy: 0.8761 - recall_1: 0.8196 - val_loss: 1.0656 - val_precision_1: 0.5519 - val_binary_accuracy: 0.5900 - val_recall_1: 0.9322\n",
      "Epoch 50/100\n",
      "123/123 [==============================] - 4s 33ms/step - loss: 0.2990 - precision_1: 0.9154 - binary_accuracy: 0.8744 - recall_1: 0.8234 - val_loss: 2.5812 - val_precision_1: 0.4973 - val_binary_accuracy: 0.4975 - val_recall_1: 0.9946\n",
      "Epoch 51/100\n",
      "123/123 [==============================] - 4s 33ms/step - loss: 0.2906 - precision_1: 0.9255 - binary_accuracy: 0.8800 - recall_1: 0.8248 - val_loss: 0.9339 - val_precision_1: 0.9794 - val_binary_accuracy: 0.6994 - val_recall_1: 0.4039\n",
      "Epoch 52/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.2861 - precision_1: 0.9304 - binary_accuracy: 0.8823 - recall_1: 0.8241 - val_loss: 2.9927 - val_precision_1: 0.9908 - val_binary_accuracy: 0.5894 - val_recall_1: 0.1759\n",
      "Epoch 53/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.2833 - precision_1: 0.9336 - binary_accuracy: 0.8847 - recall_1: 0.8266 - val_loss: 2.1221 - val_precision_1: 0.4987 - val_binary_accuracy: 0.5002 - val_recall_1: 0.9935\n",
      "Epoch 54/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.2871 - precision_1: 0.9233 - binary_accuracy: 0.8807 - recall_1: 0.8276 - val_loss: 1.5525 - val_precision_1: 0.9856 - val_binary_accuracy: 0.6672 - val_recall_1: 0.3357\n",
      "Epoch 55/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.2799 - precision_1: 0.9275 - binary_accuracy: 0.8840 - recall_1: 0.8306 - val_loss: 1.7890 - val_precision_1: 0.4939 - val_binary_accuracy: 0.4908 - val_recall_1: 0.9722\n",
      "Epoch 56/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.2782 - precision_1: 0.9276 - binary_accuracy: 0.8857 - recall_1: 0.8342 - val_loss: 0.5558 - val_precision_1: 0.9636 - val_binary_accuracy: 0.8058 - val_recall_1: 0.6334\n",
      "Epoch 57/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.2739 - precision_1: 0.9271 - binary_accuracy: 0.8874 - recall_1: 0.8377 - val_loss: 6.3912 - val_precision_1: 0.4967 - val_binary_accuracy: 0.4962 - val_recall_1: 0.9941\n",
      "Epoch 58/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.2722 - precision_1: 0.9265 - binary_accuracy: 0.8868 - recall_1: 0.8379 - val_loss: 0.8171 - val_precision_1: 0.5556 - val_binary_accuracy: 0.5938 - val_recall_1: 0.9152\n",
      "Epoch 59/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.2701 - precision_1: 0.9290 - binary_accuracy: 0.8895 - recall_1: 0.8402 - val_loss: 1.1932 - val_precision_1: 0.9596 - val_binary_accuracy: 0.6733 - val_recall_1: 0.3579\n",
      "Epoch 60/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.2696 - precision_1: 0.9327 - binary_accuracy: 0.8911 - recall_1: 0.8395 - val_loss: 1.5654 - val_precision_1: 0.9835 - val_binary_accuracy: 0.6506 - val_recall_1: 0.3023\n",
      "Epoch 61/100\n",
      "123/123 [==============================] - 4s 33ms/step - loss: 0.2659 - precision_1: 0.9326 - binary_accuracy: 0.8899 - recall_1: 0.8370 - val_loss: 0.6024 - val_precision_1: 0.9849 - val_binary_accuracy: 0.7322 - val_recall_1: 0.4686\n",
      "Epoch 62/100\n",
      "123/123 [==============================] - 4s 33ms/step - loss: 0.2619 - precision_1: 0.9345 - binary_accuracy: 0.8943 - recall_1: 0.8447 - val_loss: 10.9082 - val_precision_1: 0.4972 - val_binary_accuracy: 0.4972 - val_recall_1: 0.9979\n",
      "Epoch 63/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.2678 - precision_1: 0.9267 - binary_accuracy: 0.8888 - recall_1: 0.8416 - val_loss: 1.4143 - val_precision_1: 0.4979 - val_binary_accuracy: 0.4986 - val_recall_1: 0.9840\n",
      "Epoch 64/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.2614 - precision_1: 0.9310 - binary_accuracy: 0.8927 - recall_1: 0.8446 - val_loss: 0.8234 - val_precision_1: 0.5274 - val_binary_accuracy: 0.5523 - val_recall_1: 0.9576\n",
      "Epoch 65/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.2574 - precision_1: 0.9336 - binary_accuracy: 0.8955 - recall_1: 0.8473 - val_loss: 2.8030 - val_precision_1: 0.9890 - val_binary_accuracy: 0.5680 - val_recall_1: 0.1326\n",
      "Epoch 66/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.2546 - precision_1: 0.9362 - binary_accuracy: 0.8959 - recall_1: 0.8463 - val_loss: 0.6986 - val_precision_1: 0.9528 - val_binary_accuracy: 0.7649 - val_recall_1: 0.5547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100\n",
      "123/123 [==============================] - 4s 31ms/step - loss: 0.2550 - precision_1: 0.9332 - binary_accuracy: 0.8957 - recall_1: 0.8491 - val_loss: 4.5277 - val_precision_1: 0.4925 - val_binary_accuracy: 0.4880 - val_recall_1: 0.9769\n",
      "Epoch 68/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.2490 - precision_1: 0.9341 - binary_accuracy: 0.8986 - recall_1: 0.8540 - val_loss: 4.4132 - val_precision_1: 0.4977 - val_binary_accuracy: 0.4982 - val_recall_1: 0.9956\n",
      "Epoch 69/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.2435 - precision_1: 0.9394 - binary_accuracy: 0.9021 - recall_1: 0.8558 - val_loss: 0.7442 - val_precision_1: 0.6758 - val_binary_accuracy: 0.6720 - val_recall_1: 0.6540\n",
      "Epoch 70/100\n",
      "123/123 [==============================] - 4s 31ms/step - loss: 0.2431 - precision_1: 0.9378 - binary_accuracy: 0.9026 - recall_1: 0.8589 - val_loss: 3.5336 - val_precision_1: 0.4995 - val_binary_accuracy: 0.5017 - val_recall_1: 0.9881\n",
      "Epoch 71/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.2377 - precision_1: 0.9418 - binary_accuracy: 0.9052 - recall_1: 0.8607 - val_loss: 2.9983 - val_precision_1: 0.4980 - val_binary_accuracy: 0.4989 - val_recall_1: 0.9869\n",
      "Epoch 72/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.2368 - precision_1: 0.9408 - binary_accuracy: 0.9052 - recall_1: 0.8623 - val_loss: 1.6273 - val_precision_1: 0.9785 - val_binary_accuracy: 0.5751 - val_recall_1: 0.1488\n",
      "Epoch 73/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.2345 - precision_1: 0.9423 - binary_accuracy: 0.9057 - recall_1: 0.8618 - val_loss: 12.7777 - val_precision_1: 0.4971 - val_binary_accuracy: 0.4971 - val_recall_1: 0.9979\n",
      "Epoch 74/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.2335 - precision_1: 0.9399 - binary_accuracy: 0.9048 - recall_1: 0.8630 - val_loss: 5.6705 - val_precision_1: 0.4965 - val_binary_accuracy: 0.4958 - val_recall_1: 0.9931\n",
      "Epoch 75/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.2346 - precision_1: 0.9381 - binary_accuracy: 0.9050 - recall_1: 0.8651 - val_loss: 8.7849 - val_precision_1: 0.4971 - val_binary_accuracy: 0.4971 - val_recall_1: 0.9969\n",
      "Epoch 76/100\n",
      "123/123 [==============================] - 4s 31ms/step - loss: 0.2315 - precision_1: 0.9374 - binary_accuracy: 0.9063 - recall_1: 0.8694 - val_loss: 1.1348 - val_precision_1: 0.9776 - val_binary_accuracy: 0.7008 - val_recall_1: 0.4075\n",
      "Epoch 77/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.2327 - precision_1: 0.9421 - binary_accuracy: 0.9055 - recall_1: 0.8626 - val_loss: 3.3199 - val_precision_1: 0.9894 - val_binary_accuracy: 0.5854 - val_recall_1: 0.1681\n",
      "Epoch 78/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.2358 - precision_1: 0.9379 - binary_accuracy: 0.9050 - recall_1: 0.8666 - val_loss: 7.2910 - val_precision_1: 0.4965 - val_binary_accuracy: 0.4958 - val_recall_1: 0.9928\n",
      "Epoch 79/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.2348 - precision_1: 0.9352 - binary_accuracy: 0.9044 - recall_1: 0.8678 - val_loss: 1.2931 - val_precision_1: 0.9847 - val_binary_accuracy: 0.6827 - val_recall_1: 0.3676\n",
      "Epoch 80/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.2239 - precision_1: 0.9414 - binary_accuracy: 0.9102 - recall_1: 0.8737 - val_loss: 7.9569 - val_precision_1: 0.4964 - val_binary_accuracy: 0.4956 - val_recall_1: 0.9943\n",
      "Epoch 81/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.2207 - precision_1: 0.9445 - binary_accuracy: 0.9123 - recall_1: 0.8746 - val_loss: 2.7626 - val_precision_1: 0.4999 - val_binary_accuracy: 0.5025 - val_recall_1: 0.9864\n",
      "Epoch 82/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.2173 - precision_1: 0.9432 - binary_accuracy: 0.9118 - recall_1: 0.8749 - val_loss: 3.2300 - val_precision_1: 0.4944 - val_binary_accuracy: 0.4919 - val_recall_1: 0.9653\n",
      "Epoch 83/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.2174 - precision_1: 0.9458 - binary_accuracy: 0.9150 - recall_1: 0.8791 - val_loss: 6.7189 - val_precision_1: 0.4967 - val_binary_accuracy: 0.4962 - val_recall_1: 0.9903\n",
      "Epoch 84/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.2107 - precision_1: 0.9444 - binary_accuracy: 0.9162 - recall_1: 0.8825 - val_loss: 0.6322 - val_precision_1: 0.7067 - val_binary_accuracy: 0.7125 - val_recall_1: 0.7211\n",
      "Epoch 85/100\n",
      "123/123 [==============================] - 4s 33ms/step - loss: 0.2124 - precision_1: 0.9470 - binary_accuracy: 0.9153 - recall_1: 0.8786 - val_loss: 6.1780 - val_precision_1: 0.4979 - val_binary_accuracy: 0.4987 - val_recall_1: 0.9933\n",
      "Epoch 86/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.2055 - precision_1: 0.9475 - binary_accuracy: 0.9189 - recall_1: 0.8850 - val_loss: 1.9586 - val_precision_1: 0.4992 - val_binary_accuracy: 0.5012 - val_recall_1: 0.9820\n",
      "Epoch 87/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.2039 - precision_1: 0.9498 - binary_accuracy: 0.9192 - recall_1: 0.8835 - val_loss: 1.1599 - val_precision_1: 0.5117 - val_binary_accuracy: 0.5247 - val_recall_1: 0.9661\n",
      "Epoch 88/100\n",
      "123/123 [==============================] - 4s 33ms/step - loss: 0.2051 - precision_1: 0.9445 - binary_accuracy: 0.9169 - recall_1: 0.8839 - val_loss: 6.6681 - val_precision_1: 0.9929 - val_binary_accuracy: 0.5592 - val_recall_1: 0.1142\n",
      "Epoch 89/100\n",
      "123/123 [==============================] - 4s 33ms/step - loss: 0.2047 - precision_1: 0.9504 - binary_accuracy: 0.9193 - recall_1: 0.8827 - val_loss: 1.7964 - val_precision_1: 0.9864 - val_binary_accuracy: 0.6833 - val_recall_1: 0.3682\n",
      "Epoch 90/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.1985 - precision_1: 0.9518 - binary_accuracy: 0.9221 - recall_1: 0.8870 - val_loss: 4.1729 - val_precision_1: 0.4977 - val_binary_accuracy: 0.4983 - val_recall_1: 0.9923\n",
      "Epoch 91/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.1939 - precision_1: 0.9517 - binary_accuracy: 0.9239 - recall_1: 0.8917 - val_loss: 5.6594 - val_precision_1: 0.4984 - val_binary_accuracy: 0.4995 - val_recall_1: 0.9926\n",
      "Epoch 92/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.1931 - precision_1: 0.9520 - binary_accuracy: 0.9248 - recall_1: 0.8931 - val_loss: 10.8839 - val_precision_1: 0.4969 - val_binary_accuracy: 0.4966 - val_recall_1: 0.9959\n",
      "Epoch 93/100\n",
      "123/123 [==============================] - 4s 33ms/step - loss: 0.1924 - precision_1: 0.9472 - binary_accuracy: 0.9231 - recall_1: 0.8944 - val_loss: 5.6215 - val_precision_1: 0.9933 - val_binary_accuracy: 0.5867 - val_recall_1: 0.1699\n",
      "Epoch 94/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.1928 - precision_1: 0.9477 - binary_accuracy: 0.9225 - recall_1: 0.8923 - val_loss: 3.2086 - val_precision_1: 0.9862 - val_binary_accuracy: 0.6287 - val_recall_1: 0.2570\n",
      "Epoch 95/100\n",
      "123/123 [==============================] - 4s 33ms/step - loss: 0.1913 - precision_1: 0.9503 - binary_accuracy: 0.9235 - recall_1: 0.8920 - val_loss: 11.8295 - val_precision_1: 0.4973 - val_binary_accuracy: 0.4973 - val_recall_1: 0.9967\n",
      "Epoch 96/100\n",
      "123/123 [==============================] - 4s 33ms/step - loss: 0.1891 - precision_1: 0.9482 - binary_accuracy: 0.9252 - recall_1: 0.8986 - val_loss: 7.8648 - val_precision_1: 0.4975 - val_binary_accuracy: 0.4979 - val_recall_1: 0.9933\n",
      "Epoch 97/100\n",
      "123/123 [==============================] - 4s 33ms/step - loss: 0.1818 - precision_1: 0.9549 - binary_accuracy: 0.9283 - recall_1: 0.8983 - val_loss: 4.5442 - val_precision_1: 0.9867 - val_binary_accuracy: 0.5862 - val_recall_1: 0.1700\n",
      "Epoch 98/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.1805 - precision_1: 0.9537 - binary_accuracy: 0.9296 - recall_1: 0.9010 - val_loss: 5.1775 - val_precision_1: 0.5002 - val_binary_accuracy: 0.5031 - val_recall_1: 0.9895\n",
      "Epoch 99/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.1798 - precision_1: 0.9507 - binary_accuracy: 0.9287 - recall_1: 0.9026 - val_loss: 2.7403 - val_precision_1: 0.4998 - val_binary_accuracy: 0.5024 - val_recall_1: 0.9899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 0.1799 - precision_1: 0.9546 - binary_accuracy: 0.9289 - recall_1: 0.8987 - val_loss: 1.9640 - val_precision_1: 0.5174 - val_binary_accuracy: 0.5348 - val_recall_1: 0.9573\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "gen = RamGenerator(loadData, handler)\n",
    "\n",
    "batch_size = fit_args[\"batch_size\"]\n",
    "\n",
    "train_gen = gen.data_generator(x_train, y_train, batch_size)\n",
    "val_gen = gen.data_generator(x_val, y_val, batch_size)\n",
    "\n",
    "args = {'steps_per_epoch' : helper.get_steps_per_epoch(train_ds, batch_size),\n",
    "        'epochs' : 100,\n",
    "        'validation_data' : val_gen,\n",
    "        'validation_steps' : helper.get_steps_per_epoch(val_ds, batch_size),\n",
    "        'verbose' : 1,\n",
    "        'use_multiprocessing' : False, \n",
    "        'workers' : 1,\n",
    "        'callbacks' : callbacks\n",
    "}\n",
    "\n",
    "model_fit = model.fit(train_gen, **args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
