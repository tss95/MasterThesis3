{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "raising-premises",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tord/miniconda3/envs/thesis/lib/python3.8/site-packages/tensorflow/python/util/module_wrapper.py:49: The name tf.keras.layers.CuDNNLSTM is deprecated. Please use tf.compat.v1.keras.layers.CuDNNLSTM instead.\n",
      "\n",
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: GeForce RTX 3090, compute capability 8.6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import gc\n",
    "\n",
    "import sklearn as sk\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras.utils import GeneratorEnqueuer\n",
    "\n",
    "import os\n",
    "base_dir = '/media/tord/T7/Thesis_ssd/MasterThesis3'\n",
    "os.chdir(base_dir)\n",
    "\n",
    "from Classes.Modeling.DynamicModels import DynamicModels\n",
    "from Classes.Modeling.StaticModels import StaticModels\n",
    "from Classes.DataProcessing.LoadData import LoadData\n",
    "from Classes.DataProcessing.HelperFunctions import HelperFunctions\n",
    "from Classes.DataProcessing.DataHandler import DataHandler\n",
    "from Classes.DataProcessing.RamLoader import RamLoader\n",
    "from Classes.Modeling.GridSearchResultProcessor import GridSearchResultProcessor\n",
    "from Classes.DataProcessing.ts_RamGenerator import data_generator\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "import random\n",
    "import pprint\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "differential-boxing",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-d053011f799b>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-d053011f799b>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    model_type, **p, reshape = True, results_df = None):\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class TrainSingleModel(GridSearchResultProcessor):\n",
    "    \n",
    "    def __init__(self, x_train, y_train, x_val, y_val, x_test, y_test, noiseAug, helper, loadData, \n",
    "                 model_type, num_channels, use_tensorboard, use_liveplots, use_custom_callback,\n",
    "                 use_early_stopping, use_reduced_lr, log_data = True, results_df = None, \n",
    "                 results_file_name = None, index = None):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_val = x_val\n",
    "        self.y_val = y_val\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        self.num_channels = num_channels\n",
    "        \n",
    "        self.noiseAug = noiseAug\n",
    "        self.helper = helper\n",
    "        self.loadData = loadData\n",
    "        \n",
    "        self.use_tensorboard = use_tensorboard\n",
    "        self.use_liveplots = use_liveplots\n",
    "        self.use_custom_callback = use_custom_callback\n",
    "        self.use_early_stopping = use_early_stopping\n",
    "        self.use_reduced_lr = use_reduced_lr\n",
    "        \n",
    "        self.num_classes = len(set(self.loadData.label_dict.values()))\n",
    "        \n",
    "        self.model_type = model_type\n",
    "        self.p = p\n",
    "        self.results_df = results_df\n",
    "        self.log_data = log_data\n",
    "        \n",
    "        self.index = index\n",
    "        \n",
    "    def create_and_compile_model(self, **p):\n",
    "        gc.collect()\n",
    "        tf.keras.backend.clear_session()\n",
    "        tf.config.optimizer.set_jit(True)\n",
    "        mixed_precision.set_global_policy('mixed_float16')\n",
    "        \n",
    "        epoch = p[\"epochs\"]\n",
    "        batch_size = p[\"batch_size\"]\n",
    "        opt = self.helper.get_optimizer(p[\"optimizer\"], p[\"learning_rate\"])\n",
    "        \n",
    "        p = self.handle_hyperparams(p)\n",
    "        \n",
    "        if self.index != None\n",
    "            model_info = {\"model_type\" : self.model_type, \"index\" : self.index}\n",
    "        else:\n",
    "            model_info = {\"model_type\" : self.model_type}\n",
    "        current_picks = [model_info, p]\n",
    "        pp = pprint.PrettyPrinter(indent=4)\n",
    "        pp.pprint(current_picks)\n",
    "        if self.log_data and self.results_df != None and self.results_file_name != None:\n",
    "            self.results_df = self.store_params_before_fit_opti(p, self.results_df, self.results_file_name)\n",
    "        \n",
    "        _,_,timesteps = self.x_train.shape\n",
    "        input_shape = (timesteps, self.num_channels)\n",
    "        \n",
    "        model = DynamicModels(self.model_type, self.num_classes, input_shape, **p).model\n",
    "        model_compile_args = self.helper.generate_model_compile_args(opt, self.num_classes)\n",
    "        model.compile(**model_compile_args)\n",
    "        return model\n",
    "        \n",
    "        \n",
    "    \n",
    "    def handle_hyperparams(self, **p):\n",
    "        if \"decay_sequence\" or \"growth_sequence\" in p:\n",
    "            if \"num_filters\" in p:\n",
    "                units_or_num_filters = p[\"num_filters\"]\n",
    "            else:\n",
    "                units_or_num_filters = p[\"units\"]\n",
    "            num_layers = p[\"num_layers\"]\n",
    "            if \"decay_sequence\" in p:\n",
    "                p[\"decay_sequence\"] = self.helper.get_max_decay_sequence(num_layers,\n",
    "                                                                         units_or_num_filters,\n",
    "                                                                         p[\"decay_sequence\"],\n",
    "                                                                         self.num_classes)\n",
    "            else:\n",
    "                p[\"growth_sequence\"] = p[\"growth_sequence\"][:num_layers]\n",
    "        return p\n",
    "    \n",
    "    def create_enqueuer(self, x, y, batch_size, noiseAug, num_channels):\n",
    "        enq = GeneratorEnqueuer(data_generator(X, y, batch_size, noiseAug, num_channels = num_channels, is_lstm  = True), \n",
    "                                use_multiprocessing = False)\n",
    "        return enq\n",
    "        \n",
    "    def fit_model(self, model, workers, max_queue_size, **p):\n",
    "        train_enq = create_enqueuer(self.x_train, self.y_train, p[\"batch_size\"], self.num_channels)\n",
    "        val_enq = create_enqueuer(self.x_val, self.y_val, p[\"batch_size\"], self.num_channels)\n",
    "        train_enq.start(workers = workers, max_queue_size = max_queue_size)\n",
    "        val_enq.start(workers = workers, max_queue_size = max_queue_size)\n",
    "        train_gen = train_enq.get()\n",
    "        val_gen = val_enq.get()\n",
    "        \n",
    "        fit_args = self.helper.generate_fit_args(self.loadData.train, self.val, self.loadData,\n",
    "                                                 p[\"batch_size\"], p[\"epoch\"], val_gen,\n",
    "                                                 use_tensorboard = self.use_tensorboard, \n",
    "                                                 use_liveplots = self.use_liveplots, \n",
    "                                                 use_custom_callback = self.use_custom_callback,\n",
    "                                                 use_early_stopping = self.use_early_stopping,\n",
    "                                                 use_reduced_lr = self.use_reduced_lr)\n",
    "         try:\n",
    "                print(f\"Utilizes {self.helper.get_steps_per_epoch(self.loadData.val, p[\"batch_size\"])*p[\"batch_size\"]}/{len(self.loadData.val)} validation points\")\n",
    "                print(f\"Utilizes {self.helper.get_steps_per_epoch(self.loadData.train, p[\"batch_size\"])*p[\"batch_size\"]}/{len(self.loadData.train)} training points\")\n",
    "                print(\"---------------------------------------------------------------------------------\")\n",
    "                \n",
    "                # Fit the model using the generated args\n",
    "                model.fit(train_gen, **fit_args)\n",
    "                train_enq.stop()\n",
    "                val_enq.stop()\n",
    "                del train_gen, val_gen, train_enq, val_enq\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "            print(\"Something went wrong.\")\n",
    "        return model\n",
    "    \n",
    "\n",
    "        \n",
    "            \n",
    "        \n",
    "       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
