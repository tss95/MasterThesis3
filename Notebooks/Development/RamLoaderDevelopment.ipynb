{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "thesis",
   "display_name": "thesis",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import pylab as pl\n",
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"0\" \n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "base_dir = '/media/tord/T7/Thesis_ssd/MasterThesis3/'\n",
    "os.chdir(base_dir)\n",
    "\n",
    "from GlobalUtils import GlobalUtils\n",
    "utils = GlobalUtils()\n",
    "os.chdir(utils.base_dir)\n",
    "from Classes.DataProcessing.HelperFunctions import HelperFunctions\n",
    "from Classes.DataProcessing.DataHandler import DataHandler\n",
    "\n",
    "\n",
    "helper = HelperFunctions()\n",
    "\n",
    "import sys\n",
    "ISCOLAB = 'google.colab' in sys.modules\n",
    "\n",
    "import random\n",
    "import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import utils\n",
    "from obspy import Stream, Trace, UTCDateTime\n",
    "\n",
    "import os\n",
    "import sys\n",
    "classes_dir = '/media/tord/T7/Thesis_ssd/MasterThesis3'\n",
    "os.chdir(classes_dir)\n",
    "from Classes.DataProcessing.LoadData import LoadData\n",
    "from Classes.DataProcessing.HelperFunctions import HelperFunctions\n",
    "from Classes.DataProcessing.DataHandler import DataHandler\n",
    "from Classes.DataProcessing.DataGenerator import DataGenerator\n",
    "from Classes.DataProcessing.TimeAugmentor import TimeAugmentor\n",
    "from Classes.Scaling.ScalerFitter import ScalerFitter\n",
    "from Classes.Scaling.MinMaxScalerFitter import MinMaxScalerFitter\n",
    "from Classes.Scaling.StandardScalerFitter import StandardScalerFitter\n",
    "\n",
    "class RamLoader:\n",
    "    def __init__(self, loadData, handler, use_time_augmentor = False, use_scaler = False, use_minmax = False, \n",
    "                use_highpass = False, highpass_freq = 0.1, detrend = False, load_test_set = False):\n",
    "        self.loadData = loadData\n",
    "        self.handler = handler\n",
    "        self.full_ds, self.train_ds, self.val_ds, self.test_ds = self.loadData.get_datasets()\n",
    "        self.use_time_augmentor = use_time_augmentor\n",
    "        self.use_scaler = use_scaler\n",
    "        self.use_minmax = use_minmax\n",
    "        self.use_highpass = use_highpass\n",
    "        self.highpass_freq = highpass_freq\n",
    "        self.detrend = detrend\n",
    "        self.load_test_set = load_test_set\n",
    "        self.num_classes = len(set(handler.loadData.label_dict.values()))\n",
    "\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    Time, filter, scaler, noise:\n",
    "    1. timeaug\n",
    "    2. filter\n",
    "    3 scaler\n",
    "    4. noise\n",
    "    Time, scaler, noise:\n",
    "    1. timeaug\n",
    "    2. scaler\n",
    "    3. noise\n",
    "    filter, scaler, noise:\n",
    "    1. filter\n",
    "    2. scaler\n",
    "    3. noise\n",
    "    \n",
    "\n",
    "    PROBLEMS: \n",
    "    - Scaling is different if a filter is used. If a filter is used, we need to load the data into ram,\n",
    "    detrend/filter it, as well as time augment it, prior to fitting the scaler.\n",
    "\n",
    "    - Initially this class was initiated once for each dataset. Since we are fitting timeAug and scalers\n",
    "    within this class now, we need to do everything in on initiation of the class\n",
    "    \"\"\"\n",
    "    \n",
    "    def fit_timeAug(self):\n",
    "        timeAug = None\n",
    "        if self.use_time_augmentor:\n",
    "            timeAug = TimeAugmentor(self.handler, self.full_ds, seed = self.loadData.seed)\n",
    "            timeAug.fit()\n",
    "            print(\"\\n\")\n",
    "        return timeAug\n",
    "    \n",
    "    def fit_scaler(self, traces):\n",
    "        scaler = None\n",
    "        if self.use_scaler:\n",
    "            if self.use_minmax:\n",
    "                scaler = MinMaxScalerFitter(self.train_ds, self.timeAug).fit_scaler_ram(traces)\n",
    "            else:\n",
    "                scaler = StandardScalerFitter(self.train_ds, self.timeAug).fit_scaler_ram(traces)\n",
    "        print(\"\\n\")\n",
    "        return scaler\n",
    "    \n",
    "    def stage_one_load(self, ds):\n",
    "        loaded_label = np.empty((len(ds), 1))\n",
    "        loaded_trace = np.empty((self.handler.get_trace_shape_no_cast(ds, self.use_time_augmentor)))\n",
    "        num_events = len(ds)\n",
    "        for i in range(num_events):\n",
    "            self.progress_bar_1(i+1, num_events)\n",
    "            loaded_label[i] = self.handler.label_dict.get(ds[i][1])\n",
    "            # timeAug, highpass and detrend.\n",
    "            if (self.use_highpass or self.detrend) or self.use_time_augmentor:\n",
    "                if (self.use_highpass or self.detrend) and self.use_time_augmentor:\n",
    "                    loaded_trace[i] = self.timeAug.augment_event(ds[i][0], ds[i][2])\n",
    "                    loaded_trace[i] = self.detrend_highpass(loaded_trace[i], self.detrend, self.use_highpass)\n",
    "                if not (self.use_highpass or self.detrend):\n",
    "                    loaded_trace[i] = self.timeAug.augment_event(ds[i][0], ds[i][2])\n",
    "                if not self.use_time_augmentor:\n",
    "                    loaded_trace[i] = self.handler.path_to_trace(ds[i][0])\n",
    "                    loaded_trace[i] = self.detrend_highpass(loaded_trace[i], self.detrend, self.use_highpass)\n",
    "            else:\n",
    "                loaded_trace[i] = self.handler.path_to_trace(ds[i][0])\n",
    "        print(\"\\n\")\n",
    "        return loaded_trace, loaded_label\n",
    "    \n",
    "    def stage_two_load(self, traces, labels, is_lstm, num_channels):\n",
    "        num_samples = traces.shape[0]\n",
    "        if use_scaler:\n",
    "            for i in range(num_samples):\n",
    "                self.progress_bar_2(i+1, num_samples)\n",
    "                traces[i] = self.scaler.transform(traces[i])\n",
    "            print(\"\\n\")\n",
    "        traces = traces[:][:,0:num_channels]\n",
    "        if is_lstm:\n",
    "            traces = np.reshape(traces, (traces.shape[0], \n",
    "                                         traces.shape[2], \n",
    "                                         traces.shape[1]))\n",
    "        labels = utils.to_categorical(labels, self.num_classes, dtype=np.int8)\n",
    "        if self.num_classes == 2:\n",
    "            labels = labels[:,1]\n",
    "            labels = np.reshape(labels, (labels.shape[0],1))\n",
    "        return traces\n",
    "\n",
    "\n",
    "    def load_to_ram(self, is_lstm, load_test_set = False, num_channels = 3):\n",
    "        print(\"\\n\")\n",
    "        # Starting with fitting potential time augmentor\n",
    "        self.timeAug = self.fit_timeAug()\n",
    "        # Step one, load traces and apply time augmentation and/or detrend/highpass\n",
    "        train_trace, train_label = self.stage_one_load(self.train_ds)\n",
    "        val_trace, val_label = self.stage_one_load(self.val_ds)\n",
    "        if load_test_set:\n",
    "            test_trace, test_label = self.stage_one_load(self.test_ds)\n",
    "        # The scaler is dependent on timeAug and highpasss/detrend, so must now fit the scaler:\n",
    "        self.scaler = self.fit_scaler(train_trace)\n",
    "        # Using the fitted scaler, we transform the traces:\n",
    "        train_trace = self.stage_two_load(train_trace, train_label, is_lstm, num_channels)\n",
    "        val_trace = self.stage_two_load(val_trace, val_label, is_lstm, num_channels)\n",
    "        if load_test_set:\n",
    "            test_trace = self.stage_two_load(test_trace, test_label, is_lstm, num_channels)\n",
    "        print(\"Completed loading to RAM\")\n",
    "        if load_test_set:\n",
    "            return train_trace, train_label, val_trace, val_label, test_trace, test_label, self.timeAug, self.scaler\n",
    "        return train_trace, train_label, val_trace, val_label, self.timeAug, self.scaler\n",
    "                \n",
    "    \n",
    "    def detrend_highpass(self, trace, detrend, use_highpass):\n",
    "        trace_BHE = Trace(data=trace[0])\n",
    "        trace_BHN = Trace(data=trace[1])\n",
    "        trace_BHZ = Trace(data=trace[2])\n",
    "        stream = Stream([trace_BHE, trace_BHN, trace_BHZ])\n",
    "        if detrend:\n",
    "            stream.detrend('demean')\n",
    "        if use_highpass:\n",
    "            stream.taper(max_percentage=0.05, type='cosine')\n",
    "            stream.filter('highpass', freq = highpass_freq)\n",
    "        return np.array(stream)\n",
    "\n",
    "    def progress_bar_1(self, current, total, barLength = 40):\n",
    "        percent = float(current) * 100 / total\n",
    "        arrow   = '-' * int(percent/100 * barLength - 1) + '>'\n",
    "        spaces  = ' ' * (barLength - len(arrow))\n",
    "        print('Stage 1 loading to RAM: [%s%s] %d %%' % (arrow, spaces, percent), end='\\r')\n",
    "\n",
    "    def progress_bar_2(self, current, total, barLength = 40):\n",
    "        percent = float(current) * 100 / total\n",
    "        arrow   = '-' * int(percent/100 * barLength - 1) + '>'\n",
    "        spaces  = ' ' * (barLength - len(arrow))\n",
    "        print('Stage 2 loading to RAM: [%s%s] %d %%' % (arrow, spaces, percent), end='\\r')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": []
    }
   ],
   "source": [
    "load_args = {\n",
    "    'earth_explo_only' : True,\n",
    "    'noise_earth_only' : False,\n",
    "    'noise_not_noise' : False,\n",
    "    'downsample' : True,\n",
    "    'upsample' : True,\n",
    "    'frac_diff' : 1,\n",
    "    'seed' : 1,\n",
    "    'subsample_size' : 0.5,\n",
    "    'balance_non_train_set' : False,\n",
    "    'use_true_test_set' : False,\n",
    "    'even_balance' : False\n",
    "}\n",
    "loadData = LoadData(**load_args)\n",
    "full_ds, train_ds, val_ds, test_ds = loadData.get_datasets()\n",
    "noise_ds = loadData.noise_ds\n",
    "handler = DataHandler(loadData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_time_augmentor = True\n",
    "use_scaler = True\n",
    "use_minmax = False\n",
    "use_highpass = True\n",
    "highpass_freq = 0.1\n",
    "detrend = False\n",
    "\n",
    "is_lstm = False\n",
    "load_test_set = False\n",
    "num_channels = 3\n",
    "\n",
    "\n",
    "ramLoader = RamLoader(loadData, handler, use_time_augmentor, use_scaler, use_minmax, use_highpass, highpass_freq, detrend)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "Fit process completed after 5.637794733047485 seconds. Total datapoints fitted: 18342.\n",
      "Average time per datapoint: 0.0003073707738004299\n",
      "\n",
      "\n",
      "Stage 1 loading to RAM: [--------------------------------------->] 100 %\n",
      "\n",
      "Stage 1 loading to RAM: [--------------------------------------->] 100 %\n",
      "\n",
      "Fitting scaler progress: [------------------->] 100 %\n",
      "\n",
      "Stage 2 loading to RAM: [--------------------------------------->] 100 %\n",
      "\n",
      "Stage 2 loading to RAM: [--------------------------------------->] 100 %\n",
      "\n",
      "Completed loading to RAM\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0c1da3cffb51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeAug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mramLoader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_to_ram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_test_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "train_trace, train_label, val_trace, val_label, timeAug, scaler = ramLoader.load_to_ram(is_lstm, load_test_set, num_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}