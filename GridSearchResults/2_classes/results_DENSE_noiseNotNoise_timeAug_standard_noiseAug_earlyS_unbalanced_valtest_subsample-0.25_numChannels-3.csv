use_layerwise_dropout_batchnorm,units,output_layer_activation,optimizer,num_layers,learning_rate,l2_r,l1_r,epochs,dropout_rate,dropout_T_bn_F,decay_sequence,batch_size,activation,train_loss,train_accuracy,train_precision,train_recall,train_f1,val_loss,val_accuracy,val_precision,val_recall,val_f1,confusion_matrix
False,160,sigmoid,adam,3,0.01,0.1,0.001,50,0.01,False,"[1, 2, 4]",256,relu,,,,,,,,,,,
